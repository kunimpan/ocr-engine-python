{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34dada8f-805b-4f0f-98ca-f0c5e539f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Conv2D, MaxPool2D, \n",
    "                                     BatchNormalization, Flatten, GlobalAveragePooling2D, Input)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.applications import EfficientNetB7, MobileNetV2, VGG19, DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0cd42ac-5d40-430e-a94f-a411500e43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directory_to_df(path : str):\n",
    "    \"\"\"\n",
    "    This function to retrieve all images from targeted folder in a file, the\n",
    "    folder must be divided hirarchally in which each class contains its images individually.\n",
    "    ________________________________________________________________________________________________\n",
    "    Arguments-\n",
    "    \n",
    "    path: String -> the main folder directory that contains train/test folders\n",
    "    \n",
    "    ________________________________________________________________________________________________\n",
    "    Return-\n",
    "    \n",
    "    DataFrame: contains the images path and label corresponding to every image\n",
    "    \"\"\"\n",
    "    df = []\n",
    "    chars = 'abcdefghijklmnopqrstuvwxyz'    # to include lowercase letters only\n",
    "    for cls in os.listdir(path):\n",
    "        cls_path = os.path.join(path,cls)\n",
    "        cls_name = cls.split('_')[0]\n",
    "        if not cls_name in chars:\n",
    "            continue\n",
    "        for img_path in os.listdir(cls_path):\n",
    "            direct = os.path.join(cls_path,img_path)\n",
    "            df.append([direct,cls_name])\n",
    "    \n",
    "    df = pd.DataFrame(df, columns=['image','label'])\n",
    "    print(\"The number of samples found:\",len(df))\n",
    "    return df.copy()\n",
    "\n",
    "def read_image(path):\n",
    "    \"\"\"\n",
    "    Read an image from specified directory\n",
    "    _____________________________________________________________\n",
    "    Arguments:\n",
    "    \n",
    "    path: String -> a directory of the image\n",
    "    _____________________________________________________________\n",
    "    Return:\n",
    "    \n",
    "    image: numpy.array of the image\n",
    "    \"\"\"\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def show_image(img, label=None) -> None:\n",
    "    \"\"\"\n",
    "    This function to display any image\n",
    "    _________________________________________________________\n",
    "    Arguements:\n",
    "    \n",
    "    img: numpy.array of N-D\n",
    "    \n",
    "    label: String -> the title/label added with the image, Default= None\n",
    "    _________________________________________________________\n",
    "    Return:\n",
    "    \n",
    "    plt.imshow()\n",
    "    \"\"\"\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis(False)\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "    \n",
    "def clbck(model_name):\n",
    "    # The function is defined to make the callbacks for training the models\n",
    "    ERLY = EarlyStopping(patience=10, min_delta=0.01, start_from_epoch=10, verbose=1)\n",
    "    RD = ReduceLROnPlateau(patience=5, min_delta=0.01, factor=0.5)\n",
    "    CHK = ModelCheckpoint(f'{model_name}_model.h5',verbose=1, save_best_only=True)\n",
    "    return [ERLY,RD,CHK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e961d796-2d06-4457-a521-5311fb7ee314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-defined hyperparameters\n",
    "IMG_SHAPE = (32,32)\n",
    "IMG_SIZE = (32,32,3)\n",
    "BATCH_SIZE = 32\n",
    "opt = Adam(learning_rate=0.00001, epsilon=1e-6)\n",
    "loss = 'categorical_crossentropy'\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae185eb-e790-4bfd-9645-77b240852f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples found: 85199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset\\a_L\\A_L_1.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset\\a_L\\A_L_10.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset\\a_L\\A_L_100.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset\\a_L\\A_L_1000.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset\\a_L\\A_L_1001.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image label\n",
       "0     dataset\\a_L\\A_L_1.png     a\n",
       "1    dataset\\a_L\\A_L_10.png     a\n",
       "2   dataset\\a_L\\A_L_100.png     a\n",
       "3  dataset\\a_L\\A_L_1000.png     a\n",
       "4  dataset\\a_L\\A_L_1001.png     a"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = 'dataset'\n",
    "df = directory_to_df(main_path)                   \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "734bc867-beda-4054-9fbe-e5449671e5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "e    3284\n",
       "r    3284\n",
       "a    3281\n",
       "m    3281\n",
       "n    3281\n",
       "q    3279\n",
       "u    3278\n",
       "i    3277\n",
       "d    3277\n",
       "s    3276\n",
       "y    3276\n",
       "x    3276\n",
       "k    3276\n",
       "l    3276\n",
       "t    3276\n",
       "f    3275\n",
       "w    3275\n",
       "p    3275\n",
       "g    3275\n",
       "o    3275\n",
       "h    3275\n",
       "z    3275\n",
       "c    3274\n",
       "v    3274\n",
       "b    3274\n",
       "j    3274\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaad8024-3131-4bd1-9a8a-1da32068588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['image'], df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.30, random_state=41)\n",
    "training_df = pd.concat((X_train,y_train), axis=1)\n",
    "testing_df = pd.concat((X_test,y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a361f203-2805-45c9-ab05-d291f1e8a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting for training & validation (75,25 respectively) -> the training set size = 52.5%\n",
    "X, y = training_df['image'], training_df['label']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y , test_size=0.25, random_state=41)\n",
    "training_df = pd.concat((X_train,y_train), axis=1)\n",
    "validation_df = pd.concat((X_valid,y_valid), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ec45de-3d80-4c52-9987-e056f2085e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44729 validated image filenames belonging to 26 classes.\n",
      "Found 14910 validated image filenames belonging to 26 classes.\n",
      "Found 25560 validated image filenames belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(dtype=np.int32, brightness_range=[0.0,1.0], fill_mode='nearest')\n",
    "gen2 = ImageDataGenerator(dtype=np.int32, fill_mode='nearest')\n",
    "train_gen = gen.flow_from_dataframe(training_df, x_col='image',y_col='label', batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMG_SHAPE)\n",
    "valid_gen = gen2.flow_from_dataframe(validation_df, x_col='image', y_col='label', batch_size=BATCH_SIZE, \n",
    "                                        target_size=IMG_SHAPE, shuffle=False)\n",
    "test_gen = gen2.flow_from_dataframe(testing_df, x_col='image', y_col='label', batch_size=BATCH_SIZE, \n",
    "                                       target_size=IMG_SHAPE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7055d603-a0b8-4ebf-9f0d-a69f17ac98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = train_gen.class_indices\n",
    "mapping_inverse = dict(map(lambda x: tuple(reversed(x)), mapping.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b6b0693-d56c-4553-a5e9-551d69e12742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the image: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "BATCH_NUM = 10\n",
    "IMG_NUM = 2      # from 0 to 31\n",
    "show_image(train_gen[BATCH_NUM][0][IMG_NUM],mapping_inverse[train_gen[BATCH_NUM][1][IMG_NUM].argmax()])\n",
    "print('The shape of the image:',train_gen[BATCH_NUM][0][IMG_NUM].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c37c6a-306d-43b2-8dcb-24e05d3fe9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the image: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "BATCH_NUM = 65\n",
    "IMG_NUM = 30      # from 0 to 31\n",
    "show_image(train_gen[BATCH_NUM][0][IMG_NUM],mapping_inverse[train_gen[BATCH_NUM][1][IMG_NUM].argmax()])\n",
    "print('The shape of the image:',train_gen[BATCH_NUM][0][IMG_NUM].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19cffdc-d416-460b-b838-1d878f36d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = Sequential()\n",
    "CNN_model.add(Input(shape=IMG_SIZE, batch_size=BATCH_SIZE, name='Input'))\n",
    "CNN_model.add(Conv2D(3, (3,3), strides=1, activation='relu', padding='same'))\n",
    "CNN_model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "CNN_model.add(MaxPool2D((3,3)))\n",
    "CNN_model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "CNN_model.add(Dropout(0.2))\n",
    "CNN_model.add(Conv2D(256, (3,3), strides=2, activation='relu', padding='same'))\n",
    "CNN_model.add(MaxPool2D((2,2)))\n",
    "CNN_model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "CNN_model.add(Dropout(0.2))\n",
    "CNN_model.add(Conv2D(1024, (2,2), activation='relu', padding='same'))\n",
    "CNN_model.add(MaxPool2D(2,2))\n",
    "CNN_model.add(Flatten())\n",
    "CNN_model.add(Dense(1024, activation='selu'))\n",
    "CNN_model.add(Dense(len(mapping), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf5537f-2b30-45e1-9092-e8b8adaee5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (32, 32, 32, 3)           84        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (32, 30, 30, 128)         3584      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (32, 10, 10, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (32, 8, 8, 256)           295168    \n",
      "                                                                 \n",
      " dropout (Dropout)           (32, 8, 8, 256)           0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (32, 4, 4, 256)           590080    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (32, 2, 2, 256)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (32, 2, 2, 512)           1180160   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (32, 2, 2, 512)           0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (32, 2, 2, 1024)          2098176   \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (32, 1, 1, 1024)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (32, 1024)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (32, 1024)                1049600   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32, 26)                  26650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,243,502\n",
      "Trainable params: 5,243,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07da5cbd-827b-4a89-99df-7fa429e14bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.compile(optimizer=Adam(), loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7de5a94a-be44-41e0-9c3d-25a56cae7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 117/1398 [=>............................] - ETA: 2:33 - loss: 3.3129 - accuracy: 0.1322"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/dropout/dropout/Mul_1' defined at (most recent call last):\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Impan\\AppData\\Local\\Temp\\ipykernel_27956\\3023231320.py\", line 1, in <module>\n      history = CNN_model.fit(train_gen, epochs=20, validation_data=valid_gen)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 116, in call\n      output = control_flow_util.smart_cond(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 112, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\backend.py\", line 2162, in dropout\n      return tf.nn.dropout(\nNode: 'sequential/dropout/dropout/Mul_1'\nrequired broadcastable shapes\n\t [[{{node sequential/dropout/dropout/Mul_1}}]] [Op:__inference_train_function_1270]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mCNN_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_gen\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/dropout/dropout/Mul_1' defined at (most recent call last):\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Impan\\AppData\\Local\\Temp\\ipykernel_27956\\3023231320.py\", line 1, in <module>\n      history = CNN_model.fit(train_gen, epochs=20, validation_data=valid_gen)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 116, in call\n      output = control_flow_util.smart_cond(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 112, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"C:\\Users\\Impan\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\backend.py\", line 2162, in dropout\n      return tf.nn.dropout(\nNode: 'sequential/dropout/dropout/Mul_1'\nrequired broadcastable shapes\n\t [[{{node sequential/dropout/dropout/Mul_1}}]] [Op:__inference_train_function_1270]"
     ]
    }
   ],
   "source": [
    "history = CNN_model.fit(train_gen, epochs=20, validation_data=valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf359f23-8976-4e3c-b3c9-eb30f8115236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
