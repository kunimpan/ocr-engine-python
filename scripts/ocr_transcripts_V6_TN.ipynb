{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "output_folder = Path(\"../data/output_images/output_V6_TN\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_1.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_3.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_4.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_5.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_6.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_7.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_8.png\") # ซ้ำกับ 7\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_9.png\") # จับตารางได้แต่พังตอน pt\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_10.png\") # ลบเส้นตารางไม่หมดตรงรหัสวิชา\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_11.png\") # ภาพใหญ่เกินไป\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_12.png\") # ตารางไม่ตรง\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_13.png\") # ติดลอยปั้มหมึก\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_14.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_15.png\")\n",
    "\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"ไม่พบไฟล์ภาพ กรุณาตรวจสอบเส้นทางของไฟล์\")\n",
    "\n",
    "denoised = cv2.bilateralFilter(image, d=9, sigmaColor=100, sigmaSpace=100) # จำกัด noise\n",
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "binary_gaussian = cv2.adaptiveThreshold(\n",
    "    gray_img, \n",
    "    maxValue=255, \n",
    "    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    thresholdType=cv2.THRESH_BINARY_INV, \n",
    "    blockSize=51, \n",
    "    C=21 #21\n",
    ")\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/original.png\", image)\n",
    "cv2.imwrite(f\"{output_folder}/denoised.png\", denoised)\n",
    "cv2.imwrite(f\"{output_folder}/gray.png\", gray_img)\n",
    "cv2.imwrite(f\"{output_folder}/binary_g.png\", binary_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour #0: bounding box = (x=6, y=195, w=161, h=1810, area=289440)\n",
      "Contour #1: bounding box = (x=178, y=195, w=678, h=1810, area=1224693)\n",
      "Contour #2: bounding box = (x=867, y=195, w=53, h=1810, area=94068)\n",
      "Contour #3: bounding box = (x=931, y=195, w=61, h=1810, area=108540)\n",
      "Contour #4: bounding box = (x=1003, y=195, w=68, h=1810, area=121203)\n",
      "Contour #5: bounding box = (x=1082, y=195, w=161, h=1810, area=289440)\n",
      "Contour #6: bounding box = (x=1254, y=195, w=678, h=1810, area=1224693)\n",
      "Contour #7: bounding box = (x=1943, y=195, w=54, h=1810, area=95877)\n",
      "Contour #8: bounding box = (x=2008, y=195, w=60, h=1810, area=106731)\n",
      "Contour #9: bounding box = (x=2079, y=195, w=69, h=1810, area=123012)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_grade_table_and_students(binary_img, denoised):\n",
    "    \n",
    "    # แยกตาราง\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_img, connectivity=8)\n",
    "    areas = [stat[4] for stat in stats]  # ดึงค่า area\n",
    "    sorted_areas = sorted(areas, reverse=True)  # เรียงลำดับจากมากไปน้อย\n",
    "    second_max_area = sorted_areas[1]  # ค่าอันดับ 2\n",
    "    second_max_area_index = areas.index(second_max_area)  # หาตำแหน่งในลิสต์เดิม\n",
    "    table_position = stats[second_max_area_index]\n",
    "    x, y, w, h, area = table_position\n",
    "    table_img = binary_img[y:y+h, x:x+w]\n",
    "    table_original_img = denoised[y:y+h, x:x+w]\n",
    "\n",
    "    # ข้อมูลนักเรียน\n",
    "    #x_start = int((x+w) * 0.40) # ความกว้าง 40% ของตาราง\n",
    "    x_end = int((x+w) * 0.85) # ความกว้าง 85% ของตาราง\n",
    "    x_split_half = int((x+w) * 0.38) # ความกว้าง 38% ของตาราง\n",
    "\n",
    "    student_info_img = binary_img[:y, :x_end]\n",
    "    student_info_fh_img = binary_img[:y, :x_split_half] # ครึ่งแรก\n",
    "    student_info_sh_img = binary_img[:y, x_split_half:x_end] # ครึ่งหลัง\n",
    "\n",
    "    return table_img, student_info_img, student_info_fh_img, student_info_sh_img, table_original_img\n",
    "\n",
    "def biggest_contour(contours):\n",
    "    biggest = np.array([])\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i)\n",
    "        #print(area)\n",
    "        if area > 1000:\n",
    "            #print(\"มา\")\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.02 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "\n",
    "    return biggest\n",
    "\n",
    "def persective_transformation(table_binary_img, table_original_img):\n",
    "\n",
    "    # ค้นหาคอนทัวร์\n",
    "    contours, hierarchy = cv2.findContours(table_binary_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #contours, hierarchy = cv2.findContours(table_binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "    # ค้นหาสี่เหลี่ยมที่ใหญ่ที่สุด\n",
    "    biggest = biggest_contour(contours)\n",
    "\n",
    "    points = biggest.reshape(4, 2)\n",
    "    input_points = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "    points_sum = points.sum(axis=1)\n",
    "    input_points[0] = points[np.argmin(points_sum)]\n",
    "    input_points[3] = points[np.argmax(points_sum)]\n",
    "\n",
    "    points_diff = np.diff(points, axis=1)\n",
    "    input_points[1] = points[np.argmin(points_diff)]\n",
    "    input_points[2] = points[np.argmax(points_diff)]\n",
    "\n",
    "    (top_left, top_right, bottom_right, bottom_left) = input_points\n",
    "\n",
    "    # Euclidean Distance Formula\n",
    "    bottom_width = np.sqrt(((bottom_right[0] - bottom_left[0]) ** 2) + ((bottom_right[1] - bottom_left[1]) ** 2))\n",
    "    top_width = np.sqrt(((top_right[0] - top_left[0]) ** 2) + ((top_right[1] - top_left[1]) ** 2))\n",
    "    rigth_height = np.sqrt(((top_left[0] - bottom_right[0]) ** 2) + ((top_left[1] - bottom_right[1]) ** 2))\n",
    "    left_height = np.sqrt(((top_left[0] - bottom_left[0]) ** 2) + ((top_left[1] - bottom_left[1]) ** 2))\n",
    "\n",
    "    # Output image size\n",
    "    #max_width = max(int(bottom_width), int(top_width))\n",
    "    expand_width = round(max(int(bottom_width), int(top_width)) * 0.4)\n",
    "    max_width = max(int(bottom_width), int(top_width)) + expand_width\n",
    "    max_height = max(int(rigth_height), int(left_height))\n",
    "\n",
    "    # Desird points values in the output image\n",
    "    converted_points = np.float32([[0, 0], [max_width, 0], [0, max_height], [max_width, max_height]])\n",
    "\n",
    "    # Perspective transformaxtion\n",
    "    matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "    img_out = cv2.warpPerspective(table_binary_img.copy(), matrix, (max_width, max_height))\n",
    "    img_original_out = cv2.warpPerspective(table_original_img.copy(), matrix, (max_width, max_height))\n",
    "\n",
    "    return img_out, img_original_out\n",
    "\n",
    "def hough_line_transform(binary_image, table_original_persective_img, grid_img):\n",
    "\n",
    "    # 1) ใช้ HoughLinesP ตรวจจับเส้น\n",
    "    #    - พารามิเตอร์ที่สำคัญ: threshold, minLineLength, maxLineGap\n",
    "    lines = cv2.HoughLinesP(\n",
    "        binary_image,\n",
    "        rho=1,\n",
    "        theta=np.pi/180,\n",
    "        threshold=100,      # ต้องปรับจูน\n",
    "        minLineLength=700,  # ต้องปรับจูน\n",
    "        maxLineGap=10     # ต้องปรับจูน\n",
    "    )\n",
    "\n",
    "    # 2) สร้าง mask (เป็นภาพดำล้วน ขนาดเท่ากับต้นฉบับ)\n",
    "    line_mask = np.zeros_like(binary_image)\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            # วาดเส้นสีขาวลงใน mask (ปรับ thickness ตามความหนาเส้นในภาพ)\n",
    "            cv2.line(line_mask, (x1, y1), (x2, y2), 255, 2)\n",
    "\n",
    "    # 4) เราจะเอา mask นี้มาช่วยลบเส้นในภาพ\n",
    "    #    วิธีง่าย ๆ คือการเอา thresh ที่เป็น binary_inv มาลบด้วย mask (bitwise)\n",
    "    #    หรืออาจใช้เทคนิค inpaint บนภาพสี\n",
    "\n",
    "    # วิธีที่ 4.1: ลบตรง ๆ จาก thresh ก่อน (ซึ่งเป็น Binary แล้ว)\n",
    "    table_without_lines = cv2.bitwise_and(binary_image, cv2.bitwise_not(line_mask))\n",
    "    table_without_lines_2 = cv2.bitwise_and(table_without_lines, cv2.bitwise_not(grid_img))\n",
    "\n",
    "\n",
    "    # หรือ วิธีที่ 4.2: ลอง inpaint บนภาพจริงสี (img)\n",
    "    #    โดยปกติ inpaint จะต้องการ mask สีขาว บริเวณที่ต้องการซ่อมแซม\n",
    "    #    ซึ่ง line_mask ของเราพอดีอยู่แล้ว\n",
    "    inpainted = cv2.inpaint(table_original_persective_img, line_mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    #kernel = np.ones((20, 15), np.uint8)\n",
    "    #final_dilate = cv2.dilate(image_without_lines, kernel, iterations=1)\n",
    "\n",
    "\n",
    "    # เนื่องจาก thresh เป็น invert (พื้นดำ ตัวหนังสือขาว)\n",
    "    # ถ้าอยากกลับด้านให้พื้นขาว ตัวหนังสือดำก็ทำ bitwise_not อีกที\n",
    "    #final = cv2.bitwise_not(image_without_lines)\n",
    "    cv2.imwrite(f\"{output_folder}/line_mask.png\", line_mask)\n",
    "    cv2.imwrite(f\"{output_folder}/image_without_lines.png\", table_without_lines)\n",
    "    cv2.imwrite(f\"{output_folder}/image_without_lines_2.png\", table_without_lines_2)\n",
    "    #cv2.imwrite(f\"{output_folder}/final_dilate.png\", final_dilate)\n",
    "    cv2.imwrite(f\"{output_folder}/inpainted.png\", inpainted)\n",
    "\n",
    "    return line_mask, table_without_lines, table_without_lines_2\n",
    "\n",
    "def cells_detect(grid_lines):\n",
    "    # ขั้นตอนที่ 1: Invert ภาพ\n",
    "    inverted = cv2.bitwise_not(grid_lines) # (เพื่อให้พื้นที่ดำ (ช่องตาราง) กลายเป็นสีขาว, ส่วนเส้นขาวจะเป็นสีดำ)\n",
    "\n",
    "    # ขั้นตอนที่ 2: Erode พื้นที่ขาวเล็กน้อย เพื่อลดการติดเส้น\n",
    "    kernel = np.ones((3, 3), np.uint8) # สร้าง kernel เล็ก ๆ เพื่อ erode\n",
    "    eroded = cv2.erode(inverted, kernel, iterations=0)\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/eroded.png\", eroded)\n",
    "\n",
    "    # ขั้นตอนที่ 3: Find Contours (หาพื้นที่สีขาว ซึ่งเป็นรูปทรงของช่องตาราง)\n",
    "    #contours, hierarchy = cv2.findContours(eroded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours, hierarchy = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_contours = filter(lambda c: cv2.boundingRect(c)[2] > 40, contours)  # กรอง w > 10\n",
    "    contours = sorted(filtered_contours, key=lambda c: cv2.boundingRect(c)[3], reverse=True)[:10] # เรียงลำดับ contours ตามค่า h (ความสูง) จากมากไปน้อย\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0], reverse=False)  # เรียงลำดับ contours ตามค่า x จากน้อยไปมาก\n",
    " \n",
    "    # ขั้นตอนที่ 4: วนลูปดูผลลัพธ์ของ Contours แต่ละอัน\n",
    "\n",
    "    output = cv2.cvtColor(grid_lines.copy(), cv2.COLOR_GRAY2BGR)  # ไว้สำหรับวาดกรอบ\n",
    "\n",
    "    cell_contours = []\n",
    "\n",
    "    for i, cnt in enumerate(contours):\n",
    "        # หา bounding box ของ contour\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = int(cv2.contourArea(cnt))\n",
    "        cell_contours.append([x, y, w, h, area])\n",
    "\n",
    "        # วาดสี่เหลี่ยมครอบลงบน output เพื่อดู\n",
    "        cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "        print(f\"Contour #{i}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/Contours.png\", output)\n",
    "\n",
    "    return cell_contours\n",
    "\n",
    "def create_grid_image(table_img,\n",
    "                      col_percentages=[8, 40, 43, 46.33, 50, 58, 90, 93, 96.33, 100],\n",
    "                      #col_percentages=[8, 39, 43, 46.33, 50, 58, 89, 93, 96.33, 100],\n",
    "                      row_percentages=[9.22, 100],\n",
    "                      grid_color=(255, 255, 255),\n",
    "                      vertical_line_thickness_percent=0.005,   # 0.33% ของความกว้างภาพสำหรับเส้นแนวตั้ง\n",
    "                      horizontal_line_thickness_percent=0.008, # 0.33% ของความกว้างภาพสำหรับเส้นแนวนอน\n",
    "                      bg_color=(0, 0, 0),\n",
    "                      return_binary=True,\n",
    "                      threshold_val=127):\n",
    "    \n",
    "    \"\"\"\n",
    "    สร้างภาพตารางที่มีขนาด width x height โดยแบ่งคอลัมน์และแถวตามเปอร์เซ็นต์ที่กำหนด\n",
    "    ความหนาของเส้นจะถูกคำนวณเป็นเปอร์เซ็นต์ของความกว้างของภาพ\n",
    "    ถ้า return_binary=True จะทำการแปลงภาพเป็น binary (ขาวดำ) โดยใช้ threshold ที่กำหนด\n",
    "\n",
    "    :param width: ความกว้างของภาพ (พิกเซล)\n",
    "    :param height: ความสูงของภาพ (พิกเซล)\n",
    "    :param col_percentages: รายการเปอร์เซ็นต์สำหรับขอบขวาของแต่ละคอลัมน์ (เรียงจากน้อยไปมาก; คอลัมน์สุดท้าย = 100%)\n",
    "    :param row_percentages: รายการเปอร์เซ็นต์สำหรับขอบล่างของแต่ละแถว (เรียงจากน้อยไปมาก; แถวสุดท้าย = 100%)\n",
    "    :param grid_color: สีของเส้นตารางในรูปแบบ (B, G, R)\n",
    "    :param line_thickness_percent: ความหนาของเส้นในรูปแบบเปอร์เซ็นต์ของความกว้างภาพ\n",
    "    :param bg_color: สีพื้นหลังของภาพ\n",
    "    :param return_binary: ถ้า True จะคืนภาพในรูปแบบ binary (หลัง threshold) มิฉะนั้นคืนค่าเป็น BGR image\n",
    "    :param threshold_val: ค่าที่ใช้ threshold เมื่อแปลงเป็นภาพ binary\n",
    "    :return: ภาพตารางในรูปแบบ binary (ถ้า return_binary=True) หรือ BGR image (ถ้า False)\n",
    "    \"\"\"\n",
    "\n",
    "    height, width, = table_img.shape  # ได้ค่า (สูง, กว้าง)\n",
    "\n",
    "    image = np.full((height, width, 3), bg_color, dtype=np.uint8)\n",
    "    \n",
    "    # คำนวณความหนาของเส้นสำหรับแต่ละแนว (อย่างน้อย 1 พิกเซล)\n",
    "    vertical_thickness = max(1, int(width * vertical_line_thickness_percent))\n",
    "    horizontal_thickness = max(1, int(width * horizontal_line_thickness_percent))\n",
    "    \n",
    "    # คำนวณตำแหน่งเส้นแนวตั้ง (x_positions)\n",
    "    col_fracs = [p / 100.0 for p in col_percentages]\n",
    "    x_positions = [0] + [int(width * p) for p in col_fracs]\n",
    "    \n",
    "    # คำนวณตำแหน่งเส้นแนวนอน (y_positions)\n",
    "    row_fracs = [p / 100.0 for p in row_percentages]\n",
    "    y_positions = [0] + [int(height * p) for p in row_fracs]\n",
    "    \n",
    "    # วาดเส้นตารางแนวตั้งโดยใช้ความหนาที่คำนวณสำหรับแนวตั้ง\n",
    "    for x in x_positions:\n",
    "        cv2.line(image, (x, 0), (x, height), grid_color, vertical_thickness)\n",
    "    \n",
    "    # วาดเส้นตารางแนวนอนโดยใช้ความหนาที่คำนวณสำหรับแนวนอน\n",
    "    for y in y_positions:\n",
    "        cv2.line(image, (0, y), (width, y), grid_color, horizontal_thickness)\n",
    "    \n",
    "    # แปลงภาพเป็น binary หากต้องการ\n",
    "    if return_binary:\n",
    "        # แปลงเป็น grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # ใช้ threshold เพื่อแปลงเป็นภาพ binary\n",
    "        _, binary_image = cv2.threshold(gray, threshold_val, 255, cv2.THRESH_BINARY)\n",
    "        return binary_image\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "table_img, student_info_img, student_info_fh_img, student_info_sh_img, table_original_img = split_grade_table_and_students(binary_gaussian, denoised)\n",
    "table_persective_img, table_original_persective_img = persective_transformation(binary_gaussian, denoised)\n",
    "grid_img = create_grid_image(table_persective_img)\n",
    "line_mask, table_without_lines, table_without_lines_2 = hough_line_transform(table_persective_img, table_original_persective_img, grid_img)\n",
    "\n",
    "cell_contours = cells_detect(grid_img)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/table_img.png\", table_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_img.png\", student_info_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_original_img.png\", table_original_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_persective_img.png\", table_persective_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_original_persective_img.png\", table_original_persective_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_fh_img.png\", student_info_fh_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_sh_img.png\", student_info_sh_img)\n",
    "cv2.imwrite(f\"{output_folder}/grid_img.png\", grid_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# แบ่งส่วนตาราง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(cell_contours, table_without_lines):\n",
    "    cell_images = []\n",
    "    for idx, cell_position in enumerate(cell_contours):\n",
    "        x, y, w, h, area = cell_position\n",
    "        crop_img = table_without_lines[y:y+h, x:x+w]\n",
    "        cell_images.append(crop_img)\n",
    "        cv2.imwrite(f\"{output_folder}/cell_images/crop_img_{idx}.png\", crop_img)\n",
    "        #print(f\"Contour #{idx}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "\n",
    "    return cell_images\n",
    "        \n",
    "cell_images = crop_image(cell_contours, table_without_lines_2)\n",
    "\n",
    "cell_subject_code_img = cell_images[0]\n",
    "cell_subject_name_img = cell_images[1]\n",
    "cell_credit_img = cell_images[2]\n",
    "cell_academic_results_img = cell_images[3]\n",
    "cell_subject_code_img_2 = cell_images[5]\n",
    "cell_subject_name_img_2 = cell_images[6]\n",
    "cell_credit_img_2 = cell_images[7]\n",
    "cell_academic_results_img_2 = cell_images[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_text_group_in_cell(cell_img, mode=0, calculate_line_stats=None):\n",
    "    text_group_images = []\n",
    "\n",
    "    kernel_open = np.ones((4, 4), np.uint8)\n",
    "    #kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    remove_noise = cv2.morphologyEx(cell_img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/cell_images/remove_noise.jpg\", remove_noise)\n",
    "\n",
    "    kernel = np.ones((3, 13), np.uint8)\n",
    "    group_text_img = cv2.dilate(remove_noise, kernel, iterations=2)\n",
    "    rgb_image = cv2.cvtColor(cell_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #plt.imshow(group_text, cmap=\"gray\")\n",
    "\n",
    "    if(mode == 1):\n",
    "        # ใช้ Connected Component Analysis\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(group_text_img, connectivity=8)\n",
    "\n",
    "        text_stats = stats[1:]\n",
    "        sorted_indices = np.argsort(text_stats[:, 1])  # จัดเรียงตามค่า y (คอลัมน์ที่ 1)\n",
    "        sorted_stats = text_stats[sorted_indices]\n",
    "\n",
    "        # ใช้ Boolean Indexing เพื่อเอา noise ออก \n",
    "        sorted_stats = sorted_stats[sorted_stats[:, 4] >= 2000]\n",
    "        calculate_line_stats = []\n",
    "\n",
    "        for idx_stat, stat in enumerate(sorted_stats):\n",
    "            x, y, w, h, area = stat\n",
    "            #print(f\"CCA #{idx_stat}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            if idx_stat == (len(sorted_stats)-1):\n",
    "                #print(\"เข้าเงื่อนลำดัยสุดท้าย\",idx_stat)\n",
    "                x, y, w, h, area = stat\n",
    "                new_y = round(y-(h/2))\n",
    "                new_h = round(h+(h*0.8))\n",
    "                calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "            else:\n",
    "                current_stat = stat\n",
    "                next_stat = sorted_stats[idx_stat+1]\n",
    "\n",
    "                distance = next_stat[1] - current_stat[1]\n",
    "                line_spacing = distance/current_stat[3]\n",
    "\n",
    "                if line_spacing > 3 and line_spacing <= 5: # เป็นชื่อวิชาที่มีความยาวมากกว่า 1 บรรทัด\n",
    "                    #print(\"เข้าเงื่อนไข มากกว่า 1 บรรทัด\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+(h*2.5))\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "\n",
    "                elif line_spacing > 6: # เป็นช่องว่างที่ไม่มีวิชา\n",
    "                    #print(\"เข้าเงื่อนไข เป็นช่องว่างที่ไม่มีวิชา\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+h)\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "                \n",
    "                else: # เป็นชื่อวิชาที่มีความยาวแค่ว่า 1 บรรทัด\n",
    "                    #print(\"เข้าเงื่อนไข 1 บรรทัด\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+(h*0.8))\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "\n",
    "        calculate_line_stats = np.array(calculate_line_stats) \n",
    "\n",
    "            #print(f\"CCA #{idx_stat}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            #cv2.rectangle(rgb_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        #cv2.imwrite(f\"{output_folder}/cell_images/cca.jpg\", rgb_image)\n",
    "\n",
    "    text_stats = sorted_stats if mode == 1 else calculate_line_stats\n",
    "\n",
    "    \n",
    "    for idx, stats in enumerate(text_stats): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "   \n",
    "        if mode == 1:\n",
    "            cca_img = cell_img[y:y+h, x:x+w]\n",
    "        if mode == 2:\n",
    "            #print(f\"stats #{idx}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            if idx == 0: # ดักบัค crop รูปเกินขอบเขต\n",
    "                cca_img = cell_img[y+5:y+h, :]\n",
    "            elif idx == (len(text_stats)-1):\n",
    "                cca_img = cell_img[y:y+h-5, :]\n",
    "            else:\n",
    "                cca_img = cell_img[y:y+h, :]\n",
    "        text_group_images.append(cca_img)\n",
    "\n",
    "        # หาขนาดของภาพ (ความกว้างและความสูง)\n",
    "        image_height, image_width, _ = rgb_image.shape  # ได้ค่า (สูง, กว้าง, ช่องสี)\n",
    "        cv2.rectangle(rgb_image, (x, y), (image_width, y + h), (0, 255, 0), 1)\n",
    "\n",
    "    if mode == 1:\n",
    "        return text_group_images, calculate_line_stats, rgb_image\n",
    "    else:\n",
    "        return text_group_images, rgb_image\n",
    "\n",
    "# ตารางครึ่งแรก\n",
    "text_subject_code_images, calculate_line_stats_1, subject_code_img = detect_text_group_in_cell(cell_subject_code_img, 1)\n",
    "text_subject_name_images, subject_name_img = detect_text_group_in_cell(cell_subject_name_img, 2, calculate_line_stats_1)\n",
    "text_credit_images, credit_img = detect_text_group_in_cell(cell_credit_img, 2, calculate_line_stats_1)\n",
    "text_academic_results_images, academic_results_img = detect_text_group_in_cell(cell_academic_results_img, 2, calculate_line_stats_1)\n",
    "\n",
    "# ตารางครึ่งหลัง\n",
    "text_subject_code_images_2, calculate_line_stats_2, subject_code_img_2 = detect_text_group_in_cell(cell_subject_code_img_2, 1)\n",
    "text_subject_name_images_2, subject_name_img_2 = detect_text_group_in_cell(cell_subject_name_img_2, 2, calculate_line_stats_2)\n",
    "text_credit_images_2, credit_img_2 = detect_text_group_in_cell(cell_credit_img_2, 2, calculate_line_stats_2)\n",
    "text_academic_results_images_2, academic_results_img_2 = detect_text_group_in_cell(cell_academic_results_img_2, 2, calculate_line_stats_2)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_code_img.jpg\", subject_code_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_name_img.jpg\", subject_name_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_credit_img.jpg\", credit_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_academic_results_img.jpg\", academic_results_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_code_img_2.jpg\", subject_code_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_name_img_2.jpg\", subject_name_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_credit_img_2.jpg\", credit_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_academic_results_img_2.jpg\", academic_results_img_2)\n",
    "#cv2.imwrite(f\"{output_folder}/cell_images/cca_text_subject_name_images.jpg\", subject_name_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(text_subject_code_images):\n",
    "    print(idx)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### จับข้อความย่อยในกลุ่มข้อความของ cell ตาราง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n"
     ]
    }
   ],
   "source": [
    "from numpy import append\n",
    "\n",
    "def detect_sub_text_in_group(binary_image):\n",
    "\n",
    "    text_group = []\n",
    "    for idx, img in enumerate(binary_image):\n",
    "        #print(idx+1)\n",
    "\n",
    "        #plt.figure(figsize=(5,5))\n",
    "        #plt.imshow(img, cmap=\"gray\")\n",
    "        #plt.title(f\"binary_image\")\n",
    "        #plt.show()\n",
    "\n",
    "        sub_text_images = []\n",
    "\n",
    "        kernel_open = np.ones((3, 3), np.uint8)\n",
    "        remove_noise = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "        #plt.figure(figsize=(5,5))\n",
    "        #plt.imshow(remove_noise, cmap=\"gray\")\n",
    "        #plt.title(f\"remove_noise\")\n",
    "        #plt.show()\n",
    "\n",
    "        # เช็คว่าภาพเป็นสีดำทั้งหมดหรือไม่\n",
    "        if not np.any(remove_noise):  # ถ้าค่าพิกเซลทั้งหมดเป็น 0 (ดำสนิท)\n",
    "            print(\"ภาพเป็นสีดำทั้งหมด\")\n",
    "            sub_text_images.append(remove_noise)\n",
    "            #return sub_text_images \n",
    "        \n",
    "        else:\n",
    "            kernel = np.ones((6, 6), np.uint8)\n",
    "            dummy_image = cv2.dilate(remove_noise, kernel, iterations=2)\n",
    "\n",
    "            #plt.figure(figsize=(5,5))\n",
    "            #plt.imshow(dummy_image, cmap=\"gray\")\n",
    "            #plt.title(f\"dummy_image\")\n",
    "            #plt.show()\n",
    "\n",
    "            # ใช้ Connected Component Analysis\n",
    "            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dummy_image, connectivity=8)\n",
    "            char_stats = stats[1:] # ข้าม Background (index 0)\n",
    "            sorted_indices = np.argsort(char_stats[:, 0]) # จัดเรียงตามค่า x (คอลัมน์ที่ 0)\n",
    "            sorted_stats = char_stats[sorted_indices]\n",
    "\n",
    "            # ใช้ Boolean Indexing เพื่อเอา noise ออก \n",
    "            sorted_stats = sorted_stats[sorted_stats[:, 4] >= 200]\n",
    "\n",
    "            for idx, stats in enumerate(sorted_stats):\n",
    "                #x, y, w, h, area = stats[i]\n",
    "                x, y, w, h, area = stats\n",
    "\n",
    "                cca_img = img[y:y+h, x:x+w]\n",
    "                sub_text_images.append(cca_img)\n",
    "\n",
    "        text_group.append(sub_text_images)\n",
    "\n",
    "    return text_group\n",
    "    \n",
    "text_group_subject_code = detect_sub_text_in_group(text_subject_code_images)\n",
    "text_group_subject_name = detect_sub_text_in_group(text_subject_name_images)\n",
    "text_group_credit = detect_sub_text_in_group(text_credit_images)\n",
    "text_group_academic_results = detect_sub_text_in_group(text_academic_results_images)\n",
    "\n",
    "text_group_subject_code_2 = detect_sub_text_in_group(text_subject_code_images_2)\n",
    "text_group_subject_name_2 = detect_sub_text_in_group(text_subject_name_images_2)\n",
    "text_group_credit_2 = detect_sub_text_in_group(text_credit_images_2)\n",
    "text_group_academic_results_2 = detect_sub_text_in_group(text_academic_results_images_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx_g, text_group in enumerate(text_group_subject_code):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(sub_text, cmap=\"gray\")\n",
    "        plt.title(f\"sub text {idx_s+1}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## จับตัวอักษร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_difference(value1, value2):\n",
    "    return abs(value1 - value2) / value1 * 100\n",
    "\n",
    "def detect_one_level_of_char(text_group):\n",
    "    text_group_char = []\n",
    "    for idx_g, text_g in enumerate(text_group):\n",
    "\n",
    "        sub_text_char = []\n",
    "        for idx_s, sub_text in enumerate(text_g):\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(sub_text, cmap=\"gray\")\n",
    "            plt.title(f\"text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "            skeleton_guohall = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(skeleton_guohall, cmap=\"gray\")\n",
    "            plt.title(f\"skeleton, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "\n",
    "            #kernel_open = np.ones((2, 2), np.uint8)\n",
    "            kernel = np.ones((2, 2), np.uint8)\n",
    "            #opening = cv2.morphologyEx(skeleton, cv2.MORPH_OPEN, kernel=kernel_open, iterations=2)\n",
    "            #closing = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_open, iterations=2)\n",
    "            dummy_image = cv2.dilate(skeleton_guohall, kernel, iterations=1)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(dummy_image, cmap=\"gray\")\n",
    "            plt.title(f\"dummy_image, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            rgb_image = cv2.cvtColor(sub_text.copy(), cv2.COLOR_GRAY2RGB)\n",
    "            contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "\n",
    "            char_images = []\n",
    "            for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "                left_margin_percent   = 0.2   # ขยายด้านซ้าย 10% ของความกว้าง bounding box\n",
    "                right_margin_percent  = 0.0    # ขยายด้านขวา 10%\n",
    "                top_margin_percent    = 0.15    # ขยายด้านบน 10% ของความสูง bounding box\n",
    "                bottom_margin_percent = 0.1    # ขยายด้านล่าง 10%\n",
    "\n",
    "                # คำนวณ margin ในหน่วยพิกเซล\n",
    "                left_margin   = int(w * left_margin_percent)\n",
    "                right_margin  = int(w * right_margin_percent)\n",
    "                top_margin    = int(h * top_margin_percent)\n",
    "                bottom_margin = int(h * bottom_margin_percent)\n",
    "\n",
    "                # คำนวณตำแหน่ง bounding box ใหม่\n",
    "                new_x  = max(x - left_margin, 0)\n",
    "                new_y  = max(y - top_margin, 0)\n",
    "                img_height, img_width = sub_text.shape\n",
    "                new_x2 = min(x + w + right_margin, img_width)   # new_x2 คือพิกัดขวาสุดของกรอบ\n",
    "                new_y2 = min(y + h + bottom_margin, img_height)   # new_y2 คือพิกัดล่างสุดของกรอบ\n",
    "\n",
    "                cropped_img = sub_text[new_y:new_y2, new_x:new_x2]\n",
    "                char_images.append(cropped_img)\n",
    "\n",
    "                cv2.rectangle(rgb_image, (new_x, new_y), (new_x2, new_y2), (0, 255, 0), 1)\n",
    "                #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "            sub_text_char.append(char_images)\n",
    "            '''\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(rgb_image, cmap=\"gray\")\n",
    "            plt.title(f\"Contour, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "        text_group_char.append(sub_text_char)\n",
    "    return text_group_char\n",
    "\n",
    "text_group_char_subject_code = detect_one_level_of_char(text_group_subject_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_g, text_group in enumerate(text_group_char_subject_code):\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            continue\n",
    "            #print(idx_s)\n",
    "            '''\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(char, cmap=\"gray\")\n",
    "            plt.title(f\"char, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนาย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_subject_code_tn = \"../models/char_subject_code_tn_model.h5\"\n",
    "\n",
    "model_char_subject_code_tn = load_model(model_path_char_subject_code_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "ประมวลผลเสร็จสิ้น\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_subject_code_tn = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-',\n",
    "]\n",
    "\n",
    "class_char = char_subject_code_tn\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_one_level(text_group_char):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "    text_block = []\n",
    "\n",
    "    for idx_g, text_group in enumerate(text_group_char):\n",
    "        text_result = \"\"\n",
    "\n",
    "        for idx_s, sub_text in enumerate(text_group):\n",
    "            sub_text_result = \"\"\n",
    "\n",
    "            for idx_c, char in enumerate(sub_text):\n",
    "                if char is None:\n",
    "                    print(f\"Character image {idx_c} is None.\")\n",
    "                    continue  # ข้ามภาพนี้\n",
    "                else:\n",
    "                    # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                    padded_img = resize_with_min_padding(char, input_size, min_padding=1)\n",
    "\n",
    "                    # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                    normalized_img = padded_img / 255.0\n",
    "\n",
    "                    if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                        normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                        processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                        prediction = model_char_subject_code_tn.predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        predicted_letter = class_char[predicted_class]\n",
    "\n",
    "                        sub_text_result += predicted_letter\n",
    "\n",
    "            text_result += sub_text_result\n",
    "            text_result += \" \"\n",
    "        text_block.append(text_result)\n",
    "\n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_block   \n",
    "            \n",
    "\n",
    "text_box_subject_code = predict_text_one_level(text_group_char_subject_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_information(array):\n",
    "    for idx, data in enumerate(array):\n",
    "        print(f\"text {idx + 1}: {data}\")\n",
    "\n",
    "show_information(text_box_subject_code[:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
