{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "output_folder = Path(\"../data/output_images/output_V6_TN\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_1.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_3.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_4.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_5.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_6.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_7.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_8.png\") # ซ้ำกับ 7\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_9.png\") # จับตารางได้แต่พังตอน pt\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_10.png\") # ลบเส้นตารางไม่หมดตรงรหัสวิชา\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_11.png\") # ภาพใหญ่เกินไป\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_12.png\") # ตารางไม่ตรง\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_13.png\") # ติดลอยปั้มหมึก\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_14.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_15.png\")\n",
    "\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"ไม่พบไฟล์ภาพ กรุณาตรวจสอบเส้นทางของไฟล์\")\n",
    "\n",
    "new_size = (1660, 2347)  # ตัวอย่างขนาดใหม่\n",
    "resized_pil = image.resize(new_size, Image.LANCZOS) # ปรับขนาดภาพด้วย LANCZOS filter\n",
    "\n",
    "# แปลงภาพจาก PIL Image เป็น NumPy array (ในรูปแบบ RGB)\n",
    "img_rgb = np.array(resized_pil)\n",
    "\n",
    "# แปลงจาก RGB เป็น BGR เพื่อให้ใช้งานกับ OpenCV ได้\n",
    "img_cv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "denoised = cv2.bilateralFilter(img_cv, d=9, sigmaColor=75, sigmaSpace=75) # จำกัด noise\n",
    "gray_img = cv2.cvtColor(denoised, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "binary_gaussian = cv2.adaptiveThreshold(\n",
    "    gray_img, \n",
    "    maxValue=255, \n",
    "    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    thresholdType=cv2.THRESH_BINARY_INV, \n",
    "    blockSize=51, \n",
    "    C=15 #21\n",
    ")\n",
    "\n",
    "# สร้าง kernel สำหรับ morphological operation\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "dilated = cv2.dilate(binary_gaussian, kernel, iterations=1)\n",
    "# ใช้ closing เพื่อเติมเต็มส่วนที่ขาดของเส้น\n",
    "closed_dummy = cv2.morphologyEx(binary_gaussian, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/img_cv.png\", img_cv)\n",
    "cv2.imwrite(f\"{output_folder}/denoised.png\", denoised)\n",
    "cv2.imwrite(f\"{output_folder}/gray.png\", gray_img)\n",
    "cv2.imwrite(f\"{output_folder}/binary_g.png\", binary_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## แยกตารางเกรดกับข้อมูลนักศึกษา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_grade_table_and_students(binary_img, denoised, dummy):\n",
    "    \n",
    "    # แยกตาราง\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dummy, connectivity=8)\n",
    "    areas = [stat[4] for stat in stats]  # ดึงค่า area\n",
    "    sorted_areas = sorted(areas, reverse=True)  # เรียงลำดับจากมากไปน้อย\n",
    "    second_max_area = sorted_areas[1]  # ค่าอันดับ 2\n",
    "    second_max_area_index = areas.index(second_max_area)  # หาตำแหน่งในลิสต์เดิม\n",
    "    table_position = stats[second_max_area_index]\n",
    "    x, y, w, h, area = table_position\n",
    "\n",
    "    table_img = binary_img[y:y+h, x:x+w]\n",
    "    table_dummy_img = dummy[y:y+h, x:x+w]\n",
    "    table_original_img = denoised[y:y+h, x:x+w]\n",
    "\n",
    "    # ข้อมูลนักเรียน\n",
    "    #x_start = int((x+w) * 0.40) # ความกว้าง 40% ของตาราง\n",
    "    x_end = int((x+w) * 0.85) # ความกว้าง 85% ของตาราง\n",
    "    x_split_half = int((x+w) * 0.38) # ความกว้าง 38% ของตาราง\n",
    "\n",
    "    student_info_img = binary_img[:y, :x_end]\n",
    "    student_info_fh_img = binary_img[:y, :x_split_half] # ครึ่งแรก\n",
    "    student_info_sh_img = binary_img[:y, x_split_half:x_end] # ครึ่งหลัง\n",
    "\n",
    "    return table_img, table_dummy_img, table_original_img, student_info_img, student_info_fh_img, student_info_sh_img\n",
    "\n",
    "def biggest_contour(contours):\n",
    "    biggest = np.array([])\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i)\n",
    "        #print(area)\n",
    "        if area > 1000:\n",
    "            #print(\"มา\")\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.02 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "\n",
    "    return biggest\n",
    "\n",
    "def persective_transformation(table_binary_img, table_original_img, table_dummy_img):\n",
    "\n",
    "    # ค้นหาคอนทัวร์\n",
    "    contours, hierarchy = cv2.findContours(table_dummy_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #contours, hierarchy = cv2.findContours(table_binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "    # ค้นหาสี่เหลี่ยมที่ใหญ่ที่สุด\n",
    "    biggest = biggest_contour(contours)\n",
    "\n",
    "    points = biggest.reshape(4, 2)\n",
    "    input_points = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "    points_sum = points.sum(axis=1)\n",
    "    input_points[0] = points[np.argmin(points_sum)]\n",
    "    input_points[3] = points[np.argmax(points_sum)]\n",
    "\n",
    "    points_diff = np.diff(points, axis=1)\n",
    "    input_points[1] = points[np.argmin(points_diff)]\n",
    "    input_points[2] = points[np.argmax(points_diff)]\n",
    "\n",
    "    (top_left, top_right, bottom_right, bottom_left) = input_points\n",
    "\n",
    "    # Euclidean Distance Formula\n",
    "    bottom_width = np.sqrt(((bottom_right[0] - bottom_left[0]) ** 2) + ((bottom_right[1] - bottom_left[1]) ** 2))\n",
    "    top_width = np.sqrt(((top_right[0] - top_left[0]) ** 2) + ((top_right[1] - top_left[1]) ** 2))\n",
    "    rigth_height = np.sqrt(((top_left[0] - bottom_right[0]) ** 2) + ((top_left[1] - bottom_right[1]) ** 2))\n",
    "    left_height = np.sqrt(((top_left[0] - bottom_left[0]) ** 2) + ((top_left[1] - bottom_left[1]) ** 2))\n",
    "\n",
    "    # Output image size\n",
    "    #max_width = max(int(bottom_width), int(top_width))\n",
    "    expand_width = round(max(int(bottom_width), int(top_width)) * 0.4)\n",
    "    max_width = max(int(bottom_width), int(top_width)) + expand_width\n",
    "    max_height = max(int(rigth_height), int(left_height))\n",
    "\n",
    "    # Desird points values in the output image\n",
    "    converted_points = np.float32([[0, 0], [max_width, 0], [0, max_height], [max_width, max_height]])\n",
    "\n",
    "    # Perspective transformaxtion\n",
    "    matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "    img_out = cv2.warpPerspective(table_binary_img.copy(), matrix, (max_width, max_height))\n",
    "    img_original_out = cv2.warpPerspective(table_original_img.copy(), matrix, (max_width, max_height))\n",
    "    img_dummy_out = cv2.warpPerspective(table_dummy_img.copy(), matrix, (max_width, max_height))\n",
    "\n",
    "    #return img_out, img_original_out\n",
    "    return img_out, img_original_out, img_dummy_out\n",
    "\n",
    "table_img, table_dummy_img, table_original_img, student_info_img, student_info_fh_img, student_info_sh_img = split_grade_table_and_students(binary_gaussian, denoised, dilated)\n",
    "table_persective_img, table_original_persective_img, table_dummy_persective_img = persective_transformation(binary_gaussian, denoised, dilated)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/table_img.png\", table_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_dummy_img.png\", table_dummy_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_original_img.png\", table_original_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_img.png\", student_info_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_fh_img.png\", student_info_fh_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_sh_img.png\", student_info_sh_img)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/table_persective_img.png\", table_persective_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_original_persective_img.png\", table_original_persective_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_dummy_persective_img.png\", table_dummy_persective_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ตารางเกรด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ตำแหน่งของเส้นแถวที่ตรวจจับได้: [3, 188, 1987]\n",
      "ตำแหน่งของเส้นคอลัมน์ที่ตรวจจับได้: [3, 172, 822, 903, 976, 1051, 1221, 1870, 1951, 2025, 2098]\n"
     ]
    }
   ],
   "source": [
    "# ฟังก์ชันสำหรับรวมกลุ่ม indices ที่ติดกันเข้าด้วยกัน\n",
    "def group_indices(indices, gap=1):\n",
    "    groups = []\n",
    "    if not indices:\n",
    "        return groups\n",
    "    current = [indices[0]]\n",
    "    for idx in indices[1:]:\n",
    "        if idx - current[-1] <= gap:\n",
    "            current.append(idx)\n",
    "        else:\n",
    "            groups.append(current)\n",
    "            current = [idx]\n",
    "    groups.append(current)\n",
    "    return groups\n",
    "\n",
    "def find_table_columns_rows(table_dummy_persective_img, table_persective_img):\n",
    "\n",
    "    # คำนวณ horizontal projection (ผลรวมของ pixel ในแต่ละแถว)\n",
    "    horizontal_proj = np.sum(table_dummy_persective_img, axis=1)\n",
    "    vertical_proj = np.sum(table_dummy_persective_img, axis=0)\n",
    "\n",
    "    # ตั้ง threshold สำหรับเลือกเฉพาะลอลัมที่มี \"เส้น\"\n",
    "    horizontal_line_threshold = np.max(horizontal_proj) * 0.8\n",
    "    vertical_line_threshold = np.max(vertical_proj) * 0.7\n",
    "\n",
    "    # หา indices ของแถวที่มีค่า projection มากกว่าค่า threshold\n",
    "    row_line_indices = [i for i, value in enumerate(horizontal_proj) if value > horizontal_line_threshold]\n",
    "    col_line_indices = [i for i, value in enumerate(vertical_proj) if value > vertical_line_threshold]\n",
    "\n",
    "    # รวมกลุ่ม indices ที่ติดกัน\n",
    "    groups_row = group_indices(row_line_indices, gap=1)\n",
    "    groups_col = group_indices(col_line_indices, gap=1)\n",
    "\n",
    "    # สำหรับแต่ละกลุ่ม หา index กลางเป็นตำแหน่งของเส้น\n",
    "    # แต่แทนที่จะใช้ความหนาแน่น เราจะใช้ความยาวของแต่ละกลุ่ม (จำนวน index ในกลุ่ม)\n",
    "    groups_row_with_length = [(group, len(group)) for group in groups_row]\n",
    "    groups_col_with_length = [(group, len(group)) for group in groups_col]\n",
    "\n",
    "    # เรียงลำดับกลุ่มจากความยาวมากไปหาน้อย\n",
    "    groups_row_with_length.sort(key=lambda x: x[1], reverse=True)\n",
    "    groups_col_with_length.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # เลือกเฉพาะกลุ่มที่มีความยาวมากที่สุด\n",
    "    top_groups_row = groups_row_with_length[:3]\n",
    "    top_groups_col = groups_col_with_length[:11]\n",
    "\n",
    "    # คำนวณตำแหน่งเส้นโดยการหาค่าเฉลี่ยของแต่ละกลุ่ม แล้วเรียงลำดับ\n",
    "    row_lines = [int(np.mean(group)) for group, _ in top_groups_row]\n",
    "    col_lines = [int(np.mean(group)) for group, _ in top_groups_col]\n",
    "    row_lines.sort()\n",
    "    col_lines.sort()\n",
    "\n",
    "    print(\"ตำแหน่งของเส้นแถวที่ตรวจจับได้:\", row_lines)\n",
    "    print(\"ตำแหน่งของเส้นคอลัมน์ที่ตรวจจับได้:\", col_lines)\n",
    "\n",
    "    mask_row = np.zeros_like(table_dummy_persective_img)\n",
    "    mask_col = np.zeros_like(table_dummy_persective_img)\n",
    "\n",
    "    # วาดเส้นแถวลงใน mask (เส้นแนวนอน)\n",
    "    for y in row_lines:\n",
    "        cv2.line(mask_row, (0, y), (mask_row.shape[1]-1, y), 255, thickness=10)\n",
    "    cv2.imwrite(f\"{output_folder}/table/row_lines_mask.png\", mask_row)\n",
    "\n",
    "    # วาดเส้นคอลัมน์ลงใน mask (เส้นแนวตั้ง)\n",
    "    for x in col_lines:\n",
    "        cv2.line(mask_col, (x, 0), (x, mask_col.shape[0]-1), 255, thickness=10)\n",
    "    cv2.imwrite(f\"{output_folder}/table/col_lines_mask.png\", mask_col)\n",
    "\n",
    "    # --- ใช้ cv2.bitwise_and เพื่อลบเส้นแถวออกจากภาพ ---\n",
    "    mask_row_inv = cv2.bitwise_not(mask_row)\n",
    "    img_no_lines_row = cv2.bitwise_and(table_persective_img, table_persective_img, mask=mask_row_inv)\n",
    "    cv2.imwrite(f\"{output_folder}/table/table_no_lines_bitwise_row.png\", img_no_lines_row)\n",
    "\n",
    "    # --- ใช้ cv2.bitwise_and เพื่อลบเส้นแนวตั้งออกจากภาพ ---\n",
    "    mask_col_inv = cv2.bitwise_not(mask_col)\n",
    "    img_no_lines_col = cv2.bitwise_and(table_persective_img, table_persective_img, mask=mask_col_inv)\n",
    "    cv2.imwrite(f\"{output_folder}/table/table_no_lines_bitwise_col.png\", img_no_lines_col)\n",
    "\n",
    "    # --- ใช้ cv2.bitwise_and เพื่อลบเส้นแนวตั้งและแนวนอนออกจากภาพ ---\n",
    "    combined_mask = cv2.bitwise_or(mask_row, mask_col)\n",
    "    combined_mask_inv = cv2.bitwise_not(combined_mask)\n",
    "    img_no_lines_row_col = cv2.bitwise_and(table_persective_img, table_persective_img, mask=combined_mask_inv)\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/table/img_no_lines_row_col.png\", img_no_lines_row_col)\n",
    "\n",
    "    cropped_col_segments = []\n",
    "\n",
    "    for i in range(len(col_lines) - 1):\n",
    "        x_start = col_lines[i]\n",
    "        x_end = col_lines[i+1]\n",
    "        y_start = row_lines[1]\n",
    "        y_end = row_lines[-1]\n",
    "        \n",
    "        cropped = img_no_lines_row_col[y_start:y_end, x_start:x_end]  # crop ทุกคอลัมน์ในช่วงแถวที่กำหนด\n",
    "        cropped_col_segments.append(cropped)\n",
    "        cv2.imwrite(f\"{output_folder}/table/cropped_segment_{i+1}.png\", cropped)\n",
    "\n",
    "    return cropped_col_segments\n",
    "\n",
    "cell_images = find_table_columns_rows(table_dummy_persective_img, table_persective_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_subject_code_img = cell_images[0]\n",
    "cell_subject_name_img = cell_images[1]\n",
    "cell_credit_img = cell_images[2]\n",
    "cell_academic_results_img = cell_images[3]\n",
    "cell_subject_code_img_2 = cell_images[5]\n",
    "cell_subject_name_img_2 = cell_images[6]\n",
    "cell_credit_img_2 = cell_images[7]\n",
    "cell_academic_results_img_2 = cell_images[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### จับกลุ่มข้อความของ cell ตาราง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_text_group_in_cell(cell_img, mode=0, calculate_line_stats=None):\n",
    "    text_group_images = []\n",
    "\n",
    "    kernel_open = np.ones((4, 4), np.uint8)\n",
    "    #kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    remove_noise = cv2.morphologyEx(cell_img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/cell_images/remove_noise.jpg\", remove_noise)\n",
    "\n",
    "    kernel = np.ones((3, 13), np.uint8)\n",
    "    group_text_img = cv2.dilate(remove_noise, kernel, iterations=2)\n",
    "    rgb_image = cv2.cvtColor(cell_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #plt.imshow(group_text, cmap=\"gray\")\n",
    "\n",
    "    if(mode == 1):\n",
    "        # ใช้ Connected Component Analysis\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(group_text_img, connectivity=8)\n",
    "\n",
    "        text_stats = stats[1:]\n",
    "        sorted_indices = np.argsort(text_stats[:, 1])  # จัดเรียงตามค่า y (คอลัมน์ที่ 1)\n",
    "        sorted_stats = text_stats[sorted_indices]\n",
    "\n",
    "        # ใช้ Boolean Indexing เพื่อเอา noise ออก \n",
    "        sorted_stats = sorted_stats[sorted_stats[:, 4] >= 2000]\n",
    "        calculate_line_stats = []\n",
    "\n",
    "        for idx_stat, stat in enumerate(sorted_stats):\n",
    "            x, y, w, h, area = stat\n",
    "            #print(f\"CCA #{idx_stat}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            if idx_stat == (len(sorted_stats)-1):\n",
    "                #print(\"เข้าเงื่อนลำดัยสุดท้าย\",idx_stat)\n",
    "                x, y, w, h, area = stat\n",
    "                new_y = round(y-(h/2))\n",
    "                new_h = round(h+(h*0.8))\n",
    "                calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "            else:\n",
    "                current_stat = stat\n",
    "                next_stat = sorted_stats[idx_stat+1]\n",
    "\n",
    "                distance = next_stat[1] - current_stat[1]\n",
    "                line_spacing = distance/current_stat[3]\n",
    "\n",
    "                if line_spacing > 3 and line_spacing <= 5: # เป็นชื่อวิชาที่มีความยาวมากกว่า 1 บรรทัด\n",
    "                    #print(\"เข้าเงื่อนไข มากกว่า 1 บรรทัด\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+(h*2.5))\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "\n",
    "                elif line_spacing > 6: # เป็นช่องว่างที่ไม่มีวิชา\n",
    "                    #print(\"เข้าเงื่อนไข เป็นช่องว่างที่ไม่มีวิชา\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+h)\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "                \n",
    "                else: # เป็นชื่อวิชาที่มีความยาวแค่ว่า 1 บรรทัด\n",
    "                    #print(\"เข้าเงื่อนไข 1 บรรทัด\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+(h*0.8))\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "\n",
    "        calculate_line_stats = np.array(calculate_line_stats) \n",
    "\n",
    "            #print(f\"CCA #{idx_stat}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            #cv2.rectangle(rgb_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        #cv2.imwrite(f\"{output_folder}/cell_images/cca.jpg\", rgb_image)\n",
    "\n",
    "    text_stats = sorted_stats if mode == 1 else calculate_line_stats\n",
    "\n",
    "    \n",
    "    for idx, stats in enumerate(text_stats): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "   \n",
    "        if mode == 1:\n",
    "            cca_img = cell_img[y:y+h, x:x+w]\n",
    "        if mode == 2:\n",
    "            #print(f\"stats #{idx}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            if idx == 0: # ดักบัค crop รูปเกินขอบเขต\n",
    "                cca_img = cell_img[y+5:y+h, :]\n",
    "            elif idx == (len(text_stats)-1):\n",
    "                cca_img = cell_img[y:y+h-5, :]\n",
    "            else:\n",
    "                cca_img = cell_img[y:y+h, :]\n",
    "        text_group_images.append(cca_img)\n",
    "\n",
    "        # หาขนาดของภาพ (ความกว้างและความสูง)\n",
    "        image_height, image_width, _ = rgb_image.shape  # ได้ค่า (สูง, กว้าง, ช่องสี)\n",
    "        cv2.rectangle(rgb_image, (x, y), (image_width, y + h), (0, 255, 0), 1)\n",
    "\n",
    "    if mode == 1:\n",
    "        return text_group_images, calculate_line_stats, rgb_image\n",
    "    else:\n",
    "        return text_group_images, rgb_image\n",
    "\n",
    "# ตารางครึ่งแรก\n",
    "text_subject_code_images, calculate_line_stats_1, subject_code_img = detect_text_group_in_cell(cell_subject_code_img, 1)\n",
    "text_subject_name_images, subject_name_img = detect_text_group_in_cell(cell_subject_name_img, 2, calculate_line_stats_1)\n",
    "text_credit_images, credit_img = detect_text_group_in_cell(cell_credit_img, 2, calculate_line_stats_1)\n",
    "text_academic_results_images, academic_results_img = detect_text_group_in_cell(cell_academic_results_img, 2, calculate_line_stats_1)\n",
    "\n",
    "# ตารางครึ่งหลัง\n",
    "text_subject_code_images_2, calculate_line_stats_2, subject_code_img_2 = detect_text_group_in_cell(cell_subject_code_img_2, 1)\n",
    "text_subject_name_images_2, subject_name_img_2 = detect_text_group_in_cell(cell_subject_name_img_2, 2, calculate_line_stats_2)\n",
    "text_credit_images_2, credit_img_2 = detect_text_group_in_cell(cell_credit_img_2, 2, calculate_line_stats_2)\n",
    "text_academic_results_images_2, academic_results_img_2 = detect_text_group_in_cell(cell_academic_results_img_2, 2, calculate_line_stats_2)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_code_img.jpg\", subject_code_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_name_img.jpg\", subject_name_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_credit_img.jpg\", credit_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_academic_results_img.jpg\", academic_results_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_code_img_2.jpg\", subject_code_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_name_img_2.jpg\", subject_name_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_credit_img_2.jpg\", credit_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_academic_results_img_2.jpg\", academic_results_img_2)\n",
    "#cv2.imwrite(f\"{output_folder}/cell_images/cca_text_subject_name_images.jpg\", subject_name_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(text_subject_code_images):\n",
    "    print(idx)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### จับข้อความย่อยในกลุ่มข้อความของ cell ตาราง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def detect_sub_text_in_group(binary_image):\n",
    "\n",
    "    text_group = []\n",
    "    for idx, img in enumerate(binary_image):\n",
    "        #print(idx+1)\n",
    "\n",
    "        #plt.figure(figsize=(5,5))\n",
    "        #plt.imshow(img, cmap=\"gray\")\n",
    "        #plt.title(f\"binary_image\")\n",
    "        #plt.show()\n",
    "\n",
    "        sub_text_images = []\n",
    "\n",
    "        kernel_open = np.ones((3, 3), np.uint8)\n",
    "        remove_noise = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "        #plt.figure(figsize=(5,5))\n",
    "        #plt.imshow(remove_noise, cmap=\"gray\")\n",
    "        #plt.title(f\"remove_noise\")\n",
    "        #plt.show()\n",
    "\n",
    "        # เช็คว่าภาพเป็นสีดำทั้งหมดหรือไม่\n",
    "        if not np.any(remove_noise):  # ถ้าค่าพิกเซลทั้งหมดเป็น 0 (ดำสนิท)\n",
    "            print(\"ภาพเป็นสีดำทั้งหมด\")\n",
    "            sub_text_images.append(remove_noise)\n",
    "            #return sub_text_images \n",
    "        \n",
    "        else:\n",
    "            kernel = np.ones((6, 6), np.uint8)\n",
    "            dummy_image = cv2.dilate(remove_noise, kernel, iterations=2)\n",
    "\n",
    "            #plt.figure(figsize=(5,5))\n",
    "            #plt.imshow(dummy_image, cmap=\"gray\")\n",
    "            #plt.title(f\"dummy_image\")\n",
    "            #plt.show()\n",
    "\n",
    "            # ใช้ Connected Component Analysis\n",
    "            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dummy_image, connectivity=8)\n",
    "            char_stats = stats[1:] # ข้าม Background (index 0)\n",
    "            sorted_indices = np.argsort(char_stats[:, 0]) # จัดเรียงตามค่า x (คอลัมน์ที่ 0)\n",
    "            sorted_stats = char_stats[sorted_indices]\n",
    "\n",
    "            # ใช้ Boolean Indexing เพื่อเอา noise ออก \n",
    "            sorted_stats = sorted_stats[sorted_stats[:, 4] >= 200]\n",
    "\n",
    "            for idx, stats in enumerate(sorted_stats):\n",
    "                #x, y, w, h, area = stats[i]\n",
    "                x, y, w, h, area = stats\n",
    "\n",
    "                cca_img = img[y:y+h, x:x+w]\n",
    "                sub_text_images.append(cca_img)\n",
    "\n",
    "        text_group.append(sub_text_images)\n",
    "\n",
    "    return text_group\n",
    "    \n",
    "text_group_subject_code = detect_sub_text_in_group(text_subject_code_images)\n",
    "text_group_subject_name = detect_sub_text_in_group(text_subject_name_images)\n",
    "text_group_credit = detect_sub_text_in_group(text_credit_images)\n",
    "text_group_academic_results = detect_sub_text_in_group(text_academic_results_images)\n",
    "\n",
    "text_group_subject_code_2 = detect_sub_text_in_group(text_subject_code_images_2)\n",
    "text_group_subject_name_2 = detect_sub_text_in_group(text_subject_name_images_2)\n",
    "text_group_credit_2 = detect_sub_text_in_group(text_credit_images_2)\n",
    "text_group_academic_results_2 = detect_sub_text_in_group(text_academic_results_images_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx_g, text_group in enumerate(text_group_subject_code):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(sub_text, cmap=\"gray\")\n",
    "        plt.title(f\"sub text {idx_s+1}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## จับตัวอักษร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_contour(contour, scale_factor=1.1):\n",
    "    # คำนวณ centroid ของ contour\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] == 0:\n",
    "        return contour\n",
    "    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    # แปลง contour เป็น float32 เพื่อคำนวณ\n",
    "    scaled_contour = contour.astype(np.float32)\n",
    "    for i in range(scaled_contour.shape[0]):\n",
    "        x, y = scaled_contour[i, 0]\n",
    "        # ปรับขนาดแต่ละจุดโดยคำนวณจาก centroid\n",
    "        scaled_x = cx + (x - cx) * scale_factor\n",
    "        scaled_y = cy + (y - cy) * scale_factor\n",
    "        scaled_contour[i, 0] = [scaled_x, scaled_y]\n",
    "    \n",
    "    return scaled_contour.astype(np.int32)\n",
    "\n",
    "def percentage_difference(value1, value2):\n",
    "    return abs(value1 - value2) / value1 * 100\n",
    "\n",
    "def get_centroid(contour):\n",
    "    # คำนวณ moments ของ contour\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = M[\"m10\"] / M[\"m00\"]\n",
    "        cy = M[\"m01\"] / M[\"m00\"]\n",
    "    else:\n",
    "        cx, cy = 0, 0\n",
    "    return (cx, cy)\n",
    "\n",
    "def detect_one_level_of_char(text_group):\n",
    "    debug = False\n",
    "    text_group_char = []\n",
    "    for idx_g, text_g in enumerate(text_group):\n",
    "\n",
    "        sub_text_char = []\n",
    "        for idx_s, sub_text in enumerate(text_g):\n",
    "\n",
    "            if not np.any(sub_text): # เช็คว่าเป็นภาพว่างรึเปล่า\n",
    "\n",
    "                print(\"ภาพว่างเปล่า\")\n",
    "                sub_text_char.append([sub_text])\n",
    "                \n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.imshow(sub_text, cmap=\"gray\")\n",
    "                plt.title(f\"text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "                plt.show()\n",
    "                continue\n",
    "\n",
    "            if debug == True:\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.imshow(sub_text, cmap=\"gray\")\n",
    "                plt.title(f\"text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "                plt.show()\n",
    "            \n",
    "            \n",
    "            #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "            skeleton_guohall = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "            if debug == True:\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.imshow(skeleton_guohall, cmap=\"gray\")\n",
    "                plt.title(f\"skeleton, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "                plt.show()\n",
    "            \n",
    "            \n",
    "            #kernel_open = np.ones((2, 2), np.uint8)\n",
    "            kernel_dummy = np.ones((2, 2), np.uint8)\n",
    "            #opening = cv2.morphologyEx(skeleton, cv2.MORPH_OPEN, kernel=kernel_open, iterations=2)\n",
    "            #closing = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_open, iterations=2)\n",
    "            dummy_image = cv2.dilate(skeleton_guohall, kernel_dummy, iterations=1)\n",
    "\n",
    "            if debug == True:\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.imshow(dummy_image, cmap=\"gray\")\n",
    "                plt.title(f\"dummy_image, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "                plt.show()\n",
    "            \n",
    "            \n",
    "            rgb_image = cv2.cvtColor(sub_text.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "\n",
    "            char_images = []\n",
    "            for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "                mask = np.zeros(sub_text.shape[:2], dtype=np.uint8)\n",
    "                cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "\n",
    "                kernel_mask = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # ปรับขนาด kernel ตามต้องการ\n",
    "                dilated_mask = cv2.dilate(mask, kernel_mask, iterations=1)\n",
    "\n",
    "                # ใช้ mask กับภาพต้นฉบับ เพื่อดึงเฉพาะส่วนภายใน contour\n",
    "                char_result = cv2.bitwise_and(sub_text, sub_text, mask=dilated_mask)\n",
    "\n",
    "                contours_char, hierarchy_char = cv2.findContours(char_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                largest_contour = max(contours_char, key=cv2.contourArea)\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "                area = int(cv2.contourArea(largest_contour))\n",
    "                crop_img = char_result[y:y+h, x:x+w]\n",
    "                char_images.append(crop_img)\n",
    "                \n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"crop_img, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                    plt.show()\n",
    "                #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "            sub_text_char.append(char_images)\n",
    "        text_group_char.append(sub_text_char)\n",
    "    return text_group_char\n",
    "\n",
    "def char_level(char_images):\n",
    "    debug = False\n",
    "\n",
    "    char_box = []\n",
    "    \n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(char_images, cmap=\"gray\")\n",
    "        plt.title(f\"char\")\n",
    "        plt.show()\n",
    "    \n",
    "    skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "    #skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "\n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(skeleton, cmap=\"gray\")\n",
    "        plt.title(f\"skeleton\")\n",
    "        plt.show()\n",
    "    \n",
    "    kernel_dummy = np.ones((3, 3), np.uint8)\n",
    "    closing_skeleton = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "    dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "    closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(closing_skeleton, cmap=\"gray\")\n",
    "    plt.title(f\"closing_skeleton\")\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(dummy_image, cmap=\"gray\")\n",
    "        plt.title(f\"dummy_image\")\n",
    "        plt.show()\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # เรียง contours ตามค่า y ของ centroid จากน้อยไปหามาก\n",
    "    sorted_contours = sorted(contours, key=lambda cnt: get_centroid(cnt)[1], reverse=True)\n",
    "\n",
    "    # คำนวณพื้นที่ของ contour แต่ละตัว และหาพื้นที่ที่ใหญ่ที่สุด\n",
    "    max_area = max(cv2.contourArea(cnt) for cnt in sorted_contours)\n",
    "\n",
    "    # กำหนด threshold เป็น 5% ของพื้นที่ที่ใหญ่ที่สุด\n",
    "    min_area_threshold = max_area * 0.05\n",
    "\n",
    "    # กรอง contours ที่มีพื้นที่ไม่น้อยกว่า threshold\n",
    "    filtered_contours = [cnt for cnt in sorted_contours if cv2.contourArea(cnt) >= min_area_threshold]\n",
    "\n",
    "    # หาก filtered_contours มีแค่ 2 ตัว\n",
    "    if len(filtered_contours) == 2:\n",
    "\n",
    "        area0 = cv2.contourArea(filtered_contours[0])\n",
    "        area1 = cv2.contourArea(filtered_contours[1])\n",
    "        # คำนวณความแตกต่างเป็นอัตราส่วนของ contour ที่มีพื้นที่ใหญ่กว่า\n",
    "        diff_ratio = abs(area0 - area1) / max(area0, area1)\n",
    "        if diff_ratio <= 0.10:\n",
    "            print(\"เหมือนกัน\")\n",
    "\n",
    "            kernel_same = np.ones((4, 4), np.uint8)\n",
    "            dilated_same = cv2.dilate(char_images, kernel_same, iterations=2)\n",
    "            contours, hierarchy = cv2.findContours(dilated_same, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(closing_same, cmap=\"gray\")\n",
    "            plt.title(f\"closing_same\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            level = 1\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            contour_area = int(cv2.contourArea(largest_contour))\n",
    "            crop_img = char_images[y:y+h, x:x+w]\n",
    "            char_box.append([crop_img, level])\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"Level : {level} area: {contour_area}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            return char_box\n",
    "    elif len(filtered_contours) >= 3: # เอาไว้แก้ปัญหาพวกคำว่า \"ชั้น, บัน\" หรือทุกคำที่มี \"  ั \"\n",
    "        print(\"len(filtered_contours) >= 3\")\n",
    "        # คำนวณ centroid และพื้นที่ของแต่ละ contour ใน filtered_contours\n",
    "        centroids_filtered = [get_centroid(cnt) for cnt in filtered_contours]\n",
    "        areas_filtered = [cv2.contourArea(cnt) for cnt in filtered_contours]\n",
    "    \n",
    "        # หาตำแหน่งของ contour ที่มีพื้นที่มากที่สุด\n",
    "        max_area_idx = areas_filtered.index(max(areas_filtered))\n",
    "        max_centroid_y = centroids_filtered[max_area_idx][1]\n",
    "        max_area = areas_filtered[max_area_idx]\n",
    "    \n",
    "        # สร้าง list ใหม่เพื่อจัดกลุ่ม contour ที่จะอยู่ก่อนและหลัง\n",
    "        remain_contours = []\n",
    "        move_to_end = []\n",
    "\n",
    "        find_status = False\n",
    "        # วนลูปผ่านแต่ละ contour พร้อมกับ centroid และพื้นที่\n",
    "        for idx, (cnt, cent, area) in enumerate(zip(filtered_contours, centroids_filtered, areas_filtered)):\n",
    "            # ถ้าเป็น contour ที่มีพื้นที่มากที่สุด ให้เก็บไว้ใน remain_contours\n",
    "            if idx == max_area_idx:\n",
    "                remain_contours.append(cnt)\n",
    "            else:\n",
    "                # ตรวจสอบว่า centroid แกน y ของ contour นี้ต่างจาก max_centroid_y ไม่เกิน 20%\n",
    "                # และมีพื้นที่ไม่น้อยกว่า 30% ของ max_area\n",
    "                if abs(cent[1] - max_centroid_y) <= 0.2 * max_centroid_y and area >= 0.3 * max_area:\n",
    "                    print(\"มีอยู่หลังสุด\")\n",
    "                    move_to_end.append(cnt)\n",
    "                    find_status = True\n",
    "                else:\n",
    "                    remain_contours.append(cnt)\n",
    "        \n",
    "        # รวม list ที่เหลือเข้าด้วยกัน โดย contour ที่ตรงเงื่อนไขจะอยู่ท้ายสุด\n",
    "        filtered_contours = remain_contours + move_to_end\n",
    "\n",
    "        if find_status == True:\n",
    "            \n",
    "            # คำนวณพื้นที่และ centroid แกน x ของ contour ตัวแรกและตัวสุดท้าย\n",
    "            first_area = cv2.contourArea(filtered_contours[0])\n",
    "            last_area = cv2.contourArea(filtered_contours[-1])\n",
    "            first_centroid = get_centroid(filtered_contours[0])\n",
    "            last_centroid = get_centroid(filtered_contours[-1])\n",
    "\n",
    "            # ตรวจสอบเงื่อนไข ถ้า contour ตัวแรกมี area มากกว่าและ centroid_x มากกว่าตัวสุดท้าย\n",
    "            if first_area > last_area and first_centroid[0] > last_centroid[0]:\n",
    "                print(\"มีการสลับตัวแรกกับตัวสุดท้าย\")\n",
    "                # สลับตำแหน่ง contour ตัวแรกกับตัวสุดท้าย\n",
    "                filtered_contours[0], filtered_contours[-1] = filtered_contours[-1], filtered_contours[0]\n",
    "\n",
    "            # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "            for idx_c, cnt in enumerate(filtered_contours):\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = int(cv2.contourArea(cnt))\n",
    "                char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "            for idx, box in enumerate(char_box):\n",
    "                if idx == 0:\n",
    "                    box.append(1)\n",
    "                elif idx == (len(char_box)-1):\n",
    "                    box.append(1)\n",
    "                else:\n",
    "                    box.append(2)\n",
    "\n",
    "            char_level_images = []\n",
    "            for idx, box in enumerate(char_box):\n",
    "                x, y, w, h, area, level = box\n",
    "                crop_img = char_images[y:y+h, x:x+w]\n",
    "                char_level_images.append([crop_img, level])\n",
    "\n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"char : {idx+1} Level : {level} area: {area}\")\n",
    "                    plt.show()\n",
    "            return char_level_images\n",
    "\n",
    "        else:\n",
    "            # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "            for idx_c, cnt in enumerate(filtered_contours):\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = int(cv2.contourArea(cnt))\n",
    "                char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "            for idx, box in enumerate(char_box):\n",
    "                if idx == max_index:\n",
    "                    # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "                    box.append(1)\n",
    "                elif idx < max_index:\n",
    "                    # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "                    box.append(0)\n",
    "                #elif idx == (len(char_box)-1):\n",
    "                #    # ถ้าเป็น list append 1\n",
    "                #    box.append(1)\n",
    "                else:\n",
    "                    # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append 2\n",
    "                    box.append(2)\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "            if max_index != 0:\n",
    "                char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "            char_level_images = []\n",
    "            for idx, box in enumerate(char_box):\n",
    "                x, y, w, h, area, level = box\n",
    "                crop_img = char_images[y:y+h, x:x+w]\n",
    "                char_level_images.append([crop_img, level])\n",
    "\n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"char : {idx+1} Level : {level} area: {area}\")\n",
    "                    plt.show()\n",
    "        \n",
    "            return char_level_images\n",
    "\n",
    " #########################\n",
    "    # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "    for idx_c, cnt in enumerate(filtered_contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        contour_area = int(cv2.contourArea(cnt))\n",
    "        char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # สำหรับ list ที่อยู่หลัง list ที่มี area มากที่สุด เราจะเริ่มนับจาก 2\n",
    "    after_counter = 2\n",
    "\n",
    "    # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "    for idx, box in enumerate(char_box):\n",
    "        if idx == max_index:\n",
    "            # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "            box.append(1)\n",
    "        elif idx < max_index:\n",
    "            # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "            box.append(0)\n",
    "        else:\n",
    "            # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append sequential number เริ่มจาก 2\n",
    "            box.append(after_counter)\n",
    "            #after_counter += 1\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "    if max_index != 0:\n",
    "        char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(char_images, cmap=\"gray\")\n",
    "    plt.title(f\"char_images\")\n",
    "    plt.show()\n",
    "    '''\n",
    "        \n",
    "    char_level_images = []\n",
    "    for idx, box in enumerate(char_box):\n",
    "        x, y, w, h, area, level = box\n",
    "        crop_img = char_images[y:y+h, x:x+w]\n",
    "        char_level_images.append([crop_img, level])\n",
    "\n",
    "        if debug == True:\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"char : {idx+1} Leve : {level} area: {area}\")\n",
    "            plt.show()\n",
    "        \n",
    "    return char_level_images\n",
    "       \n",
    "def detect_char(text_group):\n",
    "    text_group_char = []\n",
    "    for idx_g, text_g in enumerate(text_group):\n",
    "\n",
    "        sub_text_char = []\n",
    "        for idx_s, sub_text in enumerate(text_g):\n",
    "            rgb_image = cv2.cvtColor(sub_text, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "            #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "            kernel_dummy = np.ones((3, 3), np.uint8)\n",
    "            dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "            kernel_closing = np.ones((7, 1), np.uint8)\n",
    "            closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_closing, iterations=1)\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "            \n",
    "            char_images_with_levels = []\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(sub_text, cmap=\"gray\")\n",
    "            plt.title(f\"text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(skeleton, cmap=\"gray\")\n",
    "            plt.title(f\"skeleton, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(dummy_image, cmap=\"gray\")\n",
    "            plt.title(f\"dummy_image, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(closing, cmap=\"gray\")\n",
    "            plt.title(f\"closing, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "                # สมมุติว่าเราได้ contour (cnt) จาก cv2.findContours แล้ว\n",
    "                #scaled_cnt = scale_contour(cnt, scale_factor=1.0)\n",
    "\n",
    "                #char_height, char_width = h, w\n",
    "                #mask = np.zeros((char_height, char_width), dtype=np.uint8)\n",
    "\n",
    "                mask = np.zeros(sub_text.shape[:2], dtype=np.uint8)\n",
    "\n",
    "                rgb_mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "                # วาด contour ลงใน mask โดยเติมเต็ม (thickness = -1) ให้ภายใน contour เป็นสีขาว (255)\n",
    "                cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "                kernel_mask = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # ปรับขนาด kernel ตามต้องการ\n",
    "                dilated_mask = cv2.dilate(mask, kernel_mask, iterations=1)\n",
    "\n",
    "                '''\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(mask, cmap=\"gray\")\n",
    "                plt.title(f\"mask, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(dilated_mask, cmap=\"gray\")\n",
    "                plt.title(f\"dilated_mask, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                # ใช้ mask กับภาพต้นฉบับ เพื่อดึงเฉพาะส่วนภายใน contour\n",
    "                char_result = cv2.bitwise_and(sub_text, sub_text, mask=dilated_mask)\n",
    "                char_images_with_levels.extend(char_level(char_result))\n",
    "                #print(\"cher_level_images :\", len(char_images_with_levels))\n",
    "\n",
    "                '''\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(char_result, cmap=\"gray\")\n",
    "                plt.title(f\"char_result, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                '''\n",
    "                for idx_c_l, cher_level in enumerate(cher_level_images):\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(cher_level[0], cmap=\"gray\")\n",
    "                    plt.title(f\"cnt, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c_l+1}, level:{cher_level[1]}\")\n",
    "                    plt.show()\n",
    "                '''\n",
    "            \n",
    "                '''\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(result, cmap=\"gray\")\n",
    "                plt.title(f\"cnt, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "            sub_text_char.append(char_images_with_levels)\n",
    "            \n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(rgb_image, cmap=\"gray\")\n",
    "            plt.title(f\"Contour, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "        text_group_char.append(sub_text_char)\n",
    "    return text_group_char\n",
    "\n",
    "\n",
    "text_group_char_subject_code = detect_one_level_of_char(text_group_subject_code[:])\n",
    "text_group_char_subject_name = detect_char(text_group_subject_name[:])\n",
    "text_group_char_credit = detect_one_level_of_char(text_group_credit[:])\n",
    "text_group_char_academic_results = detect_one_level_of_char(text_group_academic_results[:])\n",
    "\n",
    "text_group_char_subject_code_2 = detect_one_level_of_char(text_group_subject_code_2[:])\n",
    "text_group_char_subject_name_2 = detect_char(text_group_subject_name_2[:])\n",
    "text_group_char_credit_2 = detect_one_level_of_char(text_group_credit_2[:])\n",
    "text_group_char_academic_results_2 = detect_one_level_of_char(text_group_academic_results_2[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_char\n",
    "for idx_g, text_group in enumerate(text_group_char_subject_name):\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(char[0], cmap=\"gray\")\n",
    "            plt.title(f\"text_group :{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1} \")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_one_level_of_char\n",
    "for idx_g, text_group in enumerate(text_group_char_credit):\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            #continue\n",
    "            #print(idx_s)\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(char, cmap=\"gray\")\n",
    "            plt.title(f\"char, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนายตัวอักษร 1 ระดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_subject_code_tn = \"../models/char_subject_code_tn_model.h5\"\n",
    "model_path_char_academic_results_tn = \"../models/char_academic_results_tn_model.h5\"\n",
    "\n",
    "model_char_subject_code_tn = load_model(model_path_char_subject_code_tn)\n",
    "model_char_academic_results_tn= load_model(model_path_char_academic_results_tn)\n",
    "\n",
    "# สร้าง Mapping ของโมเดลตามระดับ\n",
    "models_one_level = {\n",
    "    0: model_char_subject_code_tn,\n",
    "    1: model_char_academic_results_tn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "ประมวลผลเสร็จสิ้น\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_subject_code_tn = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-',\n",
    "]\n",
    "\n",
    "char_academic_results_tn = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    'ก', 'ข', 'ถ', 'ท', 'น', 'ป', 'ผ', 'ม', 'ร', 'ล', 'ส', '.'\n",
    "]\n",
    "\n",
    "char_labels = {\n",
    "    0: char_subject_code_tn,\n",
    "    1: char_academic_results_tn,\n",
    "}\n",
    "\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_one_level(text_group_char, char_model=0):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "    text_block = []\n",
    "\n",
    "    for idx_g, text_group in enumerate(text_group_char):\n",
    "        text_result = \"\"\n",
    "\n",
    "        for idx_s, sub_text in enumerate(text_group):\n",
    "            sub_text_result = \"\"\n",
    "\n",
    "            for idx_c, char in enumerate(sub_text):\n",
    "                \n",
    "                if char is None:\n",
    "                    print(f\"Character image {idx_c} is None.\")\n",
    "                    continue  # ข้ามภาพนี้\n",
    "                else:\n",
    "                    # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                    padded_img = resize_with_min_padding(char, input_size, min_padding=1)\n",
    "\n",
    "                    # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                    normalized_img = padded_img / 255.0\n",
    "\n",
    "                    if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                        normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                        processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                    if char_model in models_one_level:\n",
    "                        prediction = models_one_level[char_model].predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence_score = np.max(prediction)\n",
    "\n",
    "                        class_char = char_labels[char_model]\n",
    "                        predicted_letter = class_char[predicted_class]\n",
    "                        sub_text_result += predicted_letter\n",
    "                    '''\n",
    "                    if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                        normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                        processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                        prediction = model_char_subject_code_tn.predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "\n",
    "                        char_label_model = char_labels[label]\n",
    "                        predicted_letter = char_label_model[predicted_class]\n",
    "\n",
    "                        sub_text_result += predicted_letter\n",
    "                    '''\n",
    "\n",
    "            text_result += sub_text_result\n",
    "            text_result += \" \"\n",
    "        text_block.append(text_result)\n",
    "\n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_block   \n",
    "            \n",
    "\n",
    "#text_box_subject_code = predict_text_one_level(text_group_char_subject_code[:], 0)\n",
    "text_box_credit = predict_text_one_level(text_group_char_credit, 0)\n",
    "#text_box_academic_results = predict_text_one_level(text_group_char_academic_results, 1)\n",
    "\n",
    "#text_box_subject_code_2 = predict_text_one_level(text_group_char_subject_code_2[:], 0)\n",
    "#text_box_credit_2 = predict_text_one_level(text_group_credit_2, 0)\n",
    "#text_box_academic_results_2 = predict_text_one_level(text_group_char_academic_results_2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: 3 \n",
      "text 2: 3 \n",
      "text 3: 3 \n",
      "text 4: - \n",
      "text 5: 3 \n",
      "text 6: 3 \n",
      "text 7: 3 \n",
      "text 8: 3 \n",
      "text 9: 3 \n",
      "text 10: 3 \n",
      "text 11: 2 \n",
      "text 12: 2 \n",
      "text 13: 2 \n",
      "text 14: 1 \n",
      "text 15: - \n",
      "text 16: 3 \n",
      "text 17: 3 \n",
      "text 18: 3 \n",
      "text 19: 3 \n",
      "text 20: 3 \n",
      "text 21: 3 \n",
      "text 22: 3 \n"
     ]
    }
   ],
   "source": [
    "def show_information(array):\n",
    "    for idx, data in enumerate(array):\n",
    "        print(f\"text {idx + 1}: {data}\")\n",
    "\n",
    "#show_information(text_box_subject_code[:])\n",
    "#show_information(text_box_academic_results[:])\n",
    "show_information(text_box_credit[:])\n",
    "#show_information(text_box_subject_code_2[:])\n",
    "#show_information(text_box_academic_results_2[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนายตัวอักษรหลายระดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rule_Based_Post_Processing(word):\n",
    "\n",
    "    if not word:\n",
    "        return word\n",
    "    #word = word.replace(\"ัั\", \"ะ\")\n",
    "    word = word.replace(\"เเ\", \"แ\")\n",
    "    #word = word.replace(\"้้\", \"ะ\")\n",
    "    #word = word.replace(\"้ั\", \"ะ\")\n",
    "    #word = word.replace(\"ั้\", \"ะ\")\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_level_0 = \"../models/char_level_0_model.h5\"\n",
    "model_path_char_level_1 = \"../models/char_level_1_model.h5\"\n",
    "model_path_char_level_2 = \"../models/char_level_2_model.h5\"\n",
    "model_path_char_level_3 = \"../models/char_level_3_model.h5\"\n",
    "\n",
    "model_char_level_0 = load_model(model_path_char_level_0)\n",
    "model_char_level_1 = load_model(model_path_char_level_1)\n",
    "model_char_level_2 = load_model(model_path_char_level_2)\n",
    "model_char_level_3 = load_model(model_path_char_level_3)\n",
    "\n",
    "# สร้าง Mapping ของโมเดลตามระดับ\n",
    "models = {\n",
    "    0: model_char_level_0,\n",
    "    1: model_char_level_1,\n",
    "    2: model_char_level_2,\n",
    "    3: model_char_level_3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "ประมวลผลเสร็จสิ้น\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_level_0_label = [\n",
    "    'ุ', 'ู'\n",
    "]\n",
    "\n",
    "char_level_1_label = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    \n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "\n",
    "    'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', \n",
    "    'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', \n",
    "    'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', \n",
    "    'ห', 'ฬ', 'อ', 'ฮ',\n",
    "\n",
    "    'ะ','า', 'เ', 'แ', 'โ', 'ฤ', 'ใ', 'ไ',\n",
    "\n",
    "    '+', '-', '*', '(', ')', '.', '=', '/', '|'\n",
    "]\n",
    "\n",
    "char_level_2_label = [\n",
    "     'ิ', 'ี', 'ึ', 'ื', '็', 'ั', 'ํ', '่', '้', '๊', '๋', '์'\n",
    "]\n",
    "\n",
    "char_level_3_label = [\n",
    "    '่', '้', '๊', '๋',\n",
    "]\n",
    "\n",
    "char_level_labels = {\n",
    "    0: char_level_0_label,\n",
    "    1: char_level_1_label,\n",
    "    2: char_level_2_label,\n",
    "    3: char_level_3_label,\n",
    "}\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_multi_level(text_group_char):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "    text_block = []\n",
    "\n",
    "    for idx_g, text_group in enumerate(text_group_char):\n",
    "        text_result = \"\"\n",
    "\n",
    "        for idx_s, sub_text in enumerate(text_group):\n",
    "            sub_text_result = \"\"\n",
    "\n",
    "            for idx_c, char in enumerate(sub_text):\n",
    "                char_image, char_level = char\n",
    "\n",
    "                if char is None:\n",
    "                    print(f\"Character image {idx_c} is None.\")\n",
    "                    continue  # ข้ามภาพนี้\n",
    "                else:\n",
    "\n",
    "                    # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                    padded_img = resize_with_min_padding(char_image, input_size, min_padding=1)\n",
    "\n",
    "                    '''\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(padded_img, cmap=\"gray\")\n",
    "                    plt.title(f\"Char, text group:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}, level: {char_level}\")\n",
    "                    plt.show()\n",
    "                    '''\n",
    "                    \n",
    "                    # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                    normalized_img = padded_img / 255.0\n",
    "\n",
    "                    if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                        normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                        processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                        if char_level in models:\n",
    "                            prediction = models[char_level].predict(processed_image)\n",
    "                            predicted_class = np.argmax(prediction)\n",
    "                            confidence_score = np.max(prediction)\n",
    "\n",
    "                            class_level = char_level_labels[char_level]\n",
    "                            predicted_letter = class_level[predicted_class]\n",
    "                        else:\n",
    "                            print(\"level ไม่ตรง\")\n",
    "                            prediction = models[2].predict(processed_image)\n",
    "                            predicted_class = np.argmax(prediction)\n",
    "                            confidence_score = np.max(prediction)\n",
    "\n",
    "                            class_level = char_level_labels[2]\n",
    "                            predicted_letter = class_level[predicted_class]\n",
    "\n",
    "                        sub_text_result += predicted_letter\n",
    "            sub_text_result += \" \"\n",
    "            text_result += sub_text_result\n",
    "            text_result_post = Rule_Based_Post_Processing(text_result)\n",
    "        text_block.append(text_result_post)\n",
    "        \n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_block \n",
    "        \n",
    "                    \n",
    "text_box_subject_name = predict_text_multi_level(text_group_char_subject_name[:])\n",
    "#text_box_subject_name_2 = predict_text_multi_level(text_group_char_subject_name_2[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: ท้กษบ้ถาษาไทยเฤงวํชาiห \n",
      "text 2: ภาษาอ้งกฤษเห่อการส่อสาร \n",
      "text 3: tวิตก้บส้งคมไทย \n",
      "text 4: กิจกรรมึองก์การว๊ชาฤพ ไ \n",
      "text 5: องล์การและการจัดการสมัฬหม่ \n",
      "text 6: หลักเศรษฐคาสตร์ \n",
      "text 7: การU้ญซีซ้้นถลาง 1 \n",
      "text 8: รw้บบบ์ญฤ \n",
      "text 9: โปรแกรมdาเร์จรูป(ท่องานบ้ญใ \n",
      "text 10: การบ้Nูชีการเง์น \n",
      "text 11: ถาษาอ้งกฤษสาหร้บการปฎิ-ุูงาน \n",
      "text 12: การสนทนาภาษาจีนเห่อการทํางาน \n",
      "text 13: มqษย*ูฬนธ่นการทํางาน \n",
      "text 14: การออกกําล้งกายเห่อสุขภาท \n",
      "text 15: กีจกรรมองค์การใชาโืพ 2 \n",
      "text 16: กฎทมายโโก๊จ \n",
      "text 17: lทคโนโลย็ดิจิท้ลเห่อการจ้ดการอาฤพ \n",
      "text 18: หลักการตลาด \n",
      "text 19: กาโข้ญซีช์นกลาง 2 \n",
      "text 20: การบัญชีต้บทุบ ใ \n",
      "text 21: การบ้ญฤช้ัน-ฃง l \n",
      "text 22: วิทยาศาสตร์งานโรภิจเlละบโิการ \n"
     ]
    }
   ],
   "source": [
    "def show_information(array):\n",
    "    for idx, data in enumerate(array):\n",
    "        print(f\"text {idx + 1}: {data}\")\n",
    "\n",
    "#show_information(text_box_subject_code[:])\n",
    "show_information(text_box_subject_name[:])\n",
    "#show_information(text_box_subject_name_2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity ratio: 0.0\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "str1 = \"8\"\n",
    "str2 = \"ทญจ3ญ1ญ170ญญ2ญญจอวญญญ1ญทอญ2จจ\"\n",
    "\n",
    "matcher = difflib.SequenceMatcher(None, str1, str2)\n",
    "print(\"Similarity ratio:\", matcher.ratio())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ข้อมูลนักศึกษา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_border(image, left_percent=0, right_percent=0, top_percent=0, bottom_percent=0):\n",
    "    \n",
    "    # หาความกว้างและความสูงของภาพ\n",
    "    height, width = image.shape\n",
    "\n",
    "    # คำนวณพิกัดที่จะตัด (แปลงเป็นพิกเซล)\n",
    "    x_start = int(width * left_percent)\n",
    "    x_end = int(width * (1 - right_percent))\n",
    "    y_start = int(height * top_percent)\n",
    "    y_end = int(height * (1 - bottom_percent))\n",
    "\n",
    "    # ตัดภาพ (Crop)\n",
    "    cropped_img = image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/cropped_fh.jpg\", cropped_img)\n",
    "    \n",
    "    return cropped_img\n",
    "\n",
    "def find_text_student_info_fh(student_info_fh_img):\n",
    "    student_info_fh_img = crop_border(student_info_fh_img.copy(), 0.06, 0.06, 0.06, 0.01)\n",
    "\n",
    "    rgb_image = cv2.cvtColor(student_info_fh_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # กำหนด kernel (ขนาดของ kernel สามารถปรับเปลี่ยนได้ตามความเหมาะสม)\n",
    "    kernel_open = np.ones((2, 2), np.uint8)\n",
    "    kernel_close = np.ones((6, 50), np.uint8)\n",
    "    \n",
    "    opening = cv2.morphologyEx(student_info_fh_img.copy(), cv2.MORPH_OPEN, kernel=kernel_open, iterations=1)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel=kernel_close, iterations=2)\n",
    "\n",
    "    rgb_closing_image = cv2.cvtColor(closing, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/opening.jpg\", opening)\n",
    "    cv2.imwrite(f\"{output_folder}/closing.jpg\", closing)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closing, connectivity=8)\n",
    "\n",
    "    # 1. เอา stats ตัวแรก (background) ออก\n",
    "    stats_no_bg = stats[1:]\n",
    "\n",
    "    # 2. เรียง stats ใหม่โดยใช้ค่า area (คอลัมน์ที่ 4) จากมากไปน้อย\n",
    "    sorted_indices = np.argsort(-stats_no_bg[:, 4])\n",
    "    sorted_stats = stats_no_bg[sorted_indices]\n",
    "\n",
    "    # 3. เลือกแค่ 13 element ที่มีค่า area สูงสุด\n",
    "    top_13_stats = sorted_stats[:13]\n",
    "    top_13_stats_sorted_by_y = top_13_stats[np.argsort(top_13_stats[:, 1])]\n",
    "\n",
    "    img_height, img_width = student_info_fh_img.shape[:2]\n",
    "\n",
    "    # กำหนด margin เป็นเปอร์เซ็นต์ของขนาด bounding box\n",
    "    # เช่น กำหนด 10% ของความกว้าง/ความสูงของ bounding box สำหรับแต่ละด้าน\n",
    "    left_margin_percent = 0.1    # ขยายซ้าย 10%\n",
    "    right_margin_percent = 0.1   # ขยายขวา 10%\n",
    "    top_margin_percent = 0.2     # ขยายบน 20%\n",
    "    bottom_margin_percent = 0.1  # ขยายล่าง 10%\n",
    "\n",
    "    text_group_stud_fh = []\n",
    "    for idx, stats in enumerate(top_13_stats_sorted_by_y): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "\n",
    "        # คำนวณ margin ตามเปอร์เซ็นต์ของ bounding box\n",
    "        left_margin = int(w * left_margin_percent)\n",
    "        right_margin = int(w * right_margin_percent)\n",
    "        top_margin = int(h * top_margin_percent)\n",
    "        bottom_margin = int(h * bottom_margin_percent)\n",
    "\n",
    "        # คำนวณพิกัดใหม่โดยใช้ margin ที่คำนวณได้\n",
    "        x_new = max(x - left_margin, 0)\n",
    "        y_new = max(y - top_margin, 0)\n",
    "        x_end = min(x + w + right_margin, img_width)\n",
    "        y_end = min(y + h + bottom_margin, img_height)\n",
    "\n",
    "        cluster_img = student_info_fh_img[y_new:y_end, x_new:x_end]\n",
    "        text_group_stud_fh.append(cluster_img)\n",
    "\n",
    "        # วาดกรอบที่ขยายแล้วลงบนภาพ\n",
    "        cv2.rectangle(rgb_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        cv2.rectangle(rgb_closing_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        \n",
    "    cv2.imwrite(f\"{output_folder}/cca_top_13_stats.jpg\", rgb_image)\n",
    "    cv2.imwrite(f\"{output_folder}/cca_rgb_closing_image.jpg\", rgb_closing_image)\n",
    "\n",
    "    return text_group_stud_fh[1:]\n",
    "\n",
    "def find_text_student_info_sh(student_info_sh_img):\n",
    "    student_info_sh_img = crop_border(student_info_sh_img.copy(), 0.05, 0.00, 0.05, 0.01)\n",
    "\n",
    "    rgb_image = cv2.cvtColor(student_info_sh_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # กำหนด kernel (ขนาดของ kernel สามารถปรับเปลี่ยนได้ตามความเหมาะสม)\n",
    "    kernel_open = np.ones((2, 2), np.uint8)\n",
    "    kernel_close = np.ones((8, 50), np.uint8)\n",
    "    \n",
    "    opening = cv2.morphologyEx(student_info_sh_img.copy(), cv2.MORPH_OPEN, kernel=kernel_open, iterations=1)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel=kernel_close, iterations=2)\n",
    "\n",
    "    rgb_closing_image = cv2.cvtColor(closing, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/opening_sh.jpg\", opening)\n",
    "    cv2.imwrite(f\"{output_folder}/closing_sh.jpg\", closing)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closing, connectivity=8)\n",
    "\n",
    "    # 1. เอา stats ตัวแรก (background) ออก\n",
    "    stats_no_bg = stats[1:]\n",
    "\n",
    "    # 2. เรียง stats ใหม่โดยใช้ค่า area (คอลัมน์ที่ 4) จากมากไปน้อย\n",
    "    sorted_indices = np.argsort(-stats_no_bg[:, 4])\n",
    "    sorted_stats = stats_no_bg[sorted_indices]\n",
    "\n",
    "    # 3. เลือกแค่ 14 element ที่มีค่า area สูงสุด\n",
    "    top_14_stats = sorted_stats[:14]\n",
    "    top_14_stats_sorted_by_y = top_14_stats[np.argsort(top_14_stats[:, 1])]\n",
    "\n",
    "    img_height, img_width = student_info_sh_img.shape[:2]\n",
    "\n",
    "    # กำหนด margin เป็นเปอร์เซ็นต์ของขนาด bounding box\n",
    "    # เช่น กำหนด 10% ของความกว้าง/ความสูงของ bounding box สำหรับแต่ละด้าน\n",
    "    left_margin_percent = 0.1    # ขยายซ้าย 10%\n",
    "    right_margin_percent = 0.1   # ขยายขวา 10%\n",
    "    top_margin_percent = 0.2     # ขยายบน 20%\n",
    "    bottom_margin_percent = 0.1  # ขยายล่าง 10%\n",
    "\n",
    "    text_group_stud_sh = []\n",
    "    for idx, stats in enumerate(top_14_stats_sorted_by_y): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "\n",
    "        # คำนวณ margin ตามเปอร์เซ็นต์ของ bounding box\n",
    "        left_margin = int(w * left_margin_percent)\n",
    "        right_margin = int(w * right_margin_percent)\n",
    "        top_margin = int(h * top_margin_percent)\n",
    "        bottom_margin = int(h * bottom_margin_percent)\n",
    "\n",
    "        # คำนวณพิกัดใหม่โดยใช้ margin ที่คำนวณได้\n",
    "        x_new = max(x - left_margin, 0)\n",
    "        y_new = max(y - top_margin, 0)\n",
    "        x_end = min(x + w + right_margin, img_width)\n",
    "        y_end = min(y + h + bottom_margin, img_height)\n",
    "\n",
    "        cluster_img = student_info_sh_img[y_new:y_end, x_new:x_end]\n",
    "        text_group_stud_sh.append(cluster_img)\n",
    "\n",
    "        # วาดกรอบที่ขยายแล้วลงบนภาพ\n",
    "        cv2.rectangle(rgb_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        cv2.rectangle(rgb_closing_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        \n",
    "    cv2.imwrite(f\"{output_folder}/cca_top_14_stats.jpg\", rgb_image)\n",
    "    cv2.imwrite(f\"{output_folder}/cca_rgb_closing_image.jpg\", rgb_closing_image)\n",
    "\n",
    "    return text_group_stud_sh[3:]\n",
    "\n",
    "text_stud_fh_images = find_text_student_info_fh(student_info_fh_img)\n",
    "text_stud_sh_images = find_text_student_info_sh(student_info_sh_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx_g, text_group in enumerate(text_stud_fh_images):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(text_group, cmap=\"gray\")\n",
    "    plt.title(f\"text_group {idx_g+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_fh = [3, -2, -1]\n",
    "indices_sh = [-3, -1]\n",
    "student_name, field_of_study, field_of_work = [text_stud_fh_images[i] for i in indices_fh]\n",
    "cgpa, graduation_date = [text_stud_sh_images[i] for i in indices_sh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sub_text_in_group_stud(binary_image):\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(binary_image, cmap=\"gray\")\n",
    "    plt.title(f\"binary_image\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    text_group = []\n",
    "\n",
    "    #kernel_open = np.ones((2, 2), np.uint8)\n",
    "    #remove_noise = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "    #plt.figure(figsize=(5,5))\n",
    "    #plt.imshow(remove_noise, cmap=\"gray\")\n",
    "    #plt.title(f\"remove_noise\")\n",
    "    #plt.show()\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dummy_image = cv2.dilate(binary_image, kernel, iterations=2)\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(dummy_image, cmap=\"gray\")\n",
    "    plt.title(f\"dummy_image\")\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    # ใช้ Connected Component Analysis\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dummy_image, connectivity=8)\n",
    "    word_stats = stats[1:] # ข้าม Background (index 0)\n",
    "    sorted_indices = np.argsort(word_stats[:, 0]) # จัดเรียงตามค่า x (คอลัมน์ที่ 0)\n",
    "    sorted_stats = word_stats[sorted_indices]\n",
    "\n",
    "    for idx, stats in enumerate(sorted_stats):\n",
    "        x, y, w, h, area = stats\n",
    "        cluster_img = binary_image[y:y+h, x:x+w]\n",
    "        text_group.append(cluster_img)\n",
    "\n",
    "    return text_group\n",
    "\n",
    "text_group_student_name = detect_sub_text_in_group_stud(student_name)\n",
    "text_group_field_of_study = detect_sub_text_in_group_stud(field_of_study)\n",
    "text_group_field_of_work = detect_sub_text_in_group_stud(field_of_work)\n",
    "\n",
    "text_group_cgpa = detect_sub_text_in_group_stud(cgpa)\n",
    "text_group_graduation_date = detect_sub_text_in_group_stud(graduation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx, sub_text in enumerate(text_group_student_name):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(sub_text, cmap=\"gray\")\n",
    "    plt.title(f\"sub_text {idx+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(filtered_contours) >= 3\n",
      "มีอยู่หลังสุด\n",
      "มีการสลับตัวแรกกับตัวสุดท้าย\n"
     ]
    }
   ],
   "source": [
    "def char_level_stud(char_images):\n",
    "    debug = False\n",
    "\n",
    "    char_box = []\n",
    "    \n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(char_images, cmap=\"gray\")\n",
    "        plt.title(f\"char\")\n",
    "        plt.show()\n",
    "    \n",
    "    skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "    #skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "\n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(skeleton, cmap=\"gray\")\n",
    "        plt.title(f\"skeleton\")\n",
    "        plt.show()\n",
    "    \n",
    "    kernel_dummy = np.ones((3, 3), np.uint8)\n",
    "    closing_skeleton = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "    dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "    closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(closing_skeleton, cmap=\"gray\")\n",
    "    plt.title(f\"closing_skeleton\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(dummy_image, cmap=\"gray\")\n",
    "        plt.title(f\"dummy_image\")\n",
    "        plt.show()\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # เรียง contours ตามค่า y ของ centroid จากน้อยไปหามาก\n",
    "    sorted_contours = sorted(contours, key=lambda cnt: get_centroid(cnt)[1], reverse=True)\n",
    "\n",
    "    # คำนวณพื้นที่ของ contour แต่ละตัว และหาพื้นที่ที่ใหญ่ที่สุด\n",
    "    max_area = max(cv2.contourArea(cnt) for cnt in sorted_contours)\n",
    "\n",
    "    # กำหนด threshold เป็น 5% ของพื้นที่ที่ใหญ่ที่สุด\n",
    "    min_area_threshold = max_area * 0.05\n",
    "\n",
    "    # กรอง contours ที่มีพื้นที่ไม่น้อยกว่า threshold\n",
    "    filtered_contours = [cnt for cnt in sorted_contours if cv2.contourArea(cnt) >= min_area_threshold]\n",
    "\n",
    "\n",
    "    # หาก filtered_contours มีแค่ 2 ตัว\n",
    "    if len(filtered_contours) == 2:\n",
    "\n",
    "        area0 = cv2.contourArea(filtered_contours[0])\n",
    "        area1 = cv2.contourArea(filtered_contours[1])\n",
    "        # คำนวณความแตกต่างเป็นอัตราส่วนของ contour ที่มีพื้นที่ใหญ่กว่า\n",
    "        diff_ratio = abs(area0 - area1) / max(area0, area1)\n",
    "        if diff_ratio <= 0.05:\n",
    "            print(\"เหมือนกัน\")\n",
    "\n",
    "            kernel_same = np.ones((4, 4), np.uint8)\n",
    "            contours, hierarchy = cv2.findContours(char_images, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(closing_same, cmap=\"gray\")\n",
    "            plt.title(f\"closing_same\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            level = 1\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            contour_area = int(cv2.contourArea(largest_contour))\n",
    "            crop_img = char_images[y:y+h, x:x+w]\n",
    "            char_box.append([crop_img, level])\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"Level : {level} area: {contour_area}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            return char_box\n",
    "    elif len(filtered_contours) >= 3: # เอาไว้แก้ปัญหาพวกคำว่า \"ชั้น, บัน\" หรือทุกคำที่มี \"  ั \"\n",
    "        print(\"len(filtered_contours) >= 3\")\n",
    "        # คำนวณ centroid และพื้นที่ของแต่ละ contour ใน filtered_contours\n",
    "        centroids_filtered = [get_centroid(cnt) for cnt in filtered_contours]\n",
    "        areas_filtered = [cv2.contourArea(cnt) for cnt in filtered_contours]\n",
    "    \n",
    "        # หาตำแหน่งของ contour ที่มีพื้นที่มากที่สุด\n",
    "        max_area_idx = areas_filtered.index(max(areas_filtered))\n",
    "        max_centroid_y = centroids_filtered[max_area_idx][1]\n",
    "        max_area = areas_filtered[max_area_idx]\n",
    "    \n",
    "        # สร้าง list ใหม่เพื่อจัดกลุ่ม contour ที่จะอยู่ก่อนและหลัง\n",
    "        remain_contours = []\n",
    "        move_to_end = []\n",
    "\n",
    "        find_status = False\n",
    "        # วนลูปผ่านแต่ละ contour พร้อมกับ centroid และพื้นที่\n",
    "        for idx, (cnt, cent, area) in enumerate(zip(filtered_contours, centroids_filtered, areas_filtered)):\n",
    "            # ถ้าเป็น contour ที่มีพื้นที่มากที่สุด ให้เก็บไว้ใน remain_contours\n",
    "            if idx == max_area_idx:\n",
    "                remain_contours.append(cnt)\n",
    "            else:\n",
    "                # ตรวจสอบว่า centroid แกน y ของ contour นี้ต่างจาก max_centroid_y ไม่เกิน 20%\n",
    "                # และมีพื้นที่ไม่น้อยกว่า 30% ของ max_area\n",
    "                if abs(cent[1] - max_centroid_y) <= 0.2 * max_centroid_y and area >= 0.3 * max_area:\n",
    "                    print(\"มีอยู่หลังสุด\")\n",
    "                    move_to_end.append(cnt)\n",
    "                    find_status = True\n",
    "                else:\n",
    "                    remain_contours.append(cnt)\n",
    "        \n",
    "        # รวม list ที่เหลือเข้าด้วยกัน โดย contour ที่ตรงเงื่อนไขจะอยู่ท้ายสุด\n",
    "        filtered_contours = remain_contours + move_to_end\n",
    "\n",
    "        if find_status == True:\n",
    "            \n",
    "            # คำนวณพื้นที่และ centroid แกน x ของ contour ตัวแรกและตัวสุดท้าย\n",
    "            first_area = cv2.contourArea(filtered_contours[0])\n",
    "            last_area = cv2.contourArea(filtered_contours[-1])\n",
    "            first_centroid = get_centroid(filtered_contours[0])\n",
    "            last_centroid = get_centroid(filtered_contours[-1])\n",
    "\n",
    "            # ตรวจสอบเงื่อนไข ถ้า contour ตัวแรกมี area มากกว่าและ centroid_x มากกว่าตัวสุดท้าย\n",
    "            if first_area > last_area and first_centroid[0] > last_centroid[0]:\n",
    "                print(\"มีการสลับตัวแรกกับตัวสุดท้าย\")\n",
    "                # สลับตำแหน่ง contour ตัวแรกกับตัวสุดท้าย\n",
    "                filtered_contours[0], filtered_contours[-1] = filtered_contours[-1], filtered_contours[0]\n",
    "\n",
    "            # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "            for idx_c, cnt in enumerate(filtered_contours):\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = int(cv2.contourArea(cnt))\n",
    "                char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "            for idx, box in enumerate(char_box):\n",
    "                if idx == 0:\n",
    "                    box.append(1)\n",
    "                elif idx == (len(char_box)-1):\n",
    "                    box.append(1)\n",
    "                else:\n",
    "                    box.append(2)\n",
    "\n",
    "            char_level_images = []\n",
    "            for idx, box in enumerate(char_box):\n",
    "                x, y, w, h, area, level = box\n",
    "                crop_img = char_images[y:y+h, x:x+w]\n",
    "                char_level_images.append([crop_img, level])\n",
    "\n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"char : {idx+1} Level : {level} area: {area}\")\n",
    "                    plt.show()\n",
    "            return char_level_images\n",
    "\n",
    "        else:\n",
    "            # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "            for idx_c, cnt in enumerate(filtered_contours):\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = int(cv2.contourArea(cnt))\n",
    "                char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "            for idx, box in enumerate(char_box):\n",
    "                if idx == max_index:\n",
    "                    # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "                    box.append(1)\n",
    "                elif idx < max_index:\n",
    "                    # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "                    box.append(0)\n",
    "                #elif idx == (len(char_box)-1):\n",
    "                #    # ถ้าเป็น list append 1\n",
    "                #    box.append(1)\n",
    "                else:\n",
    "                    # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append 2\n",
    "                    box.append(2)\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "            if max_index != 0:\n",
    "                char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "            char_level_images = []\n",
    "            for idx, box in enumerate(char_box):\n",
    "                x, y, w, h, area, level = box\n",
    "                crop_img = char_images[y:y+h, x:x+w]\n",
    "                char_level_images.append([crop_img, level])\n",
    "\n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"char : {idx+1} Level : {level} area: {area}\")\n",
    "                    plt.show()\n",
    "        \n",
    "            return char_level_images\n",
    "\n",
    " #########################\n",
    "    # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "    for idx_c, cnt in enumerate(filtered_contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        contour_area = int(cv2.contourArea(cnt))\n",
    "        char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # สำหรับ list ที่อยู่หลัง list ที่มี area มากที่สุด เราจะเริ่มนับจาก 2\n",
    "    after_counter = 2\n",
    "\n",
    "    # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "    for idx, box in enumerate(char_box):\n",
    "        if idx == max_index:\n",
    "            # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "            box.append(1)\n",
    "        elif idx < max_index:\n",
    "            # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "            box.append(0)\n",
    "        else:\n",
    "            # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append sequential number เริ่มจาก 2\n",
    "            box.append(after_counter)\n",
    "            #after_counter += 1\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "    if max_index != 0:\n",
    "        char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(char_images, cmap=\"gray\")\n",
    "    plt.title(f\"char_images\")\n",
    "    plt.show()\n",
    "    '''\n",
    "        \n",
    "    char_level_images = []\n",
    "    for idx, box in enumerate(char_box):\n",
    "        x, y, w, h, area, level = box\n",
    "        crop_img = char_images[y:y+h, x:x+w]\n",
    "        char_level_images.append([crop_img, level])\n",
    "\n",
    "        if debug == True:\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"char : {idx+1} Leve : {level} area: {area}\")\n",
    "            plt.show()\n",
    "        \n",
    "    return char_level_images\n",
    "       \n",
    "def detect_char_stud(text_group):\n",
    "\n",
    "    sub_text_char = []\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        rgb_image = cv2.cvtColor(sub_text, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "        skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "        #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "        kernel_dummy = np.ones((2, 2), np.uint8)\n",
    "        dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "        kernel_closing = np.ones((7, 1), np.uint8)\n",
    "        closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_closing, iterations=1)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "            \n",
    "        char_images_with_levels = []\n",
    "\n",
    "        '''\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(sub_text, cmap=\"gray\")\n",
    "        plt.title(f\"sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(skeleton, cmap=\"gray\")\n",
    "        plt.title(f\"skeleton, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(dummy_image, cmap=\"gray\")\n",
    "        plt.title(f\"dummy_image, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(closing, cmap=\"gray\")\n",
    "        plt.title(f\"closing, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "        for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "            # สมมุติว่าเราได้ contour (cnt) จาก cv2.findContours แล้ว\n",
    "            #scaled_cnt = scale_contour(cnt, scale_factor=1.0)\n",
    "\n",
    "            #char_height, char_width = h, w\n",
    "            #mask = np.zeros((char_height, char_width), dtype=np.uint8)\n",
    "\n",
    "            mask = np.zeros(sub_text.shape[:2], dtype=np.uint8)\n",
    "\n",
    "            rgb_mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            # วาด contour ลงใน mask โดยเติมเต็ม (thickness = -1) ให้ภายใน contour เป็นสีขาว (255)\n",
    "            cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "            kernel_mask = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # ปรับขนาด kernel ตามต้องการ\n",
    "            dilated_mask = cv2.dilate(mask, kernel_mask, iterations=1)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(dilated_mask, cmap=\"gray\")\n",
    "            plt.title(f\"dilated_mask, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            # ใช้ mask กับภาพต้นฉบับ เพื่อดึงเฉพาะส่วนภายใน contour\n",
    "            char_result = cv2.bitwise_and(sub_text, sub_text, mask=dilated_mask)\n",
    "            char_images_with_levels.extend(char_level_stud(char_result))\n",
    "            #print(\"cher_level_images :\", len(char_images_with_levels))\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(char_result, cmap=\"gray\")\n",
    "            plt.title(f\"sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "                \n",
    "            '''\n",
    "            for idx_c_l, cher_level in enumerate(cher_level_images):\n",
    "                plt.figure(figsize=(2, 2))\n",
    "                plt.imshow(cher_level[0], cmap=\"gray\")\n",
    "                plt.title(f\"cnt, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c_l+1}, level:{cher_level[1]}\")\n",
    "                plt.show()\n",
    "            '''\n",
    "            \n",
    "                \n",
    "            #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "        sub_text_char.append(char_images_with_levels)\n",
    "            \n",
    "        '''\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(rgb_image, cmap=\"gray\")\n",
    "        plt.title(f\"Contour, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "        '''\n",
    "            \n",
    "\n",
    "    return sub_text_char\n",
    "\n",
    "text_group_char_student_name = detect_char_stud(text_group_student_name[3:])\n",
    "text_group_char_field_of_study = detect_char_stud(text_group_field_of_study[1:])\n",
    "text_group_char_field_of_work = detect_char_stud(text_group_field_of_work[1:])\n",
    "\n",
    "text_group_char_cgpa = detect_char_stud(text_group_cgpa[1:])\n",
    "text_group_char_graduation_date = detect_char_stud(text_group_graduation_date[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_char\n",
    "\n",
    "for idx_s, sub_text in enumerate(text_group_char_student_name):\n",
    "    for idx_c, char in enumerate(sub_text):\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(char[0], cmap=\"gray\")\n",
    "        plt.title(f\"sub text:{idx_s+1}, char:{idx_c+1} \")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนายตัวอักษรหลายระดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rule_Based_Post_Processing(word):\n",
    "\n",
    "    if not word:\n",
    "        return word\n",
    "    #word = word.replace(\"ัั\", \"ะ\")\n",
    "    word = word.replace(\"เเ\", \"แ\")\n",
    "    #word = word.replace(\"้้\", \"ะ\")\n",
    "    #word = word.replace(\"้ั\", \"ะ\")\n",
    "    #word = word.replace(\"ั้\", \"ะ\")\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_level_0 = \"../models/char_level_0_model.h5\"\n",
    "model_path_char_level_1 = \"../models/char_level_1_model.h5\"\n",
    "model_path_char_level_2 = \"../models/char_level_2_model.h5\"\n",
    "model_path_char_level_3 = \"../models/char_level_3_model.h5\"\n",
    "\n",
    "model_char_level_0 = load_model(model_path_char_level_0)\n",
    "model_char_level_1 = load_model(model_path_char_level_1)\n",
    "model_char_level_2 = load_model(model_path_char_level_2)\n",
    "model_char_level_3 = load_model(model_path_char_level_3)\n",
    "\n",
    "# สร้าง Mapping ของโมเดลตามระดับ\n",
    "models = {\n",
    "    0: model_char_level_0,\n",
    "    1: model_char_level_1,\n",
    "    2: model_char_level_2,\n",
    "    3: model_char_level_3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_level_0_label = [\n",
    "    'ุ', 'ู'\n",
    "]\n",
    "\n",
    "char_level_1_label = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    \n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "\n",
    "    'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', \n",
    "    'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', \n",
    "    'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', \n",
    "    'ห', 'ฬ', 'อ', 'ฮ',\n",
    "\n",
    "    'ะ','า', 'เ', 'แ', 'โ', 'ฤ', 'ใ', 'ไ',\n",
    "\n",
    "    '+', '-', '*', '(', ')', '.', '=', '/', '|'\n",
    "]\n",
    "\n",
    "char_level_2_label = [\n",
    "     'ิ', 'ี', 'ึ', 'ื', '็', 'ั', 'ํ', '่', '้', '๊', '๋', '์'\n",
    "]\n",
    "\n",
    "char_level_3_label = [\n",
    "    '่', '้', '๊', '๋',\n",
    "]\n",
    "\n",
    "char_level_labels = {\n",
    "    0: char_level_0_label,\n",
    "    1: char_level_1_label,\n",
    "    2: char_level_2_label,\n",
    "    3: char_level_3_label,\n",
    "}\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_multi_level_stud(text_group_char):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "\n",
    "    text_result = \"\"\n",
    "    for idx_s, sub_text in enumerate(text_group_char):\n",
    "        sub_text_result = \"\"\n",
    "\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            char_image, char_level = char\n",
    "\n",
    "            if char is None:\n",
    "                print(f\"Character image {idx_c} is None.\")\n",
    "                continue  # ข้ามภาพนี้\n",
    "            else:\n",
    "\n",
    "                # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                padded_img = resize_with_min_padding(char_image, input_size, min_padding=1)\n",
    "\n",
    "                '''\n",
    "                plt.figure(figsize=(2, 2))\n",
    "                plt.imshow(padded_img, cmap=\"gray\")\n",
    "                plt.title(f\"Char, text group:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}, level: {char_level}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                    \n",
    "                # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                normalized_img = padded_img / 255.0\n",
    "\n",
    "                if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                    normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                    processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                    if char_level in models:\n",
    "                        prediction = models[char_level].predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence_score = np.max(prediction)\n",
    "\n",
    "                        class_level = char_level_labels[char_level]\n",
    "                        predicted_letter = class_level[predicted_class]\n",
    "                    else:\n",
    "                        print(\"level ไม่ตรง\")\n",
    "                        prediction = models[2].predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence_score = np.max(prediction)\n",
    "\n",
    "                        class_level = char_level_labels[2]\n",
    "                        predicted_letter = class_level[predicted_class]\n",
    "\n",
    "                    sub_text_result += predicted_letter\n",
    "\n",
    "        sub_text_result += \" \"\n",
    "        text_result += sub_text_result\n",
    "        text_result_post = Rule_Based_Post_Processing(text_result)\n",
    "        #text_block.append(text_result_post)\n",
    "        \n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_result_post \n",
    "        \n",
    "text_box_student_name = predict_text_multi_level_stud(text_group_char_student_name[:])\n",
    "text_box_field_of_study = predict_text_multi_level_stud(text_group_char_field_of_study[:])\n",
    "text_box_field_of_work = predict_text_multi_level_stud(text_group_char_field_of_work[:])\n",
    "\n",
    "text_box_cgpa = predict_text_multi_level_stud(text_group_char_cgpa[:])\n",
    "text_box_graduation_date = predict_text_multi_level_stud(text_group_char_graduation_date[:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "นาใสาวจิรนันท์ พีรวaนสกุล\n",
      "การบัญชี\n",
      "การฬญฤ\n",
      "3.76\n",
      "23 ม่นาคม 2565\n"
     ]
    }
   ],
   "source": [
    "print(text_box_student_name.strip())\n",
    "print(text_box_field_of_study.strip())\n",
    "print(text_box_field_of_work.strip())\n",
    "\n",
    "print(text_box_cgpa.replace(\" \", \"\"))\n",
    "print(text_box_graduation_date.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
