{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "output_folder = Path(\"../data/output_images/output_V6_TN\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_1.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_3.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_4.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_5.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_6.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_7.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_8.png\") # ซ้ำกับ 7\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_9.png\") # จับตารางได้แต่พังตอน pt\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_10.png\") # ลบเส้นตารางไม่หมดตรงรหัสวิชา\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_11.png\") # ภาพใหญ่เกินไป\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_12.png\") # ตารางไม่ตรง\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_13.png\") # ติดลอยปั้มหมึก\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_14.png\")\n",
    "#image = Image.open(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_15.png\")\n",
    "\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"ไม่พบไฟล์ภาพ กรุณาตรวจสอบเส้นทางของไฟล์\")\n",
    "\n",
    "new_size = (1660, 2347)  # ตัวอย่างขนาดใหม่\n",
    "resized_pil = image.resize(new_size, Image.LANCZOS) # ปรับขนาดภาพด้วย LANCZOS filter\n",
    "\n",
    "# แปลงภาพจาก PIL Image เป็น NumPy array (ในรูปแบบ RGB)\n",
    "img_rgb = np.array(resized_pil)\n",
    "\n",
    "# แปลงจาก RGB เป็น BGR เพื่อให้ใช้งานกับ OpenCV ได้\n",
    "img_cv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "denoised = cv2.bilateralFilter(img_cv, d=9, sigmaColor=75, sigmaSpace=75) # จำกัด noise\n",
    "gray_img = cv2.cvtColor(denoised, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "binary_gaussian = cv2.adaptiveThreshold(\n",
    "    gray_img, \n",
    "    maxValue=255, \n",
    "    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    thresholdType=cv2.THRESH_BINARY_INV, \n",
    "    blockSize=51, \n",
    "    C=21 #21\n",
    ")\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/img_cv.png\", img_cv)\n",
    "cv2.imwrite(f\"{output_folder}/denoised.png\", denoised)\n",
    "cv2.imwrite(f\"{output_folder}/gray.png\", gray_img)\n",
    "cv2.imwrite(f\"{output_folder}/binary_g.png\", binary_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour #0: bounding box = (x=6, y=192, w=156, h=1788, area=276985)\n",
      "Contour #1: bounding box = (x=173, y=192, w=661, h=1788, area=1179420)\n",
      "Contour #2: bounding box = (x=845, y=192, w=52, h=1788, area=91137)\n",
      "Contour #3: bounding box = (x=908, y=192, w=59, h=1788, area=103646)\n",
      "Contour #4: bounding box = (x=978, y=192, w=66, h=1788, area=116155)\n",
      "Contour #5: bounding box = (x=1055, y=192, w=157, h=1788, area=278772)\n",
      "Contour #6: bounding box = (x=1223, y=192, w=661, h=1788, area=1179420)\n",
      "Contour #7: bounding box = (x=1895, y=192, w=52, h=1788, area=91137)\n",
      "Contour #8: bounding box = (x=1958, y=192, w=58, h=1788, area=101859)\n",
      "Contour #9: bounding box = (x=2027, y=192, w=67, h=1788, area=117942)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_grade_table_and_students(binary_img, denoised):\n",
    "    \n",
    "    # แยกตาราง\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_img, connectivity=8)\n",
    "    areas = [stat[4] for stat in stats]  # ดึงค่า area\n",
    "    sorted_areas = sorted(areas, reverse=True)  # เรียงลำดับจากมากไปน้อย\n",
    "    second_max_area = sorted_areas[1]  # ค่าอันดับ 2\n",
    "    second_max_area_index = areas.index(second_max_area)  # หาตำแหน่งในลิสต์เดิม\n",
    "    table_position = stats[second_max_area_index]\n",
    "    x, y, w, h, area = table_position\n",
    "    table_img = binary_img[y:y+h, x:x+w]\n",
    "    table_original_img = denoised[y:y+h, x:x+w]\n",
    "\n",
    "    # ข้อมูลนักเรียน\n",
    "    #x_start = int((x+w) * 0.40) # ความกว้าง 40% ของตาราง\n",
    "    x_end = int((x+w) * 0.85) # ความกว้าง 85% ของตาราง\n",
    "    x_split_half = int((x+w) * 0.38) # ความกว้าง 38% ของตาราง\n",
    "\n",
    "    student_info_img = binary_img[:y, :x_end]\n",
    "    student_info_fh_img = binary_img[:y, :x_split_half] # ครึ่งแรก\n",
    "    student_info_sh_img = binary_img[:y, x_split_half:x_end] # ครึ่งหลัง\n",
    "\n",
    "    return table_img, student_info_img, student_info_fh_img, student_info_sh_img, table_original_img\n",
    "\n",
    "def biggest_contour(contours):\n",
    "    biggest = np.array([])\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i)\n",
    "        #print(area)\n",
    "        if area > 1000:\n",
    "            #print(\"มา\")\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.02 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "\n",
    "    return biggest\n",
    "\n",
    "def persective_transformation(table_binary_img, table_original_img):\n",
    "\n",
    "    # ค้นหาคอนทัวร์\n",
    "    contours, hierarchy = cv2.findContours(table_binary_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #contours, hierarchy = cv2.findContours(table_binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "    # ค้นหาสี่เหลี่ยมที่ใหญ่ที่สุด\n",
    "    biggest = biggest_contour(contours)\n",
    "\n",
    "    points = biggest.reshape(4, 2)\n",
    "    input_points = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "    points_sum = points.sum(axis=1)\n",
    "    input_points[0] = points[np.argmin(points_sum)]\n",
    "    input_points[3] = points[np.argmax(points_sum)]\n",
    "\n",
    "    points_diff = np.diff(points, axis=1)\n",
    "    input_points[1] = points[np.argmin(points_diff)]\n",
    "    input_points[2] = points[np.argmax(points_diff)]\n",
    "\n",
    "    (top_left, top_right, bottom_right, bottom_left) = input_points\n",
    "\n",
    "    # Euclidean Distance Formula\n",
    "    bottom_width = np.sqrt(((bottom_right[0] - bottom_left[0]) ** 2) + ((bottom_right[1] - bottom_left[1]) ** 2))\n",
    "    top_width = np.sqrt(((top_right[0] - top_left[0]) ** 2) + ((top_right[1] - top_left[1]) ** 2))\n",
    "    rigth_height = np.sqrt(((top_left[0] - bottom_right[0]) ** 2) + ((top_left[1] - bottom_right[1]) ** 2))\n",
    "    left_height = np.sqrt(((top_left[0] - bottom_left[0]) ** 2) + ((top_left[1] - bottom_left[1]) ** 2))\n",
    "\n",
    "    # Output image size\n",
    "    #max_width = max(int(bottom_width), int(top_width))\n",
    "    expand_width = round(max(int(bottom_width), int(top_width)) * 0.4)\n",
    "    max_width = max(int(bottom_width), int(top_width)) + expand_width\n",
    "    max_height = max(int(rigth_height), int(left_height))\n",
    "\n",
    "    # Desird points values in the output image\n",
    "    converted_points = np.float32([[0, 0], [max_width, 0], [0, max_height], [max_width, max_height]])\n",
    "\n",
    "    # Perspective transformaxtion\n",
    "    matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "    img_out = cv2.warpPerspective(table_binary_img.copy(), matrix, (max_width, max_height))\n",
    "    img_original_out = cv2.warpPerspective(table_original_img.copy(), matrix, (max_width, max_height))\n",
    "\n",
    "    return img_out, img_original_out\n",
    "\n",
    "def hough_line_transform(binary_image, table_original_persective_img, grid_img):\n",
    "\n",
    "    # 1) ใช้ HoughLinesP ตรวจจับเส้น\n",
    "    #    - พารามิเตอร์ที่สำคัญ: threshold, minLineLength, maxLineGap\n",
    "    lines = cv2.HoughLinesP(\n",
    "        binary_image,\n",
    "        rho=1,\n",
    "        theta=np.pi/180,\n",
    "        threshold=100,      # ต้องปรับจูน\n",
    "        minLineLength=700,  # ต้องปรับจูน\n",
    "        maxLineGap=10     # ต้องปรับจูน\n",
    "    )\n",
    "\n",
    "    # 2) สร้าง mask (เป็นภาพดำล้วน ขนาดเท่ากับต้นฉบับ)\n",
    "    line_mask = np.zeros_like(binary_image)\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            # วาดเส้นสีขาวลงใน mask (ปรับ thickness ตามความหนาเส้นในภาพ)\n",
    "            cv2.line(line_mask, (x1, y1), (x2, y2), 255, 2)\n",
    "\n",
    "    # 4) เราจะเอา mask นี้มาช่วยลบเส้นในภาพ\n",
    "    #    วิธีง่าย ๆ คือการเอา thresh ที่เป็น binary_inv มาลบด้วย mask (bitwise)\n",
    "    #    หรืออาจใช้เทคนิค inpaint บนภาพสี\n",
    "\n",
    "    # วิธีที่ 4.1: ลบตรง ๆ จาก thresh ก่อน (ซึ่งเป็น Binary แล้ว)\n",
    "    table_without_lines = cv2.bitwise_and(binary_image, cv2.bitwise_not(line_mask))\n",
    "    table_without_lines_2 = cv2.bitwise_and(table_without_lines, cv2.bitwise_not(grid_img))\n",
    "\n",
    "\n",
    "    # หรือ วิธีที่ 4.2: ลอง inpaint บนภาพจริงสี (img)\n",
    "    #    โดยปกติ inpaint จะต้องการ mask สีขาว บริเวณที่ต้องการซ่อมแซม\n",
    "    #    ซึ่ง line_mask ของเราพอดีอยู่แล้ว\n",
    "    inpainted = cv2.inpaint(table_original_persective_img, line_mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    #kernel = np.ones((20, 15), np.uint8)\n",
    "    #final_dilate = cv2.dilate(image_without_lines, kernel, iterations=1)\n",
    "\n",
    "\n",
    "    # เนื่องจาก thresh เป็น invert (พื้นดำ ตัวหนังสือขาว)\n",
    "    # ถ้าอยากกลับด้านให้พื้นขาว ตัวหนังสือดำก็ทำ bitwise_not อีกที\n",
    "    #final = cv2.bitwise_not(image_without_lines)\n",
    "    cv2.imwrite(f\"{output_folder}/line_mask.png\", line_mask)\n",
    "    cv2.imwrite(f\"{output_folder}/image_without_lines.png\", table_without_lines)\n",
    "    cv2.imwrite(f\"{output_folder}/image_without_lines_2.png\", table_without_lines_2)\n",
    "    #cv2.imwrite(f\"{output_folder}/final_dilate.png\", final_dilate)\n",
    "    cv2.imwrite(f\"{output_folder}/inpainted.png\", inpainted)\n",
    "\n",
    "    return line_mask, table_without_lines, table_without_lines_2\n",
    "\n",
    "def cells_detect(grid_lines):\n",
    "    # ขั้นตอนที่ 1: Invert ภาพ\n",
    "    inverted = cv2.bitwise_not(grid_lines) # (เพื่อให้พื้นที่ดำ (ช่องตาราง) กลายเป็นสีขาว, ส่วนเส้นขาวจะเป็นสีดำ)\n",
    "\n",
    "    # ขั้นตอนที่ 2: Erode พื้นที่ขาวเล็กน้อย เพื่อลดการติดเส้น\n",
    "    kernel = np.ones((3, 3), np.uint8) # สร้าง kernel เล็ก ๆ เพื่อ erode\n",
    "    eroded = cv2.erode(inverted, kernel, iterations=0)\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/eroded.png\", eroded)\n",
    "\n",
    "    # ขั้นตอนที่ 3: Find Contours (หาพื้นที่สีขาว ซึ่งเป็นรูปทรงของช่องตาราง)\n",
    "    #contours, hierarchy = cv2.findContours(eroded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours, hierarchy = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_contours = filter(lambda c: cv2.boundingRect(c)[2] > 40, contours)  # กรอง w > 10\n",
    "    contours = sorted(filtered_contours, key=lambda c: cv2.boundingRect(c)[3], reverse=True)[:10] # เรียงลำดับ contours ตามค่า h (ความสูง) จากมากไปน้อย\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0], reverse=False)  # เรียงลำดับ contours ตามค่า x จากน้อยไปมาก\n",
    " \n",
    "    # ขั้นตอนที่ 4: วนลูปดูผลลัพธ์ของ Contours แต่ละอัน\n",
    "\n",
    "    output = cv2.cvtColor(grid_lines.copy(), cv2.COLOR_GRAY2BGR)  # ไว้สำหรับวาดกรอบ\n",
    "\n",
    "    cell_contours = []\n",
    "\n",
    "    for i, cnt in enumerate(contours):\n",
    "        # หา bounding box ของ contour\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = int(cv2.contourArea(cnt))\n",
    "        cell_contours.append([x, y, w, h, area])\n",
    "\n",
    "        # วาดสี่เหลี่ยมครอบลงบน output เพื่อดู\n",
    "        cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "        print(f\"Contour #{i}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/Contours.png\", output)\n",
    "\n",
    "    return cell_contours\n",
    "\n",
    "def create_grid_image(table_img,\n",
    "                      col_percentages=[8, 40, 43, 46.33, 50, 58, 90, 93, 96.33, 100],\n",
    "                      #col_percentages=[8, 39, 43, 46.33, 50, 58, 89, 93, 96.33, 100],\n",
    "                      row_percentages=[9.22, 100],\n",
    "                      grid_color=(255, 255, 255),\n",
    "                      vertical_line_thickness_percent=0.005,   # 0.33% ของความกว้างภาพสำหรับเส้นแนวตั้ง\n",
    "                      horizontal_line_thickness_percent=0.008, # 0.33% ของความกว้างภาพสำหรับเส้นแนวนอน\n",
    "                      bg_color=(0, 0, 0),\n",
    "                      return_binary=True,\n",
    "                      threshold_val=127):\n",
    "    \n",
    "    \"\"\"\n",
    "    สร้างภาพตารางที่มีขนาด width x height โดยแบ่งคอลัมน์และแถวตามเปอร์เซ็นต์ที่กำหนด\n",
    "    ความหนาของเส้นจะถูกคำนวณเป็นเปอร์เซ็นต์ของความกว้างของภาพ\n",
    "    ถ้า return_binary=True จะทำการแปลงภาพเป็น binary (ขาวดำ) โดยใช้ threshold ที่กำหนด\n",
    "\n",
    "    :param width: ความกว้างของภาพ (พิกเซล)\n",
    "    :param height: ความสูงของภาพ (พิกเซล)\n",
    "    :param col_percentages: รายการเปอร์เซ็นต์สำหรับขอบขวาของแต่ละคอลัมน์ (เรียงจากน้อยไปมาก; คอลัมน์สุดท้าย = 100%)\n",
    "    :param row_percentages: รายการเปอร์เซ็นต์สำหรับขอบล่างของแต่ละแถว (เรียงจากน้อยไปมาก; แถวสุดท้าย = 100%)\n",
    "    :param grid_color: สีของเส้นตารางในรูปแบบ (B, G, R)\n",
    "    :param line_thickness_percent: ความหนาของเส้นในรูปแบบเปอร์เซ็นต์ของความกว้างภาพ\n",
    "    :param bg_color: สีพื้นหลังของภาพ\n",
    "    :param return_binary: ถ้า True จะคืนภาพในรูปแบบ binary (หลัง threshold) มิฉะนั้นคืนค่าเป็น BGR image\n",
    "    :param threshold_val: ค่าที่ใช้ threshold เมื่อแปลงเป็นภาพ binary\n",
    "    :return: ภาพตารางในรูปแบบ binary (ถ้า return_binary=True) หรือ BGR image (ถ้า False)\n",
    "    \"\"\"\n",
    "\n",
    "    height, width, = table_img.shape  # ได้ค่า (สูง, กว้าง)\n",
    "\n",
    "    image = np.full((height, width, 3), bg_color, dtype=np.uint8)\n",
    "    \n",
    "    # คำนวณความหนาของเส้นสำหรับแต่ละแนว (อย่างน้อย 1 พิกเซล)\n",
    "    vertical_thickness = max(1, int(width * vertical_line_thickness_percent))\n",
    "    horizontal_thickness = max(1, int(width * horizontal_line_thickness_percent))\n",
    "    \n",
    "    # คำนวณตำแหน่งเส้นแนวตั้ง (x_positions)\n",
    "    col_fracs = [p / 100.0 for p in col_percentages]\n",
    "    x_positions = [0] + [int(width * p) for p in col_fracs]\n",
    "    \n",
    "    # คำนวณตำแหน่งเส้นแนวนอน (y_positions)\n",
    "    row_fracs = [p / 100.0 for p in row_percentages]\n",
    "    y_positions = [0] + [int(height * p) for p in row_fracs]\n",
    "    \n",
    "    # วาดเส้นตารางแนวตั้งโดยใช้ความหนาที่คำนวณสำหรับแนวตั้ง\n",
    "    for x in x_positions:\n",
    "        cv2.line(image, (x, 0), (x, height), grid_color, vertical_thickness)\n",
    "    \n",
    "    # วาดเส้นตารางแนวนอนโดยใช้ความหนาที่คำนวณสำหรับแนวนอน\n",
    "    for y in y_positions:\n",
    "        cv2.line(image, (0, y), (width, y), grid_color, horizontal_thickness)\n",
    "    \n",
    "    # แปลงภาพเป็น binary หากต้องการ\n",
    "    if return_binary:\n",
    "        # แปลงเป็น grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # ใช้ threshold เพื่อแปลงเป็นภาพ binary\n",
    "        _, binary_image = cv2.threshold(gray, threshold_val, 255, cv2.THRESH_BINARY)\n",
    "        return binary_image\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "table_img, student_info_img, student_info_fh_img, student_info_sh_img, table_original_img = split_grade_table_and_students(binary_gaussian, denoised)\n",
    "table_persective_img, table_original_persective_img = persective_transformation(binary_gaussian, denoised)\n",
    "grid_img = create_grid_image(table_persective_img)\n",
    "line_mask, table_without_lines, table_without_lines_2 = hough_line_transform(table_persective_img, table_original_persective_img, grid_img)\n",
    "\n",
    "cell_contours = cells_detect(grid_img)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/table_img.png\", table_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_img.png\", student_info_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_original_img.png\", table_original_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_persective_img.png\", table_persective_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_original_persective_img.png\", table_original_persective_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_fh_img.png\", student_info_fh_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_sh_img.png\", student_info_sh_img)\n",
    "cv2.imwrite(f\"{output_folder}/grid_img.png\", grid_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# แบ่งส่วนตาราง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(cell_contours, table_without_lines):\n",
    "    cell_images = []\n",
    "    for idx, cell_position in enumerate(cell_contours):\n",
    "        x, y, w, h, area = cell_position\n",
    "        crop_img = table_without_lines[y:y+h, x:x+w]\n",
    "        cell_images.append(crop_img)\n",
    "        cv2.imwrite(f\"{output_folder}/cell_images/crop_img_{idx}.png\", crop_img)\n",
    "        #print(f\"Contour #{idx}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "\n",
    "    return cell_images\n",
    "        \n",
    "cell_images = crop_image(cell_contours, table_without_lines_2)\n",
    "\n",
    "cell_subject_code_img = cell_images[0]\n",
    "cell_subject_name_img = cell_images[1]\n",
    "cell_credit_img = cell_images[2]\n",
    "cell_academic_results_img = cell_images[3]\n",
    "cell_subject_code_img_2 = cell_images[5]\n",
    "cell_subject_name_img_2 = cell_images[6]\n",
    "cell_credit_img_2 = cell_images[7]\n",
    "cell_academic_results_img_2 = cell_images[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_text_group_in_cell(cell_img, mode=0, calculate_line_stats=None):\n",
    "    text_group_images = []\n",
    "\n",
    "    kernel_open = np.ones((4, 4), np.uint8)\n",
    "    #kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    remove_noise = cv2.morphologyEx(cell_img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/cell_images/remove_noise.jpg\", remove_noise)\n",
    "\n",
    "    kernel = np.ones((3, 13), np.uint8)\n",
    "    group_text_img = cv2.dilate(remove_noise, kernel, iterations=2)\n",
    "    rgb_image = cv2.cvtColor(cell_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #plt.imshow(group_text, cmap=\"gray\")\n",
    "\n",
    "    if(mode == 1):\n",
    "        # ใช้ Connected Component Analysis\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(group_text_img, connectivity=8)\n",
    "\n",
    "        text_stats = stats[1:]\n",
    "        sorted_indices = np.argsort(text_stats[:, 1])  # จัดเรียงตามค่า y (คอลัมน์ที่ 1)\n",
    "        sorted_stats = text_stats[sorted_indices]\n",
    "\n",
    "        # ใช้ Boolean Indexing เพื่อเอา noise ออก \n",
    "        sorted_stats = sorted_stats[sorted_stats[:, 4] >= 2000]\n",
    "        calculate_line_stats = []\n",
    "\n",
    "        for idx_stat, stat in enumerate(sorted_stats):\n",
    "            x, y, w, h, area = stat\n",
    "            #print(f\"CCA #{idx_stat}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            if idx_stat == (len(sorted_stats)-1):\n",
    "                #print(\"เข้าเงื่อนลำดัยสุดท้าย\",idx_stat)\n",
    "                x, y, w, h, area = stat\n",
    "                new_y = round(y-(h/2))\n",
    "                new_h = round(h+(h*0.8))\n",
    "                calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "            else:\n",
    "                current_stat = stat\n",
    "                next_stat = sorted_stats[idx_stat+1]\n",
    "\n",
    "                distance = next_stat[1] - current_stat[1]\n",
    "                line_spacing = distance/current_stat[3]\n",
    "\n",
    "                if line_spacing > 3 and line_spacing <= 5: # เป็นชื่อวิชาที่มีความยาวมากกว่า 1 บรรทัด\n",
    "                    #print(\"เข้าเงื่อนไข มากกว่า 1 บรรทัด\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+(h*2.5))\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "\n",
    "                elif line_spacing > 6: # เป็นช่องว่างที่ไม่มีวิชา\n",
    "                    #print(\"เข้าเงื่อนไข เป็นช่องว่างที่ไม่มีวิชา\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+h)\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "                \n",
    "                else: # เป็นชื่อวิชาที่มีความยาวแค่ว่า 1 บรรทัด\n",
    "                    #print(\"เข้าเงื่อนไข 1 บรรทัด\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+(h*0.8))\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "\n",
    "        calculate_line_stats = np.array(calculate_line_stats) \n",
    "\n",
    "            #print(f\"CCA #{idx_stat}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            #cv2.rectangle(rgb_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        #cv2.imwrite(f\"{output_folder}/cell_images/cca.jpg\", rgb_image)\n",
    "\n",
    "    text_stats = sorted_stats if mode == 1 else calculate_line_stats\n",
    "\n",
    "    \n",
    "    for idx, stats in enumerate(text_stats): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "   \n",
    "        if mode == 1:\n",
    "            cca_img = cell_img[y:y+h, x:x+w]\n",
    "        if mode == 2:\n",
    "            #print(f\"stats #{idx}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            if idx == 0: # ดักบัค crop รูปเกินขอบเขต\n",
    "                cca_img = cell_img[y+5:y+h, :]\n",
    "            elif idx == (len(text_stats)-1):\n",
    "                cca_img = cell_img[y:y+h-5, :]\n",
    "            else:\n",
    "                cca_img = cell_img[y:y+h, :]\n",
    "        text_group_images.append(cca_img)\n",
    "\n",
    "        # หาขนาดของภาพ (ความกว้างและความสูง)\n",
    "        image_height, image_width, _ = rgb_image.shape  # ได้ค่า (สูง, กว้าง, ช่องสี)\n",
    "        cv2.rectangle(rgb_image, (x, y), (image_width, y + h), (0, 255, 0), 1)\n",
    "\n",
    "    if mode == 1:\n",
    "        return text_group_images, calculate_line_stats, rgb_image\n",
    "    else:\n",
    "        return text_group_images, rgb_image\n",
    "\n",
    "# ตารางครึ่งแรก\n",
    "text_subject_code_images, calculate_line_stats_1, subject_code_img = detect_text_group_in_cell(cell_subject_code_img, 1)\n",
    "text_subject_name_images, subject_name_img = detect_text_group_in_cell(cell_subject_name_img, 2, calculate_line_stats_1)\n",
    "text_credit_images, credit_img = detect_text_group_in_cell(cell_credit_img, 2, calculate_line_stats_1)\n",
    "text_academic_results_images, academic_results_img = detect_text_group_in_cell(cell_academic_results_img, 2, calculate_line_stats_1)\n",
    "\n",
    "# ตารางครึ่งหลัง\n",
    "text_subject_code_images_2, calculate_line_stats_2, subject_code_img_2 = detect_text_group_in_cell(cell_subject_code_img_2, 1)\n",
    "text_subject_name_images_2, subject_name_img_2 = detect_text_group_in_cell(cell_subject_name_img_2, 2, calculate_line_stats_2)\n",
    "text_credit_images_2, credit_img_2 = detect_text_group_in_cell(cell_credit_img_2, 2, calculate_line_stats_2)\n",
    "text_academic_results_images_2, academic_results_img_2 = detect_text_group_in_cell(cell_academic_results_img_2, 2, calculate_line_stats_2)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_code_img.jpg\", subject_code_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_name_img.jpg\", subject_name_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_credit_img.jpg\", credit_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_academic_results_img.jpg\", academic_results_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_code_img_2.jpg\", subject_code_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_name_img_2.jpg\", subject_name_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_credit_img_2.jpg\", credit_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_academic_results_img_2.jpg\", academic_results_img_2)\n",
    "#cv2.imwrite(f\"{output_folder}/cell_images/cca_text_subject_name_images.jpg\", subject_name_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(text_subject_code_images):\n",
    "    print(idx)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### จับข้อความย่อยในกลุ่มข้อความของ cell ตาราง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n"
     ]
    }
   ],
   "source": [
    "from numpy import append\n",
    "\n",
    "def detect_sub_text_in_group(binary_image):\n",
    "\n",
    "    text_group = []\n",
    "    for idx, img in enumerate(binary_image):\n",
    "        #print(idx+1)\n",
    "\n",
    "        #plt.figure(figsize=(5,5))\n",
    "        #plt.imshow(img, cmap=\"gray\")\n",
    "        #plt.title(f\"binary_image\")\n",
    "        #plt.show()\n",
    "\n",
    "        sub_text_images = []\n",
    "\n",
    "        kernel_open = np.ones((3, 3), np.uint8)\n",
    "        remove_noise = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "        #plt.figure(figsize=(5,5))\n",
    "        #plt.imshow(remove_noise, cmap=\"gray\")\n",
    "        #plt.title(f\"remove_noise\")\n",
    "        #plt.show()\n",
    "\n",
    "        # เช็คว่าภาพเป็นสีดำทั้งหมดหรือไม่\n",
    "        if not np.any(remove_noise):  # ถ้าค่าพิกเซลทั้งหมดเป็น 0 (ดำสนิท)\n",
    "            print(\"ภาพเป็นสีดำทั้งหมด\")\n",
    "            sub_text_images.append(remove_noise)\n",
    "            #return sub_text_images \n",
    "        \n",
    "        else:\n",
    "            kernel = np.ones((6, 6), np.uint8)\n",
    "            dummy_image = cv2.dilate(remove_noise, kernel, iterations=2)\n",
    "\n",
    "            #plt.figure(figsize=(5,5))\n",
    "            #plt.imshow(dummy_image, cmap=\"gray\")\n",
    "            #plt.title(f\"dummy_image\")\n",
    "            #plt.show()\n",
    "\n",
    "            # ใช้ Connected Component Analysis\n",
    "            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dummy_image, connectivity=8)\n",
    "            char_stats = stats[1:] # ข้าม Background (index 0)\n",
    "            sorted_indices = np.argsort(char_stats[:, 0]) # จัดเรียงตามค่า x (คอลัมน์ที่ 0)\n",
    "            sorted_stats = char_stats[sorted_indices]\n",
    "\n",
    "            # ใช้ Boolean Indexing เพื่อเอา noise ออก \n",
    "            sorted_stats = sorted_stats[sorted_stats[:, 4] >= 200]\n",
    "\n",
    "            for idx, stats in enumerate(sorted_stats):\n",
    "                #x, y, w, h, area = stats[i]\n",
    "                x, y, w, h, area = stats\n",
    "\n",
    "                cca_img = img[y:y+h, x:x+w]\n",
    "                sub_text_images.append(cca_img)\n",
    "\n",
    "        text_group.append(sub_text_images)\n",
    "\n",
    "    return text_group\n",
    "    \n",
    "text_group_subject_code = detect_sub_text_in_group(text_subject_code_images)\n",
    "text_group_subject_name = detect_sub_text_in_group(text_subject_name_images)\n",
    "text_group_credit = detect_sub_text_in_group(text_credit_images)\n",
    "text_group_academic_results = detect_sub_text_in_group(text_academic_results_images)\n",
    "\n",
    "text_group_subject_code_2 = detect_sub_text_in_group(text_subject_code_images_2)\n",
    "text_group_subject_name_2 = detect_sub_text_in_group(text_subject_name_images_2)\n",
    "text_group_credit_2 = detect_sub_text_in_group(text_credit_images_2)\n",
    "text_group_academic_results_2 = detect_sub_text_in_group(text_academic_results_images_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx_g, text_group in enumerate(text_group_subject_code):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(sub_text, cmap=\"gray\")\n",
    "        plt.title(f\"sub text {idx_s+1}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## จับตัวอักษร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาพว่างเปล่า\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาพว่างเปล่า\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAEpCAYAAAC6MT8IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfEklEQVR4nO3deXCU9RkH8O/m2A25NhdsiMkCajAe4JFyrEcpJRIRrISMgkMLCgrCwpBgVWLVhIINV9FBwmGrULUSGxxqcVSEAHGsQSAUixJjhNBkJtlwlOzmIAfs0z8s77DmYsOGbPh9PzPPDPt7f+/7PrzZb3bf902yOhERENE1zaenGyCi7segEymAQSdSAINOpAAGnUgBDDqRAhh0IgUw6EQKYNCJFMCge9DmzZuh0+lw8ODBnm7lmvP4448jODi4p9votXpl0L/88ktkZWWhpqamW/fT0NCArKws7N27t1v3012qqqqwaNEijB49GiEhIdDpdO3+X37xi19Ap9O1qgceeODqNt1N1q1bh82bN3f7frry3Fy/fj0eeeQRmM1m6HQ6PP744x7vy8/jW7wKvvzySyxevBiPP/44wsLCum0/DQ0NWLx4MYAfg9DblJSUYPny5YiPj8eQIUNQWFjY4fzY2FhkZ2e7jMXExHRni1fNunXrEBUV1S0hulRXnpvLly9HbW0thg8fjqqqqm7pq1cGnS5PYmIizpw5g4iICGzduhWPPPJIh/ONRiN+/etfX6Xu6KKCggLt1by7Tk963Vv3rKwsPPvsswCAQYMGaW8xT5w4oc159913kZiYiD59+iAiIgJTpkxBRUWFtnzTpk3Q6XR46623XLb9hz/8ATqdDh9//DFOnDiBvn37AgAWL16s7ScrK6vTHhsaGjB79mxERkYiNDQU06ZNw9mzZ1vNW7duHW699VYYDAbExMTAarW6vOWbPn06AgICUFxc7LJecnIywsPDUVlZqY0dO3YMx44dc5kXEhKCiIiITvu91Pnz51FXV+fWOu05ePAgkpOTERUVhT59+mDQoEGYMWOGtnzv3r1tnk6cOHECOp2uzbfax48fR3JyMoKCghATE4Pf//736OwXMAcOHIhvv/0WBQUF2tfx0ndoNTU1SEtLQ1xcHAwGA2688UYsX74cTqcTACAiGD16NPr27YuTJ09q6zU3N2PIkCG44YYbUF9f3+lz8/Tp0/juu+/Q0NDg0t+AAQOg0+k6O5xXRnqZr7/+Wh577DEBIK+++qq888478s4770hdXZ2IiCxdulR0Op1MnjxZ1q1bJ4sXL5aoqCgZOHCgnD17VtvOhAkTxGg0Snl5uYiI/Pvf/xa9Xi8zZ84UEZG6ujpZv369AJCUlBRtP19//XW7vW3atEkAyJAhQ+S+++6TNWvWiNVqFR8fH/n5z38uTqdTm5uZmSkAJCkpSV5//XWZN2+e+Pr6yrBhw6S5uVlERM6ePSuxsbEybNgwOX/+vIiIbNiwQQDIO++847LvAQMGyIABA9rtLS8vTwDInj172lw+atQo8ff3F71eLwDEZDLJiy++qPXirurqagkPD5fBgwfLypUr5U9/+pP87ne/k5tvvlmbs2fPnjZ7KisrEwCyadMmbWz69OkSEBAg8fHx8pvf/EbWrl0rEyZMEADy0ksvddjLtm3bJDY2VhISErSv42effSYiIvX19TJ06FCJjIyUF154QTZs2CDTpk0TnU4nCxYs0LZx/PhxCQ4OlpSUFG1s0aJFotPppKCgQEQ6f25e/Jq39zUQEQkKCpLp06d3+P/pil4XdBGRlStXCgApKytzGT9x4oT4+vrKK6+84jJ+5MgR8fPzcxmvqqqSiIgIuf/++6WpqUnuvPNOMZvNYrfbtTmnTp0SAJKZmXlZfV0MemJioktAVqxYIQDkww8/FBGRkydPil6vl7Fjx8qFCxe0eWvXrhUA8tZbb2ljO3bsEACydOlS7ck2ceLEVvu+0qDPmDFDsrKy5IMPPpC3335bfvWrXwkAefTRRy/r//5T27ZtEwBy4MCBdue4G3QAMn/+fG3M6XTK+PHjRa/Xy6lTpzrs59Zbb5VRo0a1Gl+yZIkEBQXJ999/7zK+aNEi8fX11V4IREQ2btwoAOTdd9+Vffv2ia+vr6Slpbms195zU4RBd1t7B3P16tWi0+mktLRUTp065VI333yzJCUluczfsmWLAJDhw4eLTqeTXbt2uSzvatA3btzoMl5bWyt+fn4ye/ZsERF57733BIB8/PHHLvOampokNDRUUlNTXcZnz54ter1e7rjjDomKipLq6urL6udSnQW9LU899ZQAkMLCQrf3dzHEmZmZ7b4r6ErQS0pKXOZ+8sknAkC2bNnSYT/tBX3o0KHywAMPtHq+7Nq1Swv1pZKTkyU8PFzi4+Nl8ODB0tDQ4LK8o6Bfju4Keq87R+9IaWkpRATx8fHo27evSxUXF7ucXwHAlClTMH78eOzfvx9PPfUUxowZ45E+4uPjXR4HBwejf//+2rnaf/7zHwDATTfd5DJPr9fj+uuv15ZftGrVKkRERODw4cNYs2YN+vXr55E+O/PMM88AAHbt2uX2uqNGjUJqaioWL16MqKgoPPzww9i0aROampq63I+Pjw+uv/56l7HBgwcDgMs1GneUlpbi008/bfV8SUpKAoBWz5k333wTDQ0NKC0txebNm9GnT58u7fdqu6auujudTuh0OnzyySfw9fVttfynVzTPnDmj/XDL0aNH4XQ64ePjfd/7/vWvf2lPuCNHjuCxxx67KvuNi4sDAPz3v/91e12dToetW7di37592L59O3bs2IEZM2bgj3/8I/bt24fg4OB2L0BduHDhivp2h9PpxP3334/nnnuuzeUXv5FctHfvXu2b1ZEjR2CxWLq9R0/olUFv7wlyww03QEQwaNCgVl+gtlitVtTW1iI7OxsZGRl47bXXsHDhwk7305nS0lKMHj1ae1xXV4eqqio8+OCDAH68ygr8eJ/70leo5uZmlJWVaa8mAFBfX48nnngCt9xyC+6++26sWLECKSkpGDZsWJd6c8fx48cBQLv70BUjR47EyJEj8corr+C9997D1KlTkZubiyeffBLh4eEA0OqHS376juYip9OJ48ePu3xtv//+ewA/XlnvSEfPmbq6Opdj3p6qqirMnz8fY8eOhV6vx29/+1skJydrX8+O9tPTvO/l6zIEBQUBaP0EmTRpEnx9fbF48eJWt1xEBGfOnNEeb926Fe+//z6WLVuGRYsWYcqUKXjxxRe1Jw4ABAYGtrmfzrzxxhtoaWnRHq9fvx7nz5/HuHHjAABJSUnQ6/VYs2aNS59vvvkm7HY7xo8fr409//zzKC8vx1/+8hesXr0aAwcOxPTp01u9BW7r9trlcjgcrbYnIli6dCmAH2/nuevs2bOtvgZ33HEHAGj7GjBgAHx9ffH555+7zFu3bl272127dq1Lj2vXroW/v3+np11BQUFtfh0fffRRFBYWYseOHa2W1dTU4Pz589rjp556Ck6nE2+++SbeeOMN+Pn5YebMmS7/z/aem0D7t9euCo+f9V8F+/fvFwDy4IMPyttvvy1btmzRbmFkZ2cLALn77rtlxYoVsn79ennuueckPj5eVq5cKSI/3vqJioqS0aNHa7e8Tp8+LSaTSSwWi8uV8FtuuUWio6MlJydHtmzZIkeOHGm3r5/eXrt428zHx0fuvffeNm+vjR07VtauXSvz589vdXstPz9fdDqdZGVlaet9/vnn4uPjI88++6zLvtu76r5kyRJZsmSJTJkyRQDIjBkztLGL9uzZI9HR0ZKeni45OTmyatUqueeeewSAzJo1q9U2AbR5YetSr776qsTHx8tzzz0nGzdulFWrVslNN90koaGhcvz4cW3elClTxM/PTxYuXCg5OTkybtw4SUxM7PD22rRp0yQnJ0e7vfbCCy902IuIyNy5c0Wn08mSJUtky5Ytkp+fLyI/3l676667xM/PT5588klZv369rFq1SqZPny5BQUHa1fy33npLAMjmzZu1bb777rsCQHJycrSxjp6b7V11/8c//qF9TfR6vdx5553a445u57qjVwZd5Mcn8HXXXSc+Pj6trnJ+8MEHcu+990pQUJAEBQVJQkKCWK1W7YrtpEmTJCQkRE6cOOGyzQ8//FAAyPLly7WxL7/8UhITE7X7yx1dgb8Y9IKCApk1a5aEh4dLcHCwTJ06Vc6cOdNq/tq1ayUhIUH8/f3FZDLJnDlztHv9DodDBgwYIHfddZe0tLS4rJeeni4+Pj4uV8PbCzqAduui48ePyyOPPCIDBw6UgIAACQwMlMTERNmwYYPLNyeRH+8gAJApU6a0exxERA4dOiSPPfaYmM1mMRgM0q9fP5kwYYIcPHjQZd6pU6ckNTVVAgMDJTw8XGbPni3ffPNNm0EPCgqSY8eOydixYyUwMFBMJpNkZma6fGNuj81mk/Hjx0tISEirb1S1tbWSkZEhN954o+j1eomKipK7775bVq1aJc3NzVJRUSFGo1EeeuihVttNSUmRoKAgl29e7T032wv6xTsKbdWlx+BK6ET4d93p8n388ceYMGECvv76awwZMqSn26HL1CvP0ann7NmzB1OmTGHIexm+ohMpgK/oRApg0IkUwKATKaDbgp6Tk4OBAwciICAAI0aMwP79+7trV0TUiW65GPf+++9j2rRp2LBhA0aMGIHXXnsNeXl5KCkp6fQXMpxOJyorK7W/cUZE7RMR1NbWIiYmpuPf0/DI3fifGD58uFitVu3xhQsXJCYmRrKzsztdt6KiosMf8mCxWK2roqKiw1x5/K17c3MzioqKXH5JwMfHB0lJSW3+ccKmpiY4HA6thHf7iNwWEhLS4XKPB/306dO4cOECTCaTy7jJZILNZms1Pzs7G0ajUSuz2ezploiueZ2d5vb4VfeMjAzY7XatLv0jjkTkGR7/ffSoqCj4+vqiurraZby6uhrR0dGt5hsMBhgMBk+3QUSX8Pgrul6vR2JiIvLz87Uxp9OJ/Pz8XvPXOIiuOVd6hb0tubm5YjAYZPPmzXL06FGZNWuWhIWFic1m63Rdu93e41cwWazeVpf+9eK2dMufkpo8eTJOnTqFl19+GTabDXfccQc+/fTTVhfoiOjq8LrfXnM4HDAajT3dBlGvYrfbERoa2u7yHr/qTkTdj0EnUgCDTqQABp1IAQw6kQIYdCIFMOhECmDQiRTAoBMpgEEnUgCDTqQABp1IAQw6kQIYdCIFMOhECmDQiRTAoBMpgEEnUgCDTqQABp1IAQw6kQIYdCIFMOhECmDQiRTAoBMpgEEnUgCDTqQABp1IAW4H/fPPP8dDDz2EmJgY6HQ6/P3vf3dZLiJ4+eWX0b9/f/Tp0wdJSUkoLS31VL9E1AVuB72+vh633347cnJy2ly+YsUKrFmzBhs2bMBXX32FoKAgJCcno7Gx8YqbJaIu6vDT0zsBQLZt26Y9djqdEh0dLStXrtTGampqxGAwyJYtWy5rm3a7vcc/VJ7F6m1lt9s7zJVHz9HLyspgs9mQlJSkjRmNRowYMQKFhYVtrtPU1ASHw+FSRORZHg26zWYDAJhMJpdxk8mkLfup7OxsGI1GreLi4jzZEhHBC666Z2RkwG63a1VRUdHTLRFdczwa9OjoaABAdXW1y3h1dbW27KcMBgNCQ0Ndiog8y6NBHzRoEKKjo5Gfn6+NORwOfPXVV7BYLJ7cFRG5wc/dFerq6vDDDz9oj8vKynD48GFERETAbDYjLS0NS5cuRXx8PAYNGoSXXnoJMTExmDhxoif7JiJ3uHtLbc+ePW1e3p8+fbp2i+2ll14Sk8kkBoNBxowZIyUlJZe9fd5eY7Hcr85ur+lEROBFHA4HjEZjT7dB1KvY7fYOr2/1+FV3Iup+DDqRAhh0IgUw6EQKYNCJFMCgEymAQSdSAINOpAAGnUgBDDqRAhh0IgUw6EQKYNCJFMCgEymAQSdSAINOpAAGnUgBDDqRAhh0IgUw6EQKYNCJFMCgEymAQSdSAINOpAAGnUgBDDqRAhh0IgUw6EQKcCvo2dnZGDZsGEJCQtCvXz9MnDgRJSUlLnMaGxthtVoRGRmJ4OBgpKamorq62qNNE5F73Ap6QUEBrFYr9u3bh507d6KlpQVjx45FfX29Nic9PR3bt29HXl4eCgoKUFlZiUmTJnm8cSJyg7ufj36pkydPCgApKCgQEZGamhrx9/eXvLw8bU5xcbEAkMLCwsvaJj8fncVyvzr7fPQrOke32+0AgIiICABAUVERWlpakJSUpM1JSEiA2WxGYWHhleyKiK6AX1dXdDqdSEtLwz333IPbbrsNAGCz2aDX6xEWFuYy12QywWaztbmdpqYmNDU1aY8dDkdXWyKidnT5Fd1qteKbb75Bbm7uFTWQnZ0No9GoVVxc3BVtj4ha61LQ582bh48++gh79uxBbGysNh4dHY3m5mbU1NS4zK+urkZ0dHSb28rIyIDdbteqoqKiKy0RUUfcufjmdDrFarVKTEyMfP/9962WX7wYt3XrVm3su+++E4AX41is7qzOLsa5FfQ5c+aI0WiUvXv3SlVVlVYNDQ3anKefflrMZrPs3r1bDh48KBaLRSwWy2Xvg0Fnsdwvjwa9vZ1s2rRJm3Pu3DmZO3euhIeHS2BgoKSkpEhVVRWDzmJ1Y3UWdN3/A+w1HA4HjEZjT7dB1KvY7XaEhoa2u5w/606kAAadSAEMOpECGHQiBTDoRApg0IkUwKATKYBBJ1IAg06kAAadSAEMOpECGHQiBTDoRApg0IkUwKATKYBBJ1IAg06kAAadSAEMOpECGHQiBTDoRApg0IkUwKATKYBBJ1IAg06kAAadSAEMOpECGHQiBbgV9PXr12Po0KEIDQ1FaGgoLBYLPvnkE215Y2MjrFYrIiMjERwcjNTUVFRXV3u8aSJyj1tBj42NxbJly1BUVISDBw/il7/8JR5++GF8++23AID09HRs374deXl5KCgoQGVlJSZNmtQtjRORG9z5fPS2hIeHy5///GepqakRf39/ycvL05YVFxcLACksLLzs7fHz0Vks96uzz0fv8jn6hQsXkJubi/r6elgsFhQVFaGlpQVJSUnanISEBJjNZhQWFnZ1N0TkAX7urnDkyBFYLBY0NjYiODgY27Ztwy233ILDhw9Dr9cjLCzMZb7JZILNZmt3e01NTWhqatIeOxwOd1siok64/Yp+00034fDhw/jqq68wZ84cTJ8+HUePHu1yA9nZ2TAajVrFxcV1eVtE1I4un5z/35gxY2TWrFmSn58vAOTs2bMuy81ms6xevbrd9RsbG8Vut2tVUVHR4+c7LFZvq247R7/I6XSiqakJiYmJ8Pf3R35+vraspKQE5eXlsFgs7a5vMBi023UXi4g8y61z9IyMDIwbNw5msxm1tbV47733sHfvXuzYsQNGoxEzZ87EwoULERERgdDQUMyfPx8WiwUjR47srv6J6HK48zZ9xowZMmDAANHr9dK3b18ZM2aMfPbZZ9ryc+fOydy5cyU8PFwCAwMlJSVFqqqq3NkFb6+xWF2ozt6660RE4EUcDgeMRmNPt0HUq9jt9g5Pe/mz7kQKYNCJFMCgEymAQSdSAINOpAAGnUgBDDqRAhh0IgUw6EQKYNCJFMCgEymAQSdSAINOpAAGnUgBDDqRAhh0IgUw6EQKYNCJFMCgEymAQSdSAINOpAAGnUgBDDqRAhh0IgUw6EQKYNCJFMCgEymAQSdSwBUFfdmyZdDpdEhLS9PGGhsbYbVaERkZieDgYKSmpqK6uvpK+ySiK9DloB84cAAbN27E0KFDXcbT09Oxfft25OXloaCgAJWVlZg0adIVN0pEV8CtDy//v9raWomPj5edO3fKqFGjZMGCBSIiUlNTI/7+/pKXl6fNLS4uFgBSWFjIz0dnsbqpOvt89C69olutVowfPx5JSUku40VFRWhpaXEZT0hIgNlsRmFhYVd2RUQe4OfuCrm5uTh06BAOHDjQapnNZoNer0dYWJjLuMlkgs1ma3N7TU1NaGpq0h47HA53WyKiTrj1il5RUYEFCxbgr3/9KwICAjzSQHZ2NoxGo1ZxcXEe2S4RXcKdc/Nt27YJAPH19dUKgOh0OvH19ZVdu3YJADl79qzLemazWVavXt3mNhsbG8Vut2tVUVHR4+c7LFZvq87O0d166z5mzBgcOXLEZeyJJ55AQkICnn/+ecTFxcHf3x/5+flITU0FAJSUlKC8vBwWi6XNbRoMBhgMBnfaICI3uRX0kJAQ3HbbbS5jQUFBiIyM1MZnzpyJhQsXIiIiAqGhoZg/fz4sFgtGjhzpua6JyC1uX4zrzKuvvgofHx+kpqaiqakJycnJWLdunad3Q0Ru0ImI9HQTl3I4HDAajT3dBlGvYrfbERoa2u5y/qw7kQIYdCIFMOhECmDQiRTAoBMpgEEnUgCDTqQABp1IAQw6kQIYdCIFMOhECmDQiRTAoBMpgEEnUgCDTqQABp1IAQw6kQIYdCIFMOhECmDQiRTAoBMpgEEnUgCDTqQABp1IAQw6kQIYdCIFMOhECmDQiRTAoBMpwK2gZ2VlQafTuVRCQoK2vLGxEVarFZGRkQgODkZqaiqqq6s93jQRucftV/Rbb70VVVVVWn3xxRfasvT0dGzfvh15eXkoKChAZWUlJk2a5NGGiagLxA2ZmZly++23t7mspqZG/P39JS8vTxsrLi4WAFJYWHjZ+7Db7QKAxWK5UXa7vcNcuf2KXlpaipiYGFx//fWYOnUqysvLAQBFRUVoaWlBUlKSNjchIQFmsxmFhYXtbq+pqQkOh8OliMiz3Ar6iBEjsHnzZnz66adYv349ysrKcN9996G2thY2mw16vR5hYWEu65hMJthstna3mZ2dDaPRqFVcXFyX/iNE1D4/dyaPGzdO+/fQoUMxYsQIDBgwAH/729/Qp0+fLjWQkZGBhQsXao8dDgfDTuRhV3R7LSwsDIMHD8YPP/yA6OhoNDc3o6amxmVOdXU1oqOj292GwWBAaGioSxGRZ11R0Ovq6nDs2DH0798fiYmJ8Pf3R35+vra8pKQE5eXlsFgsV9woEV2By74cLiLPPPOM7N27V8rKyuSf//ynJCUlSVRUlJw8eVJERJ5++mkxm82ye/duOXjwoFgsFrFYLO7sglfdWawuVGdX3d0K+uTJk6V///6i1+vluuuuk8mTJ8sPP/ygLT937pzMnTtXwsPDJTAwUFJSUqSqqopBZ7G6uToLuk5EBF7E4XDAaDT2dBtEvYrdbu/w+hZ/1p1IAQw6kQIYdCIFMOhECmDQiRTAoBMpgEEnUgCDTqQABp1IAQw6kQIYdCIFMOhECmDQiRTAoBMpgEEnUgCDTqQABp1IAQw6kQIYdCIFMOhECmDQiRTAoBMpgEEnUgCDTqQABp1IAV4XdC/74BiiXqGz3Hhd0Gtra3u6BaJep7PceN1nrzmdTlRWVkJEYDabUVFRwc9Md5PD4UBcXByPnZt643ETEdTW1iImJgY+Pu2/bvtdxZ4ui4+PD2JjY+FwOAAAoaGhveagexseu67pbcftcj6U1OveuhOR5zHoRArw2qAbDAZkZmbCYDD0dCu9Do9d11zLx83rLsYRked57Ss6EXkOg06kAAadSAEMOpECvDboOTk5GDhwIAICAjBixAjs37+/p1vyKtnZ2Rg2bBhCQkLQr18/TJw4ESUlJS5zGhsbYbVaERkZieDgYKSmpqK6urqHOvZOy5Ytg06nQ1pamjZ2LR43rwz6+++/j4ULFyIzMxOHDh3C7bffjuTkZJw8ebKnW/MaBQUFsFqt2LdvH3bu3ImWlhaMHTsW9fX12pz09HRs374deXl5KCgoQGVlJSZNmtSDXXuXAwcOYOPGjRg6dKjL+DV53MQLDR8+XKxWq/b4woULEhMTI9nZ2T3YlXc7efKkAJCCggIREampqRF/f3/Jy8vT5hQXFwsAKSws7Kk2vUZtba3Ex8fLzp07ZdSoUbJgwQIRuXaPm9e9ojc3N6OoqAhJSUnamI+PD5KSklBYWNiDnXk3u90OAIiIiAAAFBUVoaWlxeU4JiQkwGw28zgCsFqtGD9+vMvxAa7d4+Z1v9Ry+vRpXLhwASaTyWXcZDLhu+++66GuvJvT6URaWhruuece3HbbbQAAm80GvV6PsLAwl7kmkwk2m60HuvQeubm5OHToEA4cONBq2bV63Lwu6OQ+q9WKb775Bl988UVPt+L1KioqsGDBAuzcuRMBAQE93c5V43Vv3aOiouDr69vqKmd1dTWio6N7qCvvNW/ePHz00UfYs2cPYmNjtfHo6Gg0NzejpqbGZb7qx7GoqAgnT57EXXfdBT8/P/j5+aGgoABr1qyBn58fTCbTNXncvC7oer0eiYmJyM/P18acTify8/NhsVh6sDPvIiKYN28etm3bht27d2PQoEEuyxMTE+Hv7+9yHEtKSlBeXq70cRwzZgyOHDmCw4cPa/Wzn/0MU6dO1f59TR63nr4a2Jbc3FwxGAyyefNmOXr0qMyaNUvCwsLEZrP1dGteY86cOWI0GmXv3r1SVVWlVUNDgzbn6aefFrPZLLt375aDBw+KxWIRi8XSg117p0uvuotcm8fNK4MuIvL666+L2WwWvV4vw4cPl3379vV0S14FQJu1adMmbc65c+dk7ty5Eh4eLoGBgZKSkiJVVVU917SX+mnQr8Xjxl9TJVKA152jE5HnMehECmDQiRTAoBMpgEEnUgCDTqQABp1IAQw6kQIYdCIFMOhECmDQiRTAoBMp4H/7OSRG2hvvqAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from turtle import width\n",
    "\n",
    "def scale_contour(contour, scale_factor=1.1):\n",
    "    # คำนวณ centroid ของ contour\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] == 0:\n",
    "        return contour\n",
    "    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    # แปลง contour เป็น float32 เพื่อคำนวณ\n",
    "    scaled_contour = contour.astype(np.float32)\n",
    "    for i in range(scaled_contour.shape[0]):\n",
    "        x, y = scaled_contour[i, 0]\n",
    "        # ปรับขนาดแต่ละจุดโดยคำนวณจาก centroid\n",
    "        scaled_x = cx + (x - cx) * scale_factor\n",
    "        scaled_y = cy + (y - cy) * scale_factor\n",
    "        scaled_contour[i, 0] = [scaled_x, scaled_y]\n",
    "    \n",
    "    return scaled_contour.astype(np.int32)\n",
    "\n",
    "def percentage_difference(value1, value2):\n",
    "    return abs(value1 - value2) / value1 * 100\n",
    "\n",
    "def get_centroid(contour):\n",
    "    # คำนวณ moments ของ contour\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = M[\"m10\"] / M[\"m00\"]\n",
    "        cy = M[\"m01\"] / M[\"m00\"]\n",
    "    else:\n",
    "        cx, cy = 0, 0\n",
    "    return (cx, cy)\n",
    "\n",
    "def detect_one_level_of_char(text_group):\n",
    "    debug = False\n",
    "    text_group_char = []\n",
    "    for idx_g, text_g in enumerate(text_group):\n",
    "\n",
    "        sub_text_char = []\n",
    "        for idx_s, sub_text in enumerate(text_g):\n",
    "\n",
    "            if not np.any(sub_text): # เช็คว่าเป็นภาพว่างรึเปล่า\n",
    "\n",
    "                print(\"ภาพว่างเปล่า\")\n",
    "                sub_text_char.append([sub_text])\n",
    "                \n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.imshow(sub_text, cmap=\"gray\")\n",
    "                plt.title(f\"text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "                plt.show()\n",
    "                continue\n",
    "\n",
    "            if debug == True:\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.imshow(sub_text, cmap=\"gray\")\n",
    "                plt.title(f\"text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "                plt.show()\n",
    "            \n",
    "            \n",
    "            #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "            skeleton_guohall = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "            if debug == True:\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.imshow(skeleton_guohall, cmap=\"gray\")\n",
    "                plt.title(f\"skeleton, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "                plt.show()\n",
    "            \n",
    "            \n",
    "            #kernel_open = np.ones((2, 2), np.uint8)\n",
    "            kernel_dummy = np.ones((2, 2), np.uint8)\n",
    "            #opening = cv2.morphologyEx(skeleton, cv2.MORPH_OPEN, kernel=kernel_open, iterations=2)\n",
    "            #closing = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_open, iterations=2)\n",
    "            dummy_image = cv2.dilate(skeleton_guohall, kernel_dummy, iterations=1)\n",
    "\n",
    "            if debug == True:\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.imshow(dummy_image, cmap=\"gray\")\n",
    "                plt.title(f\"dummy_image, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "                plt.show()\n",
    "            \n",
    "            \n",
    "            rgb_image = cv2.cvtColor(sub_text.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "\n",
    "            char_images = []\n",
    "            for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "                mask = np.zeros(sub_text.shape[:2], dtype=np.uint8)\n",
    "                cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "\n",
    "                kernel_mask = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # ปรับขนาด kernel ตามต้องการ\n",
    "                dilated_mask = cv2.dilate(mask, kernel_mask, iterations=1)\n",
    "\n",
    "                # ใช้ mask กับภาพต้นฉบับ เพื่อดึงเฉพาะส่วนภายใน contour\n",
    "                char_result = cv2.bitwise_and(sub_text, sub_text, mask=dilated_mask)\n",
    "\n",
    "                contours_char, hierarchy_char = cv2.findContours(char_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                largest_contour = max(contours_char, key=cv2.contourArea)\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "                area = int(cv2.contourArea(largest_contour))\n",
    "                crop_img = char_result[y:y+h, x:x+w]\n",
    "                char_images.append(crop_img)\n",
    "                \n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"crop_img, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                    plt.show()\n",
    "                #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "            sub_text_char.append(char_images)\n",
    "        text_group_char.append(sub_text_char)\n",
    "    return text_group_char\n",
    "\n",
    "def char_level(char_images):\n",
    "    debug = False\n",
    "\n",
    "    char_box = []\n",
    "    \n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(char_images, cmap=\"gray\")\n",
    "        plt.title(f\"char\")\n",
    "        plt.show()\n",
    "    \n",
    "    skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "    #skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "\n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(skeleton, cmap=\"gray\")\n",
    "        plt.title(f\"skeleton\")\n",
    "        plt.show()\n",
    "    \n",
    "    kernel_dummy = np.ones((3, 3), np.uint8)\n",
    "    closing_skeleton = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "    dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "    closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(closing_skeleton, cmap=\"gray\")\n",
    "    plt.title(f\"closing_skeleton\")\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(dummy_image, cmap=\"gray\")\n",
    "        plt.title(f\"dummy_image\")\n",
    "        plt.show()\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # เรียง contours ตามค่า y ของ centroid จากน้อยไปหามาก\n",
    "    sorted_contours = sorted(contours, key=lambda cnt: get_centroid(cnt)[1], reverse=True)\n",
    "\n",
    "    # คำนวณพื้นที่ของ contour แต่ละตัว และหาพื้นที่ที่ใหญ่ที่สุด\n",
    "    max_area = max(cv2.contourArea(cnt) for cnt in sorted_contours)\n",
    "\n",
    "    # กำหนด threshold เป็น 5% ของพื้นที่ที่ใหญ่ที่สุด\n",
    "    min_area_threshold = max_area * 0.05\n",
    "\n",
    "    # กรอง contours ที่มีพื้นที่ไม่น้อยกว่า threshold\n",
    "    filtered_contours = [cnt for cnt in sorted_contours if cv2.contourArea(cnt) >= min_area_threshold]\n",
    "\n",
    "\n",
    "    # หาก filtered_contours มีแค่ 2 ตัว\n",
    "    if len(filtered_contours) == 2:\n",
    "\n",
    "        area0 = cv2.contourArea(filtered_contours[0])\n",
    "        area1 = cv2.contourArea(filtered_contours[1])\n",
    "        # คำนวณความแตกต่างเป็นอัตราส่วนของ contour ที่มีพื้นที่ใหญ่กว่า\n",
    "        diff_ratio = abs(area0 - area1) / max(area0, area1)\n",
    "        if diff_ratio <= 0.05:\n",
    "            print(\"เหมือนกัน\")\n",
    "\n",
    "            kernel_same = np.ones((4, 4), np.uint8)\n",
    "            contours, hierarchy = cv2.findContours(char_images, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(closing_same, cmap=\"gray\")\n",
    "            plt.title(f\"closing_same\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            level = 1\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            contour_area = int(cv2.contourArea(largest_contour))\n",
    "            crop_img = char_images[y:y+h, x:x+w]\n",
    "            char_box.append([crop_img, level])\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"Level : {level} area: {contour_area}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            return char_box\n",
    "    elif len(filtered_contours) >= 3: # เอาไว้แก้ปัญหาพวกคำว่า \"ชั้น, บัน\" หรือทุกคำที่มี \"  ั \"\n",
    "        print(\"len(filtered_contours) >= 3\")\n",
    "        # คำนวณ centroid และพื้นที่ของแต่ละ contour ใน filtered_contours\n",
    "        centroids_filtered = [get_centroid(cnt) for cnt in filtered_contours]\n",
    "        areas_filtered = [cv2.contourArea(cnt) for cnt in filtered_contours]\n",
    "    \n",
    "        # หาตำแหน่งของ contour ที่มีพื้นที่มากที่สุด\n",
    "        max_area_idx = areas_filtered.index(max(areas_filtered))\n",
    "        max_centroid_y = centroids_filtered[max_area_idx][1]\n",
    "        max_area = areas_filtered[max_area_idx]\n",
    "    \n",
    "        # สร้าง list ใหม่เพื่อจัดกลุ่ม contour ที่จะอยู่ก่อนและหลัง\n",
    "        remain_contours = []\n",
    "        move_to_end = []\n",
    "\n",
    "        find_status = False\n",
    "        # วนลูปผ่านแต่ละ contour พร้อมกับ centroid และพื้นที่\n",
    "        for idx, (cnt, cent, area) in enumerate(zip(filtered_contours, centroids_filtered, areas_filtered)):\n",
    "            # ถ้าเป็น contour ที่มีพื้นที่มากที่สุด ให้เก็บไว้ใน remain_contours\n",
    "            if idx == max_area_idx:\n",
    "                remain_contours.append(cnt)\n",
    "            else:\n",
    "                # ตรวจสอบว่า centroid แกน y ของ contour นี้ต่างจาก max_centroid_y ไม่เกิน 20%\n",
    "                # และมีพื้นที่ไม่น้อยกว่า 30% ของ max_area\n",
    "                if abs(cent[1] - max_centroid_y) <= 0.2 * max_centroid_y and area >= 0.3 * max_area:\n",
    "                    print(\"มีอยู่หลังสุด\")\n",
    "                    move_to_end.append(cnt)\n",
    "                    find_status = True\n",
    "                else:\n",
    "                    remain_contours.append(cnt)\n",
    "        \n",
    "        # รวม list ที่เหลือเข้าด้วยกัน โดย contour ที่ตรงเงื่อนไขจะอยู่ท้ายสุด\n",
    "        filtered_contours = remain_contours + move_to_end\n",
    "\n",
    "        if find_status == True:\n",
    "            \n",
    "            # คำนวณพื้นที่และ centroid แกน x ของ contour ตัวแรกและตัวสุดท้าย\n",
    "            first_area = cv2.contourArea(filtered_contours[0])\n",
    "            last_area = cv2.contourArea(filtered_contours[-1])\n",
    "            first_centroid = get_centroid(filtered_contours[0])\n",
    "            last_centroid = get_centroid(filtered_contours[-1])\n",
    "\n",
    "            # ตรวจสอบเงื่อนไข ถ้า contour ตัวแรกมี area มากกว่าและ centroid_x มากกว่าตัวสุดท้าย\n",
    "            if first_area > last_area and first_centroid[0] > last_centroid[0]:\n",
    "                print(\"มีการสลับตัวแรกกับตัวสุดท้าย\")\n",
    "                # สลับตำแหน่ง contour ตัวแรกกับตัวสุดท้าย\n",
    "                filtered_contours[0], filtered_contours[-1] = filtered_contours[-1], filtered_contours[0]\n",
    "\n",
    "            # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "            for idx_c, cnt in enumerate(filtered_contours):\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = int(cv2.contourArea(cnt))\n",
    "                char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "            for idx, box in enumerate(char_box):\n",
    "                if idx == 0:\n",
    "                    box.append(1)\n",
    "                elif idx == (len(char_box)-1):\n",
    "                    box.append(1)\n",
    "                else:\n",
    "                    box.append(2)\n",
    "\n",
    "            char_level_images = []\n",
    "            for idx, box in enumerate(char_box):\n",
    "                x, y, w, h, area, level = box\n",
    "                crop_img = char_images[y:y+h, x:x+w]\n",
    "                char_level_images.append([crop_img, level])\n",
    "\n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"char : {idx+1} Level : {level} area: {area}\")\n",
    "                    plt.show()\n",
    "            return char_level_images\n",
    "\n",
    "        else:\n",
    "            # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "            for idx_c, cnt in enumerate(filtered_contours):\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = int(cv2.contourArea(cnt))\n",
    "                char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "            for idx, box in enumerate(char_box):\n",
    "                if idx == max_index:\n",
    "                    # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "                    box.append(1)\n",
    "                elif idx < max_index:\n",
    "                    # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "                    box.append(0)\n",
    "                #elif idx == (len(char_box)-1):\n",
    "                #    # ถ้าเป็น list append 1\n",
    "                #    box.append(1)\n",
    "                else:\n",
    "                    # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append 2\n",
    "                    box.append(2)\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "            if max_index != 0:\n",
    "                char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "            char_level_images = []\n",
    "            for idx, box in enumerate(char_box):\n",
    "                x, y, w, h, area, level = box\n",
    "                crop_img = char_images[y:y+h, x:x+w]\n",
    "                char_level_images.append([crop_img, level])\n",
    "\n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"char : {idx+1} Level : {level} area: {area}\")\n",
    "                    plt.show()\n",
    "        \n",
    "            return char_level_images\n",
    "\n",
    " #########################\n",
    "    # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "    for idx_c, cnt in enumerate(filtered_contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        contour_area = int(cv2.contourArea(cnt))\n",
    "        char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # สำหรับ list ที่อยู่หลัง list ที่มี area มากที่สุด เราจะเริ่มนับจาก 2\n",
    "    after_counter = 2\n",
    "\n",
    "    # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "    for idx, box in enumerate(char_box):\n",
    "        if idx == max_index:\n",
    "            # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "            box.append(1)\n",
    "        elif idx < max_index:\n",
    "            # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "            box.append(0)\n",
    "        else:\n",
    "            # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append sequential number เริ่มจาก 2\n",
    "            box.append(after_counter)\n",
    "            #after_counter += 1\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "    if max_index != 0:\n",
    "        char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(char_images, cmap=\"gray\")\n",
    "    plt.title(f\"char_images\")\n",
    "    plt.show()\n",
    "    '''\n",
    "        \n",
    "    char_level_images = []\n",
    "    for idx, box in enumerate(char_box):\n",
    "        x, y, w, h, area, level = box\n",
    "        crop_img = char_images[y:y+h, x:x+w]\n",
    "        char_level_images.append([crop_img, level])\n",
    "\n",
    "        if debug == True:\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"char : {idx+1} Leve : {level} area: {area}\")\n",
    "            plt.show()\n",
    "        \n",
    "    return char_level_images\n",
    "       \n",
    "def detect_char(text_group):\n",
    "    text_group_char = []\n",
    "    for idx_g, text_g in enumerate(text_group):\n",
    "\n",
    "        sub_text_char = []\n",
    "        for idx_s, sub_text in enumerate(text_g):\n",
    "            rgb_image = cv2.cvtColor(sub_text, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "            #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "            kernel_dummy = np.ones((3, 3), np.uint8)\n",
    "            dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "            kernel_closing = np.ones((7, 1), np.uint8)\n",
    "            closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_closing, iterations=1)\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "            \n",
    "            char_images_with_levels = []\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(sub_text, cmap=\"gray\")\n",
    "            plt.title(f\"text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(skeleton, cmap=\"gray\")\n",
    "            plt.title(f\"skeleton, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(dummy_image, cmap=\"gray\")\n",
    "            plt.title(f\"dummy_image, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(closing, cmap=\"gray\")\n",
    "            plt.title(f\"closing, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "                # สมมุติว่าเราได้ contour (cnt) จาก cv2.findContours แล้ว\n",
    "                #scaled_cnt = scale_contour(cnt, scale_factor=1.0)\n",
    "\n",
    "                #char_height, char_width = h, w\n",
    "                #mask = np.zeros((char_height, char_width), dtype=np.uint8)\n",
    "\n",
    "                mask = np.zeros(sub_text.shape[:2], dtype=np.uint8)\n",
    "\n",
    "                rgb_mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "                # วาด contour ลงใน mask โดยเติมเต็ม (thickness = -1) ให้ภายใน contour เป็นสีขาว (255)\n",
    "                cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "                kernel_mask = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # ปรับขนาด kernel ตามต้องการ\n",
    "                dilated_mask = cv2.dilate(mask, kernel_mask, iterations=1)\n",
    "\n",
    "                '''\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(mask, cmap=\"gray\")\n",
    "                plt.title(f\"mask, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(dilated_mask, cmap=\"gray\")\n",
    "                plt.title(f\"dilated_mask, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                # ใช้ mask กับภาพต้นฉบับ เพื่อดึงเฉพาะส่วนภายใน contour\n",
    "                char_result = cv2.bitwise_and(sub_text, sub_text, mask=dilated_mask)\n",
    "                char_images_with_levels.extend(char_level(char_result))\n",
    "                #print(\"cher_level_images :\", len(char_images_with_levels))\n",
    "\n",
    "                '''\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(char_result, cmap=\"gray\")\n",
    "                plt.title(f\"char_result, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                '''\n",
    "                for idx_c_l, cher_level in enumerate(cher_level_images):\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(cher_level[0], cmap=\"gray\")\n",
    "                    plt.title(f\"cnt, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c_l+1}, level:{cher_level[1]}\")\n",
    "                    plt.show()\n",
    "                '''\n",
    "            \n",
    "                '''\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(result, cmap=\"gray\")\n",
    "                plt.title(f\"cnt, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "            sub_text_char.append(char_images_with_levels)\n",
    "            \n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(rgb_image, cmap=\"gray\")\n",
    "            plt.title(f\"Contour, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "        text_group_char.append(sub_text_char)\n",
    "    return text_group_char\n",
    "\n",
    "\n",
    "#text_group_char_subject_code = detect_one_level_of_char(text_group_subject_code[:])\n",
    "#text_group_char_subject_name = detect_char(text_group_subject_name[:])\n",
    "text_group_char_credit = detect_one_level_of_char(text_group_credit[:])\n",
    "#text_group_char_academic_results = detect_one_level_of_char(text_group_academic_results[:])\n",
    "\n",
    "\n",
    "#text_group_char_subject_code_2 = detect_one_level_of_char(text_group_subject_code_2[:])\n",
    "#text_group_char_subject_name_2 = detect_char(text_group_subject_name_2[:])\n",
    "#text_group_char_credit_2 = detect_one_level_of_char(text_group_credit_2[:])\n",
    "#text_group_char_academic_results_2 = detect_one_level_of_char(text_group_academic_results_2[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_char\n",
    "for idx_g, text_group in enumerate(text_group_char_subject_name):\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(char[0], cmap=\"gray\")\n",
    "            plt.title(f\"text_group :{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1} \")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_one_level_of_char\n",
    "for idx_g, text_group in enumerate(text_group_char_credit):\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            #continue\n",
    "            #print(idx_s)\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(char, cmap=\"gray\")\n",
    "            plt.title(f\"char, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนายตัวอักษร 1 ระดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_subject_code_tn = \"../models/char_subject_code_tn_model.h5\"\n",
    "model_path_char_academic_results_tn = \"../models/char_academic_results_tn_model.h5\"\n",
    "\n",
    "model_char_subject_code_tn = load_model(model_path_char_subject_code_tn)\n",
    "model_char_academic_results_tn= load_model(model_path_char_academic_results_tn)\n",
    "\n",
    "# สร้าง Mapping ของโมเดลตามระดับ\n",
    "models_one_level = {\n",
    "    0: model_char_subject_code_tn,\n",
    "    1: model_char_academic_results_tn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "ประมวลผลเสร็จสิ้น\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_subject_code_tn = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-',\n",
    "]\n",
    "\n",
    "char_academic_results_tn = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    'ก', 'ข', 'ถ', 'ท', 'น', 'ป', 'ผ', 'ม', 'ร', 'ล', 'ส', '.'\n",
    "]\n",
    "\n",
    "char_labels = {\n",
    "    0: char_subject_code_tn,\n",
    "    1: char_academic_results_tn,\n",
    "}\n",
    "\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_one_level(text_group_char, char_model=0):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "    text_block = []\n",
    "\n",
    "    for idx_g, text_group in enumerate(text_group_char):\n",
    "        text_result = \"\"\n",
    "\n",
    "        for idx_s, sub_text in enumerate(text_group):\n",
    "            sub_text_result = \"\"\n",
    "\n",
    "            for idx_c, char in enumerate(sub_text):\n",
    "                \n",
    "                if char is None:\n",
    "                    print(f\"Character image {idx_c} is None.\")\n",
    "                    continue  # ข้ามภาพนี้\n",
    "                else:\n",
    "                    if not np.any(sub_text):\n",
    "                        sub_text_result = \"-\"\n",
    "                        continue\n",
    "\n",
    "                    # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                    padded_img = resize_with_min_padding(char, input_size, min_padding=1)\n",
    "\n",
    "                    # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                    normalized_img = padded_img / 255.0\n",
    "\n",
    "                    if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                        normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                        processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                    if char_model in models_one_level:\n",
    "                        prediction = models_one_level[char_model].predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence_score = np.max(prediction)\n",
    "\n",
    "                        class_char = char_labels[char_model]\n",
    "                        predicted_letter = class_char[predicted_class]\n",
    "                        sub_text_result += predicted_letter\n",
    "                    '''\n",
    "                    if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                        normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                        processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                        prediction = model_char_subject_code_tn.predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "\n",
    "                        char_label_model = char_labels[label]\n",
    "                        predicted_letter = char_label_model[predicted_class]\n",
    "\n",
    "                        sub_text_result += predicted_letter\n",
    "                    '''\n",
    "\n",
    "            text_result += sub_text_result\n",
    "            text_result += \" \"\n",
    "        text_block.append(text_result)\n",
    "\n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_block   \n",
    "            \n",
    "\n",
    "#text_box_subject_code = predict_text_one_level(text_group_char_subject_code[:], 0)\n",
    "text_box_credit = predict_text_one_level(text_group_char_credit, 0)\n",
    "#text_box_academic_results = predict_text_one_level(text_group_char_academic_results, 1)\n",
    "\n",
    "#text_box_subject_code_2 = predict_text_one_level(text_group_char_subject_code_2[:], 0)\n",
    "#text_box_credit_2 = predict_text_one_level(text_group_credit_2, 0)\n",
    "#text_box_academic_results_2 = predict_text_one_level(text_group_char_academic_results_2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: 3 \n",
      "text 2: 3 \n",
      "text 3: 3 \n",
      "text 4: - \n",
      "text 5: 3 \n",
      "text 6: 3 \n",
      "text 7: 3 \n",
      "text 8: 3 \n",
      "text 9: 3 \n",
      "text 10: 3 \n",
      "text 11: 2 \n",
      "text 12: 2 \n",
      "text 13: 2 \n",
      "text 14: 1 \n",
      "text 15: - \n",
      "text 16: 3 \n",
      "text 17: 3 \n",
      "text 18: 3 \n",
      "text 19: 3 \n",
      "text 20: 3 \n",
      "text 21: 3 \n",
      "text 22: 3 \n"
     ]
    }
   ],
   "source": [
    "def show_information(array):\n",
    "    for idx, data in enumerate(array):\n",
    "        print(f\"text {idx + 1}: {data}\")\n",
    "\n",
    "#show_information(text_box_subject_code[:])\n",
    "#show_information(text_box_academic_results[:])\n",
    "show_information(text_box_credit[:])\n",
    "#show_information(text_box_subject_code_2[:])\n",
    "#show_information(text_box_academic_results_2[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนายตัวอักษรหลายระดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rule_Based_Post_Processing(word):\n",
    "\n",
    "    if not word:\n",
    "        return word\n",
    "    #word = word.replace(\"ัั\", \"ะ\")\n",
    "    word = word.replace(\"เเ\", \"แ\")\n",
    "    #word = word.replace(\"้้\", \"ะ\")\n",
    "    #word = word.replace(\"้ั\", \"ะ\")\n",
    "    #word = word.replace(\"ั้\", \"ะ\")\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_level_0 = \"../models/char_level_0_model.h5\"\n",
    "model_path_char_level_1 = \"../models/char_level_1_model.h5\"\n",
    "model_path_char_level_2 = \"../models/char_level_2_model.h5\"\n",
    "model_path_char_level_3 = \"../models/char_level_3_model.h5\"\n",
    "\n",
    "model_char_level_0 = load_model(model_path_char_level_0)\n",
    "model_char_level_1 = load_model(model_path_char_level_1)\n",
    "model_char_level_2 = load_model(model_path_char_level_2)\n",
    "model_char_level_3 = load_model(model_path_char_level_3)\n",
    "\n",
    "# สร้าง Mapping ของโมเดลตามระดับ\n",
    "models = {\n",
    "    0: model_char_level_0,\n",
    "    1: model_char_level_1,\n",
    "    2: model_char_level_2,\n",
    "    3: model_char_level_3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "ประมวลผลเสร็จสิ้น\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_level_0_label = [\n",
    "    'ุ', 'ู'\n",
    "]\n",
    "\n",
    "char_level_1_label = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    \n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "\n",
    "    'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', \n",
    "    'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', \n",
    "    'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', \n",
    "    'ห', 'ฬ', 'อ', 'ฮ',\n",
    "\n",
    "    'ะ','า', 'เ', 'แ', 'โ', 'ฤ', 'ใ', 'ไ',\n",
    "\n",
    "    '+', '-', '*', '(', ')', '.', '=', '/', '|'\n",
    "]\n",
    "\n",
    "char_level_2_label = [\n",
    "     'ิ', 'ี', 'ึ', 'ื', '็', 'ั', 'ํ', '่', '้', '๊', '๋', '์'\n",
    "]\n",
    "\n",
    "char_level_3_label = [\n",
    "    '่', '้', '๊', '๋',\n",
    "]\n",
    "\n",
    "char_level_labels = {\n",
    "    0: char_level_0_label,\n",
    "    1: char_level_1_label,\n",
    "    2: char_level_2_label,\n",
    "    3: char_level_3_label,\n",
    "}\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_multi_level(text_group_char):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "    text_block = []\n",
    "\n",
    "    for idx_g, text_group in enumerate(text_group_char):\n",
    "        text_result = \"\"\n",
    "\n",
    "        for idx_s, sub_text in enumerate(text_group):\n",
    "            sub_text_result = \"\"\n",
    "\n",
    "            for idx_c, char in enumerate(sub_text):\n",
    "                char_image, char_level = char\n",
    "\n",
    "                if char is None:\n",
    "                    print(f\"Character image {idx_c} is None.\")\n",
    "                    continue  # ข้ามภาพนี้\n",
    "                else:\n",
    "\n",
    "                    # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                    padded_img = resize_with_min_padding(char_image, input_size, min_padding=1)\n",
    "\n",
    "                    '''\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(padded_img, cmap=\"gray\")\n",
    "                    plt.title(f\"Char, text group:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}, level: {char_level}\")\n",
    "                    plt.show()\n",
    "                    '''\n",
    "                    \n",
    "                    # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                    normalized_img = padded_img / 255.0\n",
    "\n",
    "                    if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                        normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                        processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                        if char_level in models:\n",
    "                            prediction = models[char_level].predict(processed_image)\n",
    "                            predicted_class = np.argmax(prediction)\n",
    "                            confidence_score = np.max(prediction)\n",
    "\n",
    "                            class_level = char_level_labels[char_level]\n",
    "                            predicted_letter = class_level[predicted_class]\n",
    "                        else:\n",
    "                            print(\"level ไม่ตรง\")\n",
    "                            prediction = models[2].predict(processed_image)\n",
    "                            predicted_class = np.argmax(prediction)\n",
    "                            confidence_score = np.max(prediction)\n",
    "\n",
    "                            class_level = char_level_labels[2]\n",
    "                            predicted_letter = class_level[predicted_class]\n",
    "\n",
    "                        sub_text_result += predicted_letter\n",
    "            sub_text_result += \" \"\n",
    "            text_result += sub_text_result\n",
    "            text_result_post = Rule_Based_Post_Processing(text_result)\n",
    "        text_block.append(text_result_post)\n",
    "        \n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_block \n",
    "        \n",
    "                    \n",
    "text_box_subject_name = predict_text_multi_level(text_group_char_subject_name[:])\n",
    "#text_box_subject_name_2 = predict_text_multi_level(text_group_char_subject_name_2[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: โปรเ(กรมdาเร์จรูปให็องานบ้ญชี \n"
     ]
    }
   ],
   "source": [
    "def show_information(array):\n",
    "    for idx, data in enumerate(array):\n",
    "        print(f\"text {idx + 1}: {data}\")\n",
    "\n",
    "#show_information(text_box_subject_code[:])\n",
    "show_information(text_box_subject_name[:])\n",
    "#show_information(text_box_subject_name_2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity ratio: 0.6896551724137931\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "str1 = \"โปรแกรมสำเร็จรูปเพื่องานบัญชี\"\n",
    "str2 = \"โปรเ(กรมdาเร์จรูปให็องานบ้ญชี\"\n",
    "\n",
    "matcher = difflib.SequenceMatcher(None, str1, str2)\n",
    "print(\"Similarity ratio:\", matcher.ratio())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ข้อมูลนักศึกษา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_border(image, left_percent=0, right_percent=0, top_percent=0, bottom_percent=0):\n",
    "    \n",
    "    # หาความกว้างและความสูงของภาพ\n",
    "    height, width = image.shape\n",
    "\n",
    "    # คำนวณพิกัดที่จะตัด (แปลงเป็นพิกเซล)\n",
    "    x_start = int(width * left_percent)\n",
    "    x_end = int(width * (1 - right_percent))\n",
    "    y_start = int(height * top_percent)\n",
    "    y_end = int(height * (1 - bottom_percent))\n",
    "\n",
    "    # ตัดภาพ (Crop)\n",
    "    cropped_img = image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/cropped_fh.jpg\", cropped_img)\n",
    "    \n",
    "    return cropped_img\n",
    "\n",
    "def find_text_student_info_fh(student_info_fh_img):\n",
    "    student_info_fh_img = crop_border(student_info_fh_img.copy(), 0.06, 0.06, 0.06, 0.01)\n",
    "\n",
    "    rgb_image = cv2.cvtColor(student_info_fh_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # กำหนด kernel (ขนาดของ kernel สามารถปรับเปลี่ยนได้ตามความเหมาะสม)\n",
    "    kernel_open = np.ones((2, 2), np.uint8)\n",
    "    kernel_close = np.ones((6, 50), np.uint8)\n",
    "    \n",
    "    opening = cv2.morphologyEx(student_info_fh_img.copy(), cv2.MORPH_OPEN, kernel=kernel_open, iterations=1)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel=kernel_close, iterations=2)\n",
    "\n",
    "    rgb_closing_image = cv2.cvtColor(closing, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/opening.jpg\", opening)\n",
    "    cv2.imwrite(f\"{output_folder}/closing.jpg\", closing)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closing, connectivity=8)\n",
    "\n",
    "    # 1. เอา stats ตัวแรก (background) ออก\n",
    "    stats_no_bg = stats[1:]\n",
    "\n",
    "    # 2. เรียง stats ใหม่โดยใช้ค่า area (คอลัมน์ที่ 4) จากมากไปน้อย\n",
    "    sorted_indices = np.argsort(-stats_no_bg[:, 4])\n",
    "    sorted_stats = stats_no_bg[sorted_indices]\n",
    "\n",
    "    # 3. เลือกแค่ 13 element ที่มีค่า area สูงสุด\n",
    "    top_13_stats = sorted_stats[:13]\n",
    "    top_13_stats_sorted_by_y = top_13_stats[np.argsort(top_13_stats[:, 1])]\n",
    "\n",
    "    img_height, img_width = student_info_fh_img.shape[:2]\n",
    "\n",
    "    # กำหนด margin เป็นเปอร์เซ็นต์ของขนาด bounding box\n",
    "    # เช่น กำหนด 10% ของความกว้าง/ความสูงของ bounding box สำหรับแต่ละด้าน\n",
    "    left_margin_percent = 0.1    # ขยายซ้าย 10%\n",
    "    right_margin_percent = 0.1   # ขยายขวา 10%\n",
    "    top_margin_percent = 0.2     # ขยายบน 20%\n",
    "    bottom_margin_percent = 0.1  # ขยายล่าง 10%\n",
    "\n",
    "    text_group_stud_fh = []\n",
    "    for idx, stats in enumerate(top_13_stats_sorted_by_y): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "\n",
    "        # คำนวณ margin ตามเปอร์เซ็นต์ของ bounding box\n",
    "        left_margin = int(w * left_margin_percent)\n",
    "        right_margin = int(w * right_margin_percent)\n",
    "        top_margin = int(h * top_margin_percent)\n",
    "        bottom_margin = int(h * bottom_margin_percent)\n",
    "\n",
    "        # คำนวณพิกัดใหม่โดยใช้ margin ที่คำนวณได้\n",
    "        x_new = max(x - left_margin, 0)\n",
    "        y_new = max(y - top_margin, 0)\n",
    "        x_end = min(x + w + right_margin, img_width)\n",
    "        y_end = min(y + h + bottom_margin, img_height)\n",
    "\n",
    "        cluster_img = student_info_fh_img[y_new:y_end, x_new:x_end]\n",
    "        text_group_stud_fh.append(cluster_img)\n",
    "\n",
    "        # วาดกรอบที่ขยายแล้วลงบนภาพ\n",
    "        cv2.rectangle(rgb_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        cv2.rectangle(rgb_closing_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        \n",
    "    cv2.imwrite(f\"{output_folder}/cca_top_13_stats.jpg\", rgb_image)\n",
    "    cv2.imwrite(f\"{output_folder}/cca_rgb_closing_image.jpg\", rgb_closing_image)\n",
    "\n",
    "    return text_group_stud_fh[1:]\n",
    "\n",
    "def find_text_student_info_sh(student_info_sh_img):\n",
    "    student_info_sh_img = crop_border(student_info_sh_img.copy(), 0.05, 0.00, 0.05, 0.01)\n",
    "\n",
    "    rgb_image = cv2.cvtColor(student_info_sh_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # กำหนด kernel (ขนาดของ kernel สามารถปรับเปลี่ยนได้ตามความเหมาะสม)\n",
    "    kernel_open = np.ones((2, 2), np.uint8)\n",
    "    kernel_close = np.ones((8, 50), np.uint8)\n",
    "    \n",
    "    opening = cv2.morphologyEx(student_info_sh_img.copy(), cv2.MORPH_OPEN, kernel=kernel_open, iterations=1)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel=kernel_close, iterations=2)\n",
    "\n",
    "    rgb_closing_image = cv2.cvtColor(closing, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/opening_sh.jpg\", opening)\n",
    "    cv2.imwrite(f\"{output_folder}/closing_sh.jpg\", closing)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closing, connectivity=8)\n",
    "\n",
    "    # 1. เอา stats ตัวแรก (background) ออก\n",
    "    stats_no_bg = stats[1:]\n",
    "\n",
    "    # 2. เรียง stats ใหม่โดยใช้ค่า area (คอลัมน์ที่ 4) จากมากไปน้อย\n",
    "    sorted_indices = np.argsort(-stats_no_bg[:, 4])\n",
    "    sorted_stats = stats_no_bg[sorted_indices]\n",
    "\n",
    "    # 3. เลือกแค่ 14 element ที่มีค่า area สูงสุด\n",
    "    top_14_stats = sorted_stats[:14]\n",
    "    top_14_stats_sorted_by_y = top_14_stats[np.argsort(top_14_stats[:, 1])]\n",
    "\n",
    "    img_height, img_width = student_info_sh_img.shape[:2]\n",
    "\n",
    "    # กำหนด margin เป็นเปอร์เซ็นต์ของขนาด bounding box\n",
    "    # เช่น กำหนด 10% ของความกว้าง/ความสูงของ bounding box สำหรับแต่ละด้าน\n",
    "    left_margin_percent = 0.1    # ขยายซ้าย 10%\n",
    "    right_margin_percent = 0.1   # ขยายขวา 10%\n",
    "    top_margin_percent = 0.2     # ขยายบน 20%\n",
    "    bottom_margin_percent = 0.1  # ขยายล่าง 10%\n",
    "\n",
    "    text_group_stud_sh = []\n",
    "    for idx, stats in enumerate(top_14_stats_sorted_by_y): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "\n",
    "        # คำนวณ margin ตามเปอร์เซ็นต์ของ bounding box\n",
    "        left_margin = int(w * left_margin_percent)\n",
    "        right_margin = int(w * right_margin_percent)\n",
    "        top_margin = int(h * top_margin_percent)\n",
    "        bottom_margin = int(h * bottom_margin_percent)\n",
    "\n",
    "        # คำนวณพิกัดใหม่โดยใช้ margin ที่คำนวณได้\n",
    "        x_new = max(x - left_margin, 0)\n",
    "        y_new = max(y - top_margin, 0)\n",
    "        x_end = min(x + w + right_margin, img_width)\n",
    "        y_end = min(y + h + bottom_margin, img_height)\n",
    "\n",
    "        cluster_img = student_info_sh_img[y_new:y_end, x_new:x_end]\n",
    "        text_group_stud_sh.append(cluster_img)\n",
    "\n",
    "        # วาดกรอบที่ขยายแล้วลงบนภาพ\n",
    "        cv2.rectangle(rgb_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        cv2.rectangle(rgb_closing_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        \n",
    "    cv2.imwrite(f\"{output_folder}/cca_top_14_stats.jpg\", rgb_image)\n",
    "    cv2.imwrite(f\"{output_folder}/cca_rgb_closing_image.jpg\", rgb_closing_image)\n",
    "\n",
    "    return text_group_stud_sh[3:]\n",
    "\n",
    "text_stud_fh_images = find_text_student_info_fh(student_info_fh_img)\n",
    "text_stud_sh_images = find_text_student_info_sh(student_info_sh_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx_g, text_group in enumerate(text_stud_fh_images):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(text_group, cmap=\"gray\")\n",
    "    plt.title(f\"text_group {idx_g+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_fh = [3, -2, -1]\n",
    "indices_sh = [-3, -1]\n",
    "student_name, field_of_study, field_of_work = [text_stud_fh_images[i] for i in indices_fh]\n",
    "cgpa, graduation_date = [text_stud_sh_images[i] for i in indices_sh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sub_text_in_group_stud(binary_image):\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(binary_image, cmap=\"gray\")\n",
    "    plt.title(f\"binary_image\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    text_group = []\n",
    "\n",
    "    #kernel_open = np.ones((2, 2), np.uint8)\n",
    "    #remove_noise = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "    #plt.figure(figsize=(5,5))\n",
    "    #plt.imshow(remove_noise, cmap=\"gray\")\n",
    "    #plt.title(f\"remove_noise\")\n",
    "    #plt.show()\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dummy_image = cv2.dilate(binary_image, kernel, iterations=2)\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(dummy_image, cmap=\"gray\")\n",
    "    plt.title(f\"dummy_image\")\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    # ใช้ Connected Component Analysis\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dummy_image, connectivity=8)\n",
    "    word_stats = stats[1:] # ข้าม Background (index 0)\n",
    "    sorted_indices = np.argsort(word_stats[:, 0]) # จัดเรียงตามค่า x (คอลัมน์ที่ 0)\n",
    "    sorted_stats = word_stats[sorted_indices]\n",
    "\n",
    "    for idx, stats in enumerate(sorted_stats):\n",
    "        x, y, w, h, area = stats\n",
    "        cluster_img = binary_image[y:y+h, x:x+w]\n",
    "        text_group.append(cluster_img)\n",
    "\n",
    "    return text_group\n",
    "\n",
    "text_group_student_name = detect_sub_text_in_group_stud(student_name)\n",
    "text_group_field_of_study = detect_sub_text_in_group_stud(field_of_study)\n",
    "text_group_field_of_work = detect_sub_text_in_group_stud(field_of_work)\n",
    "\n",
    "text_group_cgpa = detect_sub_text_in_group_stud(cgpa)\n",
    "text_group_graduation_date = detect_sub_text_in_group_stud(graduation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx, sub_text in enumerate(text_group_student_name):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(sub_text, cmap=\"gray\")\n",
    "    plt.title(f\"sub_text {idx+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(filtered_contours) >= 3\n",
      "มีอยู่หลังสุด\n",
      "มีการสลับตัวแรกกับตัวสุดท้าย\n"
     ]
    }
   ],
   "source": [
    "def char_level_stud(char_images):\n",
    "    debug = False\n",
    "\n",
    "    char_box = []\n",
    "    \n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(char_images, cmap=\"gray\")\n",
    "        plt.title(f\"char\")\n",
    "        plt.show()\n",
    "    \n",
    "    skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "    #skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "\n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(skeleton, cmap=\"gray\")\n",
    "        plt.title(f\"skeleton\")\n",
    "        plt.show()\n",
    "    \n",
    "    kernel_dummy = np.ones((3, 3), np.uint8)\n",
    "    closing_skeleton = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "    dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "    closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(closing_skeleton, cmap=\"gray\")\n",
    "    plt.title(f\"closing_skeleton\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    if debug == True:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(dummy_image, cmap=\"gray\")\n",
    "        plt.title(f\"dummy_image\")\n",
    "        plt.show()\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # เรียง contours ตามค่า y ของ centroid จากน้อยไปหามาก\n",
    "    sorted_contours = sorted(contours, key=lambda cnt: get_centroid(cnt)[1], reverse=True)\n",
    "\n",
    "    # คำนวณพื้นที่ของ contour แต่ละตัว และหาพื้นที่ที่ใหญ่ที่สุด\n",
    "    max_area = max(cv2.contourArea(cnt) for cnt in sorted_contours)\n",
    "\n",
    "    # กำหนด threshold เป็น 5% ของพื้นที่ที่ใหญ่ที่สุด\n",
    "    min_area_threshold = max_area * 0.05\n",
    "\n",
    "    # กรอง contours ที่มีพื้นที่ไม่น้อยกว่า threshold\n",
    "    filtered_contours = [cnt for cnt in sorted_contours if cv2.contourArea(cnt) >= min_area_threshold]\n",
    "\n",
    "\n",
    "    # หาก filtered_contours มีแค่ 2 ตัว\n",
    "    if len(filtered_contours) == 2:\n",
    "\n",
    "        area0 = cv2.contourArea(filtered_contours[0])\n",
    "        area1 = cv2.contourArea(filtered_contours[1])\n",
    "        # คำนวณความแตกต่างเป็นอัตราส่วนของ contour ที่มีพื้นที่ใหญ่กว่า\n",
    "        diff_ratio = abs(area0 - area1) / max(area0, area1)\n",
    "        if diff_ratio <= 0.05:\n",
    "            print(\"เหมือนกัน\")\n",
    "\n",
    "            kernel_same = np.ones((4, 4), np.uint8)\n",
    "            contours, hierarchy = cv2.findContours(char_images, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(closing_same, cmap=\"gray\")\n",
    "            plt.title(f\"closing_same\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            level = 1\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            contour_area = int(cv2.contourArea(largest_contour))\n",
    "            crop_img = char_images[y:y+h, x:x+w]\n",
    "            char_box.append([crop_img, level])\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"Level : {level} area: {contour_area}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            return char_box\n",
    "    elif len(filtered_contours) >= 3: # เอาไว้แก้ปัญหาพวกคำว่า \"ชั้น, บัน\" หรือทุกคำที่มี \"  ั \"\n",
    "        print(\"len(filtered_contours) >= 3\")\n",
    "        # คำนวณ centroid และพื้นที่ของแต่ละ contour ใน filtered_contours\n",
    "        centroids_filtered = [get_centroid(cnt) for cnt in filtered_contours]\n",
    "        areas_filtered = [cv2.contourArea(cnt) for cnt in filtered_contours]\n",
    "    \n",
    "        # หาตำแหน่งของ contour ที่มีพื้นที่มากที่สุด\n",
    "        max_area_idx = areas_filtered.index(max(areas_filtered))\n",
    "        max_centroid_y = centroids_filtered[max_area_idx][1]\n",
    "        max_area = areas_filtered[max_area_idx]\n",
    "    \n",
    "        # สร้าง list ใหม่เพื่อจัดกลุ่ม contour ที่จะอยู่ก่อนและหลัง\n",
    "        remain_contours = []\n",
    "        move_to_end = []\n",
    "\n",
    "        find_status = False\n",
    "        # วนลูปผ่านแต่ละ contour พร้อมกับ centroid และพื้นที่\n",
    "        for idx, (cnt, cent, area) in enumerate(zip(filtered_contours, centroids_filtered, areas_filtered)):\n",
    "            # ถ้าเป็น contour ที่มีพื้นที่มากที่สุด ให้เก็บไว้ใน remain_contours\n",
    "            if idx == max_area_idx:\n",
    "                remain_contours.append(cnt)\n",
    "            else:\n",
    "                # ตรวจสอบว่า centroid แกน y ของ contour นี้ต่างจาก max_centroid_y ไม่เกิน 20%\n",
    "                # และมีพื้นที่ไม่น้อยกว่า 30% ของ max_area\n",
    "                if abs(cent[1] - max_centroid_y) <= 0.2 * max_centroid_y and area >= 0.3 * max_area:\n",
    "                    print(\"มีอยู่หลังสุด\")\n",
    "                    move_to_end.append(cnt)\n",
    "                    find_status = True\n",
    "                else:\n",
    "                    remain_contours.append(cnt)\n",
    "        \n",
    "        # รวม list ที่เหลือเข้าด้วยกัน โดย contour ที่ตรงเงื่อนไขจะอยู่ท้ายสุด\n",
    "        filtered_contours = remain_contours + move_to_end\n",
    "\n",
    "        if find_status == True:\n",
    "            \n",
    "            # คำนวณพื้นที่และ centroid แกน x ของ contour ตัวแรกและตัวสุดท้าย\n",
    "            first_area = cv2.contourArea(filtered_contours[0])\n",
    "            last_area = cv2.contourArea(filtered_contours[-1])\n",
    "            first_centroid = get_centroid(filtered_contours[0])\n",
    "            last_centroid = get_centroid(filtered_contours[-1])\n",
    "\n",
    "            # ตรวจสอบเงื่อนไข ถ้า contour ตัวแรกมี area มากกว่าและ centroid_x มากกว่าตัวสุดท้าย\n",
    "            if first_area > last_area and first_centroid[0] > last_centroid[0]:\n",
    "                print(\"มีการสลับตัวแรกกับตัวสุดท้าย\")\n",
    "                # สลับตำแหน่ง contour ตัวแรกกับตัวสุดท้าย\n",
    "                filtered_contours[0], filtered_contours[-1] = filtered_contours[-1], filtered_contours[0]\n",
    "\n",
    "            # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "            for idx_c, cnt in enumerate(filtered_contours):\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = int(cv2.contourArea(cnt))\n",
    "                char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "            for idx, box in enumerate(char_box):\n",
    "                if idx == 0:\n",
    "                    box.append(1)\n",
    "                elif idx == (len(char_box)-1):\n",
    "                    box.append(1)\n",
    "                else:\n",
    "                    box.append(2)\n",
    "\n",
    "            char_level_images = []\n",
    "            for idx, box in enumerate(char_box):\n",
    "                x, y, w, h, area, level = box\n",
    "                crop_img = char_images[y:y+h, x:x+w]\n",
    "                char_level_images.append([crop_img, level])\n",
    "\n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"char : {idx+1} Level : {level} area: {area}\")\n",
    "                    plt.show()\n",
    "            return char_level_images\n",
    "\n",
    "        else:\n",
    "            # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "            for idx_c, cnt in enumerate(filtered_contours):\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = int(cv2.contourArea(cnt))\n",
    "                char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "            for idx, box in enumerate(char_box):\n",
    "                if idx == max_index:\n",
    "                    # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "                    box.append(1)\n",
    "                elif idx < max_index:\n",
    "                    # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "                    box.append(0)\n",
    "                #elif idx == (len(char_box)-1):\n",
    "                #    # ถ้าเป็น list append 1\n",
    "                #    box.append(1)\n",
    "                else:\n",
    "                    # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append 2\n",
    "                    box.append(2)\n",
    "\n",
    "            # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "            areas = [item[4] for item in char_box]\n",
    "            max_index = areas.index(max(areas))\n",
    "\n",
    "            # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "            if max_index != 0:\n",
    "                char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "            char_level_images = []\n",
    "            for idx, box in enumerate(char_box):\n",
    "                x, y, w, h, area, level = box\n",
    "                crop_img = char_images[y:y+h, x:x+w]\n",
    "                char_level_images.append([crop_img, level])\n",
    "\n",
    "                if debug == True:\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(crop_img, cmap=\"gray\")\n",
    "                    plt.title(f\"char : {idx+1} Level : {level} area: {area}\")\n",
    "                    plt.show()\n",
    "        \n",
    "            return char_level_images\n",
    "\n",
    " #########################\n",
    "    # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "    for idx_c, cnt in enumerate(filtered_contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        contour_area = int(cv2.contourArea(cnt))\n",
    "        char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # สำหรับ list ที่อยู่หลัง list ที่มี area มากที่สุด เราจะเริ่มนับจาก 2\n",
    "    after_counter = 2\n",
    "\n",
    "    # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "    for idx, box in enumerate(char_box):\n",
    "        if idx == max_index:\n",
    "            # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "            box.append(1)\n",
    "        elif idx < max_index:\n",
    "            # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "            box.append(0)\n",
    "        else:\n",
    "            # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append sequential number เริ่มจาก 2\n",
    "            box.append(after_counter)\n",
    "            #after_counter += 1\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "    if max_index != 0:\n",
    "        char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(char_images, cmap=\"gray\")\n",
    "    plt.title(f\"char_images\")\n",
    "    plt.show()\n",
    "    '''\n",
    "        \n",
    "    char_level_images = []\n",
    "    for idx, box in enumerate(char_box):\n",
    "        x, y, w, h, area, level = box\n",
    "        crop_img = char_images[y:y+h, x:x+w]\n",
    "        char_level_images.append([crop_img, level])\n",
    "\n",
    "        if debug == True:\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"char : {idx+1} Leve : {level} area: {area}\")\n",
    "            plt.show()\n",
    "        \n",
    "    return char_level_images\n",
    "       \n",
    "def detect_char_stud(text_group):\n",
    "\n",
    "    sub_text_char = []\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        rgb_image = cv2.cvtColor(sub_text, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "        skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "        #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "        kernel_dummy = np.ones((2, 2), np.uint8)\n",
    "        dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "        kernel_closing = np.ones((7, 1), np.uint8)\n",
    "        closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_closing, iterations=1)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "            \n",
    "        char_images_with_levels = []\n",
    "\n",
    "        '''\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(sub_text, cmap=\"gray\")\n",
    "        plt.title(f\"sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(skeleton, cmap=\"gray\")\n",
    "        plt.title(f\"skeleton, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(dummy_image, cmap=\"gray\")\n",
    "        plt.title(f\"dummy_image, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(closing, cmap=\"gray\")\n",
    "        plt.title(f\"closing, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "        for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "            # สมมุติว่าเราได้ contour (cnt) จาก cv2.findContours แล้ว\n",
    "            #scaled_cnt = scale_contour(cnt, scale_factor=1.0)\n",
    "\n",
    "            #char_height, char_width = h, w\n",
    "            #mask = np.zeros((char_height, char_width), dtype=np.uint8)\n",
    "\n",
    "            mask = np.zeros(sub_text.shape[:2], dtype=np.uint8)\n",
    "\n",
    "            rgb_mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            # วาด contour ลงใน mask โดยเติมเต็ม (thickness = -1) ให้ภายใน contour เป็นสีขาว (255)\n",
    "            cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "            kernel_mask = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # ปรับขนาด kernel ตามต้องการ\n",
    "            dilated_mask = cv2.dilate(mask, kernel_mask, iterations=1)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(dilated_mask, cmap=\"gray\")\n",
    "            plt.title(f\"dilated_mask, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            # ใช้ mask กับภาพต้นฉบับ เพื่อดึงเฉพาะส่วนภายใน contour\n",
    "            char_result = cv2.bitwise_and(sub_text, sub_text, mask=dilated_mask)\n",
    "            char_images_with_levels.extend(char_level_stud(char_result))\n",
    "            #print(\"cher_level_images :\", len(char_images_with_levels))\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(char_result, cmap=\"gray\")\n",
    "            plt.title(f\"sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "                \n",
    "            '''\n",
    "            for idx_c_l, cher_level in enumerate(cher_level_images):\n",
    "                plt.figure(figsize=(2, 2))\n",
    "                plt.imshow(cher_level[0], cmap=\"gray\")\n",
    "                plt.title(f\"cnt, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c_l+1}, level:{cher_level[1]}\")\n",
    "                plt.show()\n",
    "            '''\n",
    "            \n",
    "                \n",
    "            #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "        sub_text_char.append(char_images_with_levels)\n",
    "            \n",
    "        '''\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(rgb_image, cmap=\"gray\")\n",
    "        plt.title(f\"Contour, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "        '''\n",
    "            \n",
    "\n",
    "    return sub_text_char\n",
    "\n",
    "text_group_char_student_name = detect_char_stud(text_group_student_name[3:])\n",
    "text_group_char_field_of_study = detect_char_stud(text_group_field_of_study[1:])\n",
    "text_group_char_field_of_work = detect_char_stud(text_group_field_of_work[1:])\n",
    "\n",
    "text_group_char_cgpa = detect_char_stud(text_group_cgpa[1:])\n",
    "text_group_char_graduation_date = detect_char_stud(text_group_graduation_date[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_char\n",
    "\n",
    "for idx_s, sub_text in enumerate(text_group_char_student_name):\n",
    "    for idx_c, char in enumerate(sub_text):\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(char[0], cmap=\"gray\")\n",
    "        plt.title(f\"sub text:{idx_s+1}, char:{idx_c+1} \")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนายตัวอักษรหลายระดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rule_Based_Post_Processing(word):\n",
    "\n",
    "    if not word:\n",
    "        return word\n",
    "    #word = word.replace(\"ัั\", \"ะ\")\n",
    "    word = word.replace(\"เเ\", \"แ\")\n",
    "    #word = word.replace(\"้้\", \"ะ\")\n",
    "    #word = word.replace(\"้ั\", \"ะ\")\n",
    "    #word = word.replace(\"ั้\", \"ะ\")\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_level_0 = \"../models/char_level_0_model.h5\"\n",
    "model_path_char_level_1 = \"../models/char_level_1_model.h5\"\n",
    "model_path_char_level_2 = \"../models/char_level_2_model.h5\"\n",
    "model_path_char_level_3 = \"../models/char_level_3_model.h5\"\n",
    "\n",
    "model_char_level_0 = load_model(model_path_char_level_0)\n",
    "model_char_level_1 = load_model(model_path_char_level_1)\n",
    "model_char_level_2 = load_model(model_path_char_level_2)\n",
    "model_char_level_3 = load_model(model_path_char_level_3)\n",
    "\n",
    "# สร้าง Mapping ของโมเดลตามระดับ\n",
    "models = {\n",
    "    0: model_char_level_0,\n",
    "    1: model_char_level_1,\n",
    "    2: model_char_level_2,\n",
    "    3: model_char_level_3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "ประมวลผลเสร็จสิ้น\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "ประมวลผลเสร็จสิ้น\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "ประมวลผลเสร็จสิ้น\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "ประมวลผลเสร็จสิ้น\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "ประมวลผลเสร็จสิ้น\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_level_0_label = [\n",
    "    'ุ', 'ู'\n",
    "]\n",
    "\n",
    "char_level_1_label = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    \n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "\n",
    "    'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', \n",
    "    'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', \n",
    "    'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', \n",
    "    'ห', 'ฬ', 'อ', 'ฮ',\n",
    "\n",
    "    'ะ','า', 'เ', 'แ', 'โ', 'ฤ', 'ใ', 'ไ',\n",
    "\n",
    "    '+', '-', '*', '(', ')', '.', '=', '/', '|'\n",
    "]\n",
    "\n",
    "char_level_2_label = [\n",
    "     'ิ', 'ี', 'ึ', 'ื', '็', 'ั', 'ํ', '่', '้', '๊', '๋', '์'\n",
    "]\n",
    "\n",
    "char_level_3_label = [\n",
    "    '่', '้', '๊', '๋',\n",
    "]\n",
    "\n",
    "char_level_labels = {\n",
    "    0: char_level_0_label,\n",
    "    1: char_level_1_label,\n",
    "    2: char_level_2_label,\n",
    "    3: char_level_3_label,\n",
    "}\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_multi_level_stud(text_group_char):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "\n",
    "    text_result = \"\"\n",
    "    for idx_s, sub_text in enumerate(text_group_char):\n",
    "        sub_text_result = \"\"\n",
    "\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            char_image, char_level = char\n",
    "\n",
    "            if char is None:\n",
    "                print(f\"Character image {idx_c} is None.\")\n",
    "                continue  # ข้ามภาพนี้\n",
    "            else:\n",
    "\n",
    "                # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                padded_img = resize_with_min_padding(char_image, input_size, min_padding=1)\n",
    "\n",
    "                '''\n",
    "                plt.figure(figsize=(2, 2))\n",
    "                plt.imshow(padded_img, cmap=\"gray\")\n",
    "                plt.title(f\"Char, text group:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}, level: {char_level}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                    \n",
    "                # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                normalized_img = padded_img / 255.0\n",
    "\n",
    "                if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                    normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                    processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                    if char_level in models:\n",
    "                        prediction = models[char_level].predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence_score = np.max(prediction)\n",
    "\n",
    "                        class_level = char_level_labels[char_level]\n",
    "                        predicted_letter = class_level[predicted_class]\n",
    "                    else:\n",
    "                        print(\"level ไม่ตรง\")\n",
    "                        prediction = models[2].predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence_score = np.max(prediction)\n",
    "\n",
    "                        class_level = char_level_labels[2]\n",
    "                        predicted_letter = class_level[predicted_class]\n",
    "\n",
    "                    sub_text_result += predicted_letter\n",
    "\n",
    "        sub_text_result += \" \"\n",
    "        text_result += sub_text_result\n",
    "        text_result_post = Rule_Based_Post_Processing(text_result)\n",
    "        #text_block.append(text_result_post)\n",
    "        \n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_result_post \n",
    "        \n",
    "text_box_student_name = predict_text_multi_level_stud(text_group_char_student_name[:])\n",
    "text_box_field_of_study = predict_text_multi_level_stud(text_group_char_field_of_study[:])\n",
    "text_box_field_of_work = predict_text_multi_level_stud(text_group_char_field_of_work[:])\n",
    "\n",
    "text_box_cgpa = predict_text_multi_level_stud(text_group_char_cgpa[:])\n",
    "text_box_graduation_date = predict_text_multi_level_stud(text_group_char_graduation_date[:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "นาใสาวจิรนันท์ พีรวaนสกุล\n",
      "การบัญชี\n",
      "การฬญฤ\n",
      "3.76\n",
      "23 ม่นาคม 2565\n"
     ]
    }
   ],
   "source": [
    "print(text_box_student_name.strip())\n",
    "print(text_box_field_of_study.strip())\n",
    "print(text_box_field_of_work.strip())\n",
    "\n",
    "print(text_box_cgpa.replace(\" \", \"\"))\n",
    "print(text_box_graduation_date.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
