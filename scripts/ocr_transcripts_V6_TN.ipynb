{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "output_folder = Path(\"../data/output_images/output_V6_TN\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_1.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_3.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_4.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_5.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_6.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_7.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_8.png\") # ซ้ำกับ 7\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_9.png\") # จับตารางได้แต่พังตอน pt\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_10.png\") # ลบเส้นตารางไม่หมดตรงรหัสวิชา\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_11.png\") # ภาพใหญ่เกินไป\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_12.png\") # ตารางไม่ตรง\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_13.png\") # ติดลอยปั้มหมึก\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_14.png\")\n",
    "#image = cv2.imread(\"C:/Users/Impan/Documents/ocr-engine-python/data/test_images/transcript/technician/good/transcript_tn_f_15.png\")\n",
    "\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"ไม่พบไฟล์ภาพ กรุณาตรวจสอบเส้นทางของไฟล์\")\n",
    "\n",
    "denoised = cv2.bilateralFilter(image, d=9, sigmaColor=100, sigmaSpace=100) # จำกัด noise\n",
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "binary_gaussian = cv2.adaptiveThreshold(\n",
    "    gray_img, \n",
    "    maxValue=255, \n",
    "    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    thresholdType=cv2.THRESH_BINARY_INV, \n",
    "    blockSize=51, \n",
    "    C=21 #21\n",
    ")\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/original.png\", image)\n",
    "cv2.imwrite(f\"{output_folder}/denoised.png\", denoised)\n",
    "cv2.imwrite(f\"{output_folder}/gray.png\", gray_img)\n",
    "cv2.imwrite(f\"{output_folder}/binary_g.png\", binary_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour #0: bounding box = (x=6, y=195, w=161, h=1810, area=289440)\n",
      "Contour #1: bounding box = (x=178, y=195, w=678, h=1810, area=1224693)\n",
      "Contour #2: bounding box = (x=867, y=195, w=53, h=1810, area=94068)\n",
      "Contour #3: bounding box = (x=931, y=195, w=61, h=1810, area=108540)\n",
      "Contour #4: bounding box = (x=1003, y=195, w=68, h=1810, area=121203)\n",
      "Contour #5: bounding box = (x=1082, y=195, w=161, h=1810, area=289440)\n",
      "Contour #6: bounding box = (x=1254, y=195, w=678, h=1810, area=1224693)\n",
      "Contour #7: bounding box = (x=1943, y=195, w=54, h=1810, area=95877)\n",
      "Contour #8: bounding box = (x=2008, y=195, w=60, h=1810, area=106731)\n",
      "Contour #9: bounding box = (x=2079, y=195, w=69, h=1810, area=123012)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_grade_table_and_students(binary_img, denoised):\n",
    "    \n",
    "    # แยกตาราง\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_img, connectivity=8)\n",
    "    areas = [stat[4] for stat in stats]  # ดึงค่า area\n",
    "    sorted_areas = sorted(areas, reverse=True)  # เรียงลำดับจากมากไปน้อย\n",
    "    second_max_area = sorted_areas[1]  # ค่าอันดับ 2\n",
    "    second_max_area_index = areas.index(second_max_area)  # หาตำแหน่งในลิสต์เดิม\n",
    "    table_position = stats[second_max_area_index]\n",
    "    x, y, w, h, area = table_position\n",
    "    table_img = binary_img[y:y+h, x:x+w]\n",
    "    table_original_img = denoised[y:y+h, x:x+w]\n",
    "\n",
    "    # ข้อมูลนักเรียน\n",
    "    #x_start = int((x+w) * 0.40) # ความกว้าง 40% ของตาราง\n",
    "    x_end = int((x+w) * 0.85) # ความกว้าง 85% ของตาราง\n",
    "    x_split_half = int((x+w) * 0.38) # ความกว้าง 38% ของตาราง\n",
    "\n",
    "    student_info_img = binary_img[:y, :x_end]\n",
    "    student_info_fh_img = binary_img[:y, :x_split_half] # ครึ่งแรก\n",
    "    student_info_sh_img = binary_img[:y, x_split_half:x_end] # ครึ่งหลัง\n",
    "\n",
    "    return table_img, student_info_img, student_info_fh_img, student_info_sh_img, table_original_img\n",
    "\n",
    "def biggest_contour(contours):\n",
    "    biggest = np.array([])\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i)\n",
    "        #print(area)\n",
    "        if area > 1000:\n",
    "            #print(\"มา\")\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.02 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "\n",
    "    return biggest\n",
    "\n",
    "def persective_transformation(table_binary_img, table_original_img):\n",
    "\n",
    "    # ค้นหาคอนทัวร์\n",
    "    contours, hierarchy = cv2.findContours(table_binary_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #contours, hierarchy = cv2.findContours(table_binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "    # ค้นหาสี่เหลี่ยมที่ใหญ่ที่สุด\n",
    "    biggest = biggest_contour(contours)\n",
    "\n",
    "    points = biggest.reshape(4, 2)\n",
    "    input_points = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "    points_sum = points.sum(axis=1)\n",
    "    input_points[0] = points[np.argmin(points_sum)]\n",
    "    input_points[3] = points[np.argmax(points_sum)]\n",
    "\n",
    "    points_diff = np.diff(points, axis=1)\n",
    "    input_points[1] = points[np.argmin(points_diff)]\n",
    "    input_points[2] = points[np.argmax(points_diff)]\n",
    "\n",
    "    (top_left, top_right, bottom_right, bottom_left) = input_points\n",
    "\n",
    "    # Euclidean Distance Formula\n",
    "    bottom_width = np.sqrt(((bottom_right[0] - bottom_left[0]) ** 2) + ((bottom_right[1] - bottom_left[1]) ** 2))\n",
    "    top_width = np.sqrt(((top_right[0] - top_left[0]) ** 2) + ((top_right[1] - top_left[1]) ** 2))\n",
    "    rigth_height = np.sqrt(((top_left[0] - bottom_right[0]) ** 2) + ((top_left[1] - bottom_right[1]) ** 2))\n",
    "    left_height = np.sqrt(((top_left[0] - bottom_left[0]) ** 2) + ((top_left[1] - bottom_left[1]) ** 2))\n",
    "\n",
    "    # Output image size\n",
    "    #max_width = max(int(bottom_width), int(top_width))\n",
    "    expand_width = round(max(int(bottom_width), int(top_width)) * 0.4)\n",
    "    max_width = max(int(bottom_width), int(top_width)) + expand_width\n",
    "    max_height = max(int(rigth_height), int(left_height))\n",
    "\n",
    "    # Desird points values in the output image\n",
    "    converted_points = np.float32([[0, 0], [max_width, 0], [0, max_height], [max_width, max_height]])\n",
    "\n",
    "    # Perspective transformaxtion\n",
    "    matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "    img_out = cv2.warpPerspective(table_binary_img.copy(), matrix, (max_width, max_height))\n",
    "    img_original_out = cv2.warpPerspective(table_original_img.copy(), matrix, (max_width, max_height))\n",
    "\n",
    "    return img_out, img_original_out\n",
    "\n",
    "def hough_line_transform(binary_image, table_original_persective_img, grid_img):\n",
    "\n",
    "    # 1) ใช้ HoughLinesP ตรวจจับเส้น\n",
    "    #    - พารามิเตอร์ที่สำคัญ: threshold, minLineLength, maxLineGap\n",
    "    lines = cv2.HoughLinesP(\n",
    "        binary_image,\n",
    "        rho=1,\n",
    "        theta=np.pi/180,\n",
    "        threshold=100,      # ต้องปรับจูน\n",
    "        minLineLength=700,  # ต้องปรับจูน\n",
    "        maxLineGap=10     # ต้องปรับจูน\n",
    "    )\n",
    "\n",
    "    # 2) สร้าง mask (เป็นภาพดำล้วน ขนาดเท่ากับต้นฉบับ)\n",
    "    line_mask = np.zeros_like(binary_image)\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            # วาดเส้นสีขาวลงใน mask (ปรับ thickness ตามความหนาเส้นในภาพ)\n",
    "            cv2.line(line_mask, (x1, y1), (x2, y2), 255, 2)\n",
    "\n",
    "    # 4) เราจะเอา mask นี้มาช่วยลบเส้นในภาพ\n",
    "    #    วิธีง่าย ๆ คือการเอา thresh ที่เป็น binary_inv มาลบด้วย mask (bitwise)\n",
    "    #    หรืออาจใช้เทคนิค inpaint บนภาพสี\n",
    "\n",
    "    # วิธีที่ 4.1: ลบตรง ๆ จาก thresh ก่อน (ซึ่งเป็น Binary แล้ว)\n",
    "    table_without_lines = cv2.bitwise_and(binary_image, cv2.bitwise_not(line_mask))\n",
    "    table_without_lines_2 = cv2.bitwise_and(table_without_lines, cv2.bitwise_not(grid_img))\n",
    "\n",
    "\n",
    "    # หรือ วิธีที่ 4.2: ลอง inpaint บนภาพจริงสี (img)\n",
    "    #    โดยปกติ inpaint จะต้องการ mask สีขาว บริเวณที่ต้องการซ่อมแซม\n",
    "    #    ซึ่ง line_mask ของเราพอดีอยู่แล้ว\n",
    "    inpainted = cv2.inpaint(table_original_persective_img, line_mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    #kernel = np.ones((20, 15), np.uint8)\n",
    "    #final_dilate = cv2.dilate(image_without_lines, kernel, iterations=1)\n",
    "\n",
    "\n",
    "    # เนื่องจาก thresh เป็น invert (พื้นดำ ตัวหนังสือขาว)\n",
    "    # ถ้าอยากกลับด้านให้พื้นขาว ตัวหนังสือดำก็ทำ bitwise_not อีกที\n",
    "    #final = cv2.bitwise_not(image_without_lines)\n",
    "    cv2.imwrite(f\"{output_folder}/line_mask.png\", line_mask)\n",
    "    cv2.imwrite(f\"{output_folder}/image_without_lines.png\", table_without_lines)\n",
    "    cv2.imwrite(f\"{output_folder}/image_without_lines_2.png\", table_without_lines_2)\n",
    "    #cv2.imwrite(f\"{output_folder}/final_dilate.png\", final_dilate)\n",
    "    cv2.imwrite(f\"{output_folder}/inpainted.png\", inpainted)\n",
    "\n",
    "    return line_mask, table_without_lines, table_without_lines_2\n",
    "\n",
    "def cells_detect(grid_lines):\n",
    "    # ขั้นตอนที่ 1: Invert ภาพ\n",
    "    inverted = cv2.bitwise_not(grid_lines) # (เพื่อให้พื้นที่ดำ (ช่องตาราง) กลายเป็นสีขาว, ส่วนเส้นขาวจะเป็นสีดำ)\n",
    "\n",
    "    # ขั้นตอนที่ 2: Erode พื้นที่ขาวเล็กน้อย เพื่อลดการติดเส้น\n",
    "    kernel = np.ones((3, 3), np.uint8) # สร้าง kernel เล็ก ๆ เพื่อ erode\n",
    "    eroded = cv2.erode(inverted, kernel, iterations=0)\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/eroded.png\", eroded)\n",
    "\n",
    "    # ขั้นตอนที่ 3: Find Contours (หาพื้นที่สีขาว ซึ่งเป็นรูปทรงของช่องตาราง)\n",
    "    #contours, hierarchy = cv2.findContours(eroded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours, hierarchy = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_contours = filter(lambda c: cv2.boundingRect(c)[2] > 40, contours)  # กรอง w > 10\n",
    "    contours = sorted(filtered_contours, key=lambda c: cv2.boundingRect(c)[3], reverse=True)[:10] # เรียงลำดับ contours ตามค่า h (ความสูง) จากมากไปน้อย\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0], reverse=False)  # เรียงลำดับ contours ตามค่า x จากน้อยไปมาก\n",
    " \n",
    "    # ขั้นตอนที่ 4: วนลูปดูผลลัพธ์ของ Contours แต่ละอัน\n",
    "\n",
    "    output = cv2.cvtColor(grid_lines.copy(), cv2.COLOR_GRAY2BGR)  # ไว้สำหรับวาดกรอบ\n",
    "\n",
    "    cell_contours = []\n",
    "\n",
    "    for i, cnt in enumerate(contours):\n",
    "        # หา bounding box ของ contour\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = int(cv2.contourArea(cnt))\n",
    "        cell_contours.append([x, y, w, h, area])\n",
    "\n",
    "        # วาดสี่เหลี่ยมครอบลงบน output เพื่อดู\n",
    "        cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "        print(f\"Contour #{i}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/Contours.png\", output)\n",
    "\n",
    "    return cell_contours\n",
    "\n",
    "def create_grid_image(table_img,\n",
    "                      col_percentages=[8, 40, 43, 46.33, 50, 58, 90, 93, 96.33, 100],\n",
    "                      #col_percentages=[8, 39, 43, 46.33, 50, 58, 89, 93, 96.33, 100],\n",
    "                      row_percentages=[9.22, 100],\n",
    "                      grid_color=(255, 255, 255),\n",
    "                      vertical_line_thickness_percent=0.005,   # 0.33% ของความกว้างภาพสำหรับเส้นแนวตั้ง\n",
    "                      horizontal_line_thickness_percent=0.008, # 0.33% ของความกว้างภาพสำหรับเส้นแนวนอน\n",
    "                      bg_color=(0, 0, 0),\n",
    "                      return_binary=True,\n",
    "                      threshold_val=127):\n",
    "    \n",
    "    \"\"\"\n",
    "    สร้างภาพตารางที่มีขนาด width x height โดยแบ่งคอลัมน์และแถวตามเปอร์เซ็นต์ที่กำหนด\n",
    "    ความหนาของเส้นจะถูกคำนวณเป็นเปอร์เซ็นต์ของความกว้างของภาพ\n",
    "    ถ้า return_binary=True จะทำการแปลงภาพเป็น binary (ขาวดำ) โดยใช้ threshold ที่กำหนด\n",
    "\n",
    "    :param width: ความกว้างของภาพ (พิกเซล)\n",
    "    :param height: ความสูงของภาพ (พิกเซล)\n",
    "    :param col_percentages: รายการเปอร์เซ็นต์สำหรับขอบขวาของแต่ละคอลัมน์ (เรียงจากน้อยไปมาก; คอลัมน์สุดท้าย = 100%)\n",
    "    :param row_percentages: รายการเปอร์เซ็นต์สำหรับขอบล่างของแต่ละแถว (เรียงจากน้อยไปมาก; แถวสุดท้าย = 100%)\n",
    "    :param grid_color: สีของเส้นตารางในรูปแบบ (B, G, R)\n",
    "    :param line_thickness_percent: ความหนาของเส้นในรูปแบบเปอร์เซ็นต์ของความกว้างภาพ\n",
    "    :param bg_color: สีพื้นหลังของภาพ\n",
    "    :param return_binary: ถ้า True จะคืนภาพในรูปแบบ binary (หลัง threshold) มิฉะนั้นคืนค่าเป็น BGR image\n",
    "    :param threshold_val: ค่าที่ใช้ threshold เมื่อแปลงเป็นภาพ binary\n",
    "    :return: ภาพตารางในรูปแบบ binary (ถ้า return_binary=True) หรือ BGR image (ถ้า False)\n",
    "    \"\"\"\n",
    "\n",
    "    height, width, = table_img.shape  # ได้ค่า (สูง, กว้าง)\n",
    "\n",
    "    image = np.full((height, width, 3), bg_color, dtype=np.uint8)\n",
    "    \n",
    "    # คำนวณความหนาของเส้นสำหรับแต่ละแนว (อย่างน้อย 1 พิกเซล)\n",
    "    vertical_thickness = max(1, int(width * vertical_line_thickness_percent))\n",
    "    horizontal_thickness = max(1, int(width * horizontal_line_thickness_percent))\n",
    "    \n",
    "    # คำนวณตำแหน่งเส้นแนวตั้ง (x_positions)\n",
    "    col_fracs = [p / 100.0 for p in col_percentages]\n",
    "    x_positions = [0] + [int(width * p) for p in col_fracs]\n",
    "    \n",
    "    # คำนวณตำแหน่งเส้นแนวนอน (y_positions)\n",
    "    row_fracs = [p / 100.0 for p in row_percentages]\n",
    "    y_positions = [0] + [int(height * p) for p in row_fracs]\n",
    "    \n",
    "    # วาดเส้นตารางแนวตั้งโดยใช้ความหนาที่คำนวณสำหรับแนวตั้ง\n",
    "    for x in x_positions:\n",
    "        cv2.line(image, (x, 0), (x, height), grid_color, vertical_thickness)\n",
    "    \n",
    "    # วาดเส้นตารางแนวนอนโดยใช้ความหนาที่คำนวณสำหรับแนวนอน\n",
    "    for y in y_positions:\n",
    "        cv2.line(image, (0, y), (width, y), grid_color, horizontal_thickness)\n",
    "    \n",
    "    # แปลงภาพเป็น binary หากต้องการ\n",
    "    if return_binary:\n",
    "        # แปลงเป็น grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # ใช้ threshold เพื่อแปลงเป็นภาพ binary\n",
    "        _, binary_image = cv2.threshold(gray, threshold_val, 255, cv2.THRESH_BINARY)\n",
    "        return binary_image\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "table_img, student_info_img, student_info_fh_img, student_info_sh_img, table_original_img = split_grade_table_and_students(binary_gaussian, denoised)\n",
    "table_persective_img, table_original_persective_img = persective_transformation(binary_gaussian, denoised)\n",
    "grid_img = create_grid_image(table_persective_img)\n",
    "line_mask, table_without_lines, table_without_lines_2 = hough_line_transform(table_persective_img, table_original_persective_img, grid_img)\n",
    "\n",
    "cell_contours = cells_detect(grid_img)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/table_img.png\", table_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_img.png\", student_info_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_original_img.png\", table_original_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_persective_img.png\", table_persective_img)\n",
    "cv2.imwrite(f\"{output_folder}/table_original_persective_img.png\", table_original_persective_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_fh_img.png\", student_info_fh_img)\n",
    "cv2.imwrite(f\"{output_folder}/student_info_sh_img.png\", student_info_sh_img)\n",
    "cv2.imwrite(f\"{output_folder}/grid_img.png\", grid_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# แบ่งส่วนตาราง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(cell_contours, table_without_lines):\n",
    "    cell_images = []\n",
    "    for idx, cell_position in enumerate(cell_contours):\n",
    "        x, y, w, h, area = cell_position\n",
    "        crop_img = table_without_lines[y:y+h, x:x+w]\n",
    "        cell_images.append(crop_img)\n",
    "        cv2.imwrite(f\"{output_folder}/cell_images/crop_img_{idx}.png\", crop_img)\n",
    "        #print(f\"Contour #{idx}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "\n",
    "    return cell_images\n",
    "        \n",
    "cell_images = crop_image(cell_contours, table_without_lines_2)\n",
    "\n",
    "cell_subject_code_img = cell_images[0]\n",
    "cell_subject_name_img = cell_images[1]\n",
    "cell_credit_img = cell_images[2]\n",
    "cell_academic_results_img = cell_images[3]\n",
    "cell_subject_code_img_2 = cell_images[5]\n",
    "cell_subject_name_img_2 = cell_images[6]\n",
    "cell_credit_img_2 = cell_images[7]\n",
    "cell_academic_results_img_2 = cell_images[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_text_group_in_cell(cell_img, mode=0, calculate_line_stats=None):\n",
    "    text_group_images = []\n",
    "\n",
    "    kernel_open = np.ones((4, 4), np.uint8)\n",
    "    #kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    remove_noise = cv2.morphologyEx(cell_img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/cell_images/remove_noise.jpg\", remove_noise)\n",
    "\n",
    "    kernel = np.ones((3, 13), np.uint8)\n",
    "    group_text_img = cv2.dilate(remove_noise, kernel, iterations=2)\n",
    "    rgb_image = cv2.cvtColor(cell_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #plt.imshow(group_text, cmap=\"gray\")\n",
    "\n",
    "    if(mode == 1):\n",
    "        # ใช้ Connected Component Analysis\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(group_text_img, connectivity=8)\n",
    "\n",
    "        text_stats = stats[1:]\n",
    "        sorted_indices = np.argsort(text_stats[:, 1])  # จัดเรียงตามค่า y (คอลัมน์ที่ 1)\n",
    "        sorted_stats = text_stats[sorted_indices]\n",
    "\n",
    "        # ใช้ Boolean Indexing เพื่อเอา noise ออก \n",
    "        sorted_stats = sorted_stats[sorted_stats[:, 4] >= 2000]\n",
    "        calculate_line_stats = []\n",
    "\n",
    "        for idx_stat, stat in enumerate(sorted_stats):\n",
    "            x, y, w, h, area = stat\n",
    "            #print(f\"CCA #{idx_stat}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            if idx_stat == (len(sorted_stats)-1):\n",
    "                #print(\"เข้าเงื่อนลำดัยสุดท้าย\",idx_stat)\n",
    "                x, y, w, h, area = stat\n",
    "                new_y = round(y-(h/2))\n",
    "                new_h = round(h+(h*0.8))\n",
    "                calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "            else:\n",
    "                current_stat = stat\n",
    "                next_stat = sorted_stats[idx_stat+1]\n",
    "\n",
    "                distance = next_stat[1] - current_stat[1]\n",
    "                line_spacing = distance/current_stat[3]\n",
    "\n",
    "                if line_spacing > 3 and line_spacing <= 5: # เป็นชื่อวิชาที่มีความยาวมากกว่า 1 บรรทัด\n",
    "                    #print(\"เข้าเงื่อนไข มากกว่า 1 บรรทัด\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+(h*2.5))\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "\n",
    "                elif line_spacing > 6: # เป็นช่องว่างที่ไม่มีวิชา\n",
    "                    #print(\"เข้าเงื่อนไข เป็นช่องว่างที่ไม่มีวิชา\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+h)\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "                \n",
    "                else: # เป็นชื่อวิชาที่มีความยาวแค่ว่า 1 บรรทัด\n",
    "                    #print(\"เข้าเงื่อนไข 1 บรรทัด\")\n",
    "                    x, y, w, h, area = current_stat\n",
    "                    new_y = round(y-(h/2))\n",
    "                    new_h = round(h+(h*0.8))\n",
    "                    calculate_line_stats.append([x, new_y, w, new_h, area])\n",
    "\n",
    "        calculate_line_stats = np.array(calculate_line_stats) \n",
    "\n",
    "            #print(f\"CCA #{idx_stat}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            #cv2.rectangle(rgb_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        #cv2.imwrite(f\"{output_folder}/cell_images/cca.jpg\", rgb_image)\n",
    "\n",
    "    text_stats = sorted_stats if mode == 1 else calculate_line_stats\n",
    "\n",
    "    \n",
    "    for idx, stats in enumerate(text_stats): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "   \n",
    "        if mode == 1:\n",
    "            cca_img = cell_img[y:y+h, x:x+w]\n",
    "        if mode == 2:\n",
    "            #print(f\"stats #{idx}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={area})\")\n",
    "            if idx == 0: # ดักบัค crop รูปเกินขอบเขต\n",
    "                cca_img = cell_img[y+5:y+h, :]\n",
    "            elif idx == (len(text_stats)-1):\n",
    "                cca_img = cell_img[y:y+h-5, :]\n",
    "            else:\n",
    "                cca_img = cell_img[y:y+h, :]\n",
    "        text_group_images.append(cca_img)\n",
    "\n",
    "        # หาขนาดของภาพ (ความกว้างและความสูง)\n",
    "        image_height, image_width, _ = rgb_image.shape  # ได้ค่า (สูง, กว้าง, ช่องสี)\n",
    "        cv2.rectangle(rgb_image, (x, y), (image_width, y + h), (0, 255, 0), 1)\n",
    "\n",
    "    if mode == 1:\n",
    "        return text_group_images, calculate_line_stats, rgb_image\n",
    "    else:\n",
    "        return text_group_images, rgb_image\n",
    "\n",
    "# ตารางครึ่งแรก\n",
    "text_subject_code_images, calculate_line_stats_1, subject_code_img = detect_text_group_in_cell(cell_subject_code_img, 1)\n",
    "text_subject_name_images, subject_name_img = detect_text_group_in_cell(cell_subject_name_img, 2, calculate_line_stats_1)\n",
    "text_credit_images, credit_img = detect_text_group_in_cell(cell_credit_img, 2, calculate_line_stats_1)\n",
    "text_academic_results_images, academic_results_img = detect_text_group_in_cell(cell_academic_results_img, 2, calculate_line_stats_1)\n",
    "\n",
    "# ตารางครึ่งหลัง\n",
    "text_subject_code_images_2, calculate_line_stats_2, subject_code_img_2 = detect_text_group_in_cell(cell_subject_code_img_2, 1)\n",
    "text_subject_name_images_2, subject_name_img_2 = detect_text_group_in_cell(cell_subject_name_img_2, 2, calculate_line_stats_2)\n",
    "text_credit_images_2, credit_img_2 = detect_text_group_in_cell(cell_credit_img_2, 2, calculate_line_stats_2)\n",
    "text_academic_results_images_2, academic_results_img_2 = detect_text_group_in_cell(cell_academic_results_img_2, 2, calculate_line_stats_2)\n",
    "\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_code_img.jpg\", subject_code_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_name_img.jpg\", subject_name_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_credit_img.jpg\", credit_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_academic_results_img.jpg\", academic_results_img)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_code_img_2.jpg\", subject_code_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_subject_name_img_2.jpg\", subject_name_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_credit_img_2.jpg\", credit_img_2)\n",
    "cv2.imwrite(f\"{output_folder}/cell_images/cca_academic_results_img_2.jpg\", academic_results_img_2)\n",
    "#cv2.imwrite(f\"{output_folder}/cell_images/cca_text_subject_name_images.jpg\", subject_name_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(text_subject_code_images):\n",
    "    print(idx)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### จับข้อความย่อยในกลุ่มข้อความของ cell ตาราง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n",
      "ภาพเป็นสีดำทั้งหมด\n"
     ]
    }
   ],
   "source": [
    "from numpy import append\n",
    "\n",
    "def detect_sub_text_in_group(binary_image):\n",
    "\n",
    "    text_group = []\n",
    "    for idx, img in enumerate(binary_image):\n",
    "        #print(idx+1)\n",
    "\n",
    "        #plt.figure(figsize=(5,5))\n",
    "        #plt.imshow(img, cmap=\"gray\")\n",
    "        #plt.title(f\"binary_image\")\n",
    "        #plt.show()\n",
    "\n",
    "        sub_text_images = []\n",
    "\n",
    "        kernel_open = np.ones((3, 3), np.uint8)\n",
    "        remove_noise = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "        #plt.figure(figsize=(5,5))\n",
    "        #plt.imshow(remove_noise, cmap=\"gray\")\n",
    "        #plt.title(f\"remove_noise\")\n",
    "        #plt.show()\n",
    "\n",
    "        # เช็คว่าภาพเป็นสีดำทั้งหมดหรือไม่\n",
    "        if not np.any(remove_noise):  # ถ้าค่าพิกเซลทั้งหมดเป็น 0 (ดำสนิท)\n",
    "            print(\"ภาพเป็นสีดำทั้งหมด\")\n",
    "            sub_text_images.append(remove_noise)\n",
    "            #return sub_text_images \n",
    "        \n",
    "        else:\n",
    "            kernel = np.ones((6, 6), np.uint8)\n",
    "            dummy_image = cv2.dilate(remove_noise, kernel, iterations=2)\n",
    "\n",
    "            #plt.figure(figsize=(5,5))\n",
    "            #plt.imshow(dummy_image, cmap=\"gray\")\n",
    "            #plt.title(f\"dummy_image\")\n",
    "            #plt.show()\n",
    "\n",
    "            # ใช้ Connected Component Analysis\n",
    "            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dummy_image, connectivity=8)\n",
    "            char_stats = stats[1:] # ข้าม Background (index 0)\n",
    "            sorted_indices = np.argsort(char_stats[:, 0]) # จัดเรียงตามค่า x (คอลัมน์ที่ 0)\n",
    "            sorted_stats = char_stats[sorted_indices]\n",
    "\n",
    "            # ใช้ Boolean Indexing เพื่อเอา noise ออก \n",
    "            sorted_stats = sorted_stats[sorted_stats[:, 4] >= 200]\n",
    "\n",
    "            for idx, stats in enumerate(sorted_stats):\n",
    "                #x, y, w, h, area = stats[i]\n",
    "                x, y, w, h, area = stats\n",
    "\n",
    "                cca_img = img[y:y+h, x:x+w]\n",
    "                sub_text_images.append(cca_img)\n",
    "\n",
    "        text_group.append(sub_text_images)\n",
    "\n",
    "    return text_group\n",
    "    \n",
    "text_group_subject_code = detect_sub_text_in_group(text_subject_code_images)\n",
    "text_group_subject_name = detect_sub_text_in_group(text_subject_name_images)\n",
    "text_group_credit = detect_sub_text_in_group(text_credit_images)\n",
    "text_group_academic_results = detect_sub_text_in_group(text_academic_results_images)\n",
    "\n",
    "text_group_subject_code_2 = detect_sub_text_in_group(text_subject_code_images_2)\n",
    "text_group_subject_name_2 = detect_sub_text_in_group(text_subject_name_images_2)\n",
    "text_group_credit_2 = detect_sub_text_in_group(text_credit_images_2)\n",
    "text_group_academic_results_2 = detect_sub_text_in_group(text_academic_results_images_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx_g, text_group in enumerate(text_group_subject_code):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(sub_text, cmap=\"gray\")\n",
    "        plt.title(f\"sub text {idx_s+1}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## จับตัวอักษร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import width\n",
    "\n",
    "def scale_contour(contour, scale_factor=1.1):\n",
    "    # คำนวณ centroid ของ contour\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] == 0:\n",
    "        return contour\n",
    "    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    # แปลง contour เป็น float32 เพื่อคำนวณ\n",
    "    scaled_contour = contour.astype(np.float32)\n",
    "    for i in range(scaled_contour.shape[0]):\n",
    "        x, y = scaled_contour[i, 0]\n",
    "        # ปรับขนาดแต่ละจุดโดยคำนวณจาก centroid\n",
    "        scaled_x = cx + (x - cx) * scale_factor\n",
    "        scaled_y = cy + (y - cy) * scale_factor\n",
    "        scaled_contour[i, 0] = [scaled_x, scaled_y]\n",
    "    \n",
    "    return scaled_contour.astype(np.int32)\n",
    "\n",
    "def percentage_difference(value1, value2):\n",
    "    return abs(value1 - value2) / value1 * 100\n",
    "\n",
    "def get_centroid(contour):\n",
    "    # คำนวณ moments ของ contour\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = M[\"m10\"] / M[\"m00\"]\n",
    "        cy = M[\"m01\"] / M[\"m00\"]\n",
    "    else:\n",
    "        cx, cy = 0, 0\n",
    "    return (cx, cy)\n",
    "\n",
    "def detect_one_level_of_char(text_group):\n",
    "    text_group_char = []\n",
    "    for idx_g, text_g in enumerate(text_group):\n",
    "\n",
    "        sub_text_char = []\n",
    "        for idx_s, sub_text in enumerate(text_g):\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(sub_text, cmap=\"gray\")\n",
    "            plt.title(f\"text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "            skeleton_guohall = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(skeleton_guohall, cmap=\"gray\")\n",
    "            plt.title(f\"skeleton, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            #kernel_open = np.ones((2, 2), np.uint8)\n",
    "            kernel_dummy = np.ones((2, 2), np.uint8)\n",
    "            #opening = cv2.morphologyEx(skeleton, cv2.MORPH_OPEN, kernel=kernel_open, iterations=2)\n",
    "            #closing = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_open, iterations=2)\n",
    "            dummy_image = cv2.dilate(skeleton_guohall, kernel_dummy, iterations=1)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            plt.imshow(dummy_image, cmap=\"gray\")\n",
    "            plt.title(f\"dummy_image, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "            rgb_image = cv2.cvtColor(sub_text.copy(), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "\n",
    "            char_images = []\n",
    "            for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "                mask = np.zeros(sub_text.shape[:2], dtype=np.uint8)\n",
    "                cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "\n",
    "                kernel_mask = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # ปรับขนาด kernel ตามต้องการ\n",
    "                dilated_mask = cv2.dilate(mask, kernel_mask, iterations=1)\n",
    "\n",
    "                # ใช้ mask กับภาพต้นฉบับ เพื่อดึงเฉพาะส่วนภายใน contour\n",
    "                char_result = cv2.bitwise_and(sub_text, sub_text, mask=dilated_mask)\n",
    "\n",
    "                contours_char, hierarchy_char = cv2.findContours(char_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                largest_contour = max(contours_char, key=cv2.contourArea)\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "                area = int(cv2.contourArea(largest_contour))\n",
    "                crop_img = char_result[y:y+h, x:x+w]\n",
    "                char_images.append(crop_img)\n",
    "                \n",
    "                '''\n",
    "                plt.figure(figsize=(2, 2))\n",
    "                plt.imshow(crop_img, cmap=\"gray\")\n",
    "                plt.title(f\"crop_img, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "            sub_text_char.append(char_images)\n",
    "        text_group_char.append(sub_text_char)\n",
    "    return text_group_char\n",
    "\n",
    "def char_level(char_images):\n",
    "\n",
    "    char_box = []\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(char_images, cmap=\"gray\")\n",
    "    plt.title(f\"char\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "    skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(skeleton, cmap=\"gray\")\n",
    "    plt.title(f\"skeleton\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "\n",
    "\n",
    "    kernel_dummy = np.ones((3, 3), np.uint8)\n",
    "    closing_skeleton = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(closing_skeleton, cmap=\"gray\")\n",
    "    plt.title(f\"closing_skeleton\")\n",
    "    plt.show()\n",
    "\n",
    "    '''\n",
    "    dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "    closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # เรียง contours ตามค่า y ของ centroid จากน้อยไปหามาก\n",
    "    sorted_contours = sorted(contours, key=lambda cnt: get_centroid(cnt)[1], reverse=True)\n",
    "\n",
    "    # คำนวณพื้นที่ของ contour แต่ละตัว และหาพื้นที่ที่ใหญ่ที่สุด\n",
    "    max_area = max(cv2.contourArea(cnt) for cnt in sorted_contours)\n",
    "\n",
    "    # กำหนด threshold เป็น 5% ของพื้นที่ที่ใหญ่ที่สุด\n",
    "    min_area_threshold = max_area * 0.05\n",
    "\n",
    "    # กรอง contours ที่มีพื้นที่ไม่น้อยกว่า threshold\n",
    "    filtered_contours = [cnt for cnt in sorted_contours if cv2.contourArea(cnt) >= min_area_threshold]\n",
    "\n",
    "    '''\n",
    "    # คำนวณพื้นที่ของแต่ละ contour\n",
    "    areas = [cv2.contourArea(cnt) for cnt in filtered_contours]\n",
    "\n",
    "    # หาตำแหน่งของ contour ที่มีพื้นที่มากที่สุด\n",
    "    max_index = np.argmax(areas)\n",
    "\n",
    "    # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "    if max_index != 0:\n",
    "        filtered_contours[0], filtered_contours[max_index] = filtered_contours[max_index], filtered_contours[0]\n",
    "    '''\n",
    "\n",
    "    # หาก filtered_contours มีแค่ 2 ตัว\n",
    "    if len(filtered_contours) == 2:\n",
    "        area0 = cv2.contourArea(filtered_contours[0])\n",
    "        area1 = cv2.contourArea(filtered_contours[1])\n",
    "        # คำนวณความแตกต่างเป็นอัตราส่วนของ contour ที่มีพื้นที่ใหญ่กว่า\n",
    "        diff_ratio = abs(area0 - area1) / max(area0, area1)\n",
    "        if diff_ratio <= 0.05:\n",
    "            print(\"เหมือนกัน\")\n",
    "\n",
    "            kernel_same = kernel_dummy = np.ones((4, 4), np.uint8)\n",
    "            closing_same = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_same, iterations=2)\n",
    "            contours, hierarchy = cv2.findContours(char_images, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(closing_same, cmap=\"gray\")\n",
    "            plt.title(f\"closing_same\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            level = 1\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            contour_area = int(cv2.contourArea(largest_contour))\n",
    "            crop_img = char_images[y:y+h, x:x+w]\n",
    "            char_box.append([crop_img, level])\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"Level : {level} area: {contour_area}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            return char_box\n",
    "            \n",
    "    # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "    \n",
    "    for idx_c, cnt in enumerate(filtered_contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        contour_area = int(cv2.contourArea(cnt))\n",
    "        char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # สำหรับ list ที่อยู่หลัง list ที่มี area มากที่สุด เราจะเริ่มนับจาก 2\n",
    "    after_counter = 2\n",
    "\n",
    "    # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "    for idx, box in enumerate(char_box):\n",
    "        if idx == max_index:\n",
    "            # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "            box.append(1)\n",
    "        elif idx < max_index:\n",
    "            # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "            box.append(0)\n",
    "        else:\n",
    "            # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append sequential number เริ่มจาก 2\n",
    "            box.append(after_counter)\n",
    "            #after_counter += 1\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "    if max_index != 0:\n",
    "        char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(char_images, cmap=\"gray\")\n",
    "    plt.title(f\"char_images\")\n",
    "    plt.show()\n",
    "    '''\n",
    "        \n",
    "    char_level_images = []\n",
    "    for idx, box in enumerate(char_box):\n",
    "        x, y, w, h, area, level = box\n",
    "        crop_img = char_images[y:y+h, x:x+w]\n",
    "        char_level_images.append([crop_img, level])\n",
    "\n",
    "        '''\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(crop_img, cmap=\"gray\")\n",
    "        plt.title(f\"char : {idx+1} Leve : {level} area: {area}\")\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "    return char_level_images\n",
    "       \n",
    "def detect_char(text_group):\n",
    "    text_group_char = []\n",
    "    for idx_g, text_g in enumerate(text_group):\n",
    "\n",
    "        sub_text_char = []\n",
    "        for idx_s, sub_text in enumerate(text_g):\n",
    "            rgb_image = cv2.cvtColor(sub_text, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "            skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "            kernel_dummy = np.ones((3, 3), np.uint8)\n",
    "            dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "            kernel_closing = np.ones((6, 1), np.uint8)\n",
    "            closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_closing, iterations=1)\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "            \n",
    "            char_images_with_levels = []\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(sub_text, cmap=\"gray\")\n",
    "            plt.title(f\"text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(skeleton, cmap=\"gray\")\n",
    "            plt.title(f\"skeleton, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(dummy_image, cmap=\"gray\")\n",
    "            plt.title(f\"dummy_image, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(closing, cmap=\"gray\")\n",
    "            plt.title(f\"closing, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "                # สมมุติว่าเราได้ contour (cnt) จาก cv2.findContours แล้ว\n",
    "                #scaled_cnt = scale_contour(cnt, scale_factor=1.0)\n",
    "\n",
    "                #char_height, char_width = h, w\n",
    "                #mask = np.zeros((char_height, char_width), dtype=np.uint8)\n",
    "\n",
    "                mask = np.zeros(sub_text.shape[:2], dtype=np.uint8)\n",
    "\n",
    "                rgb_mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "                # วาด contour ลงใน mask โดยเติมเต็ม (thickness = -1) ให้ภายใน contour เป็นสีขาว (255)\n",
    "                cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "                kernel_mask = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))  # ปรับขนาด kernel ตามต้องการ\n",
    "                dilated_mask = cv2.dilate(mask, kernel_mask, iterations=1)\n",
    "\n",
    "                '''\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(dilated_mask, cmap=\"gray\")\n",
    "                plt.title(f\"dilated_mask, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                # ใช้ mask กับภาพต้นฉบับ เพื่อดึงเฉพาะส่วนภายใน contour\n",
    "                char_result = cv2.bitwise_and(sub_text, sub_text, mask=dilated_mask)\n",
    "                char_images_with_levels.extend(char_level(char_result))\n",
    "                #print(\"cher_level_images :\", len(char_images_with_levels))\n",
    "                \n",
    "                '''\n",
    "                for idx_c_l, cher_level in enumerate(cher_level_images):\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(cher_level[0], cmap=\"gray\")\n",
    "                    plt.title(f\"cnt, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c_l+1}, level:{cher_level[1]}\")\n",
    "                    plt.show()\n",
    "                '''\n",
    "            \n",
    "                '''\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.imshow(result, cmap=\"gray\")\n",
    "                plt.title(f\"cnt, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "            sub_text_char.append(char_images_with_levels)\n",
    "            \n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(rgb_image, cmap=\"gray\")\n",
    "            plt.title(f\"Contour, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "            \n",
    "        text_group_char.append(sub_text_char)\n",
    "    return text_group_char\n",
    "\n",
    "\n",
    "#text_group_char_subject_code = detect_one_level_of_char(text_group_subject_code)\n",
    "#text_group_char_academic_results = detect_one_level_of_char(text_group_academic_results)\n",
    "#text_group_char_subject_name = detect_char(text_group_subject_name[8:9])\n",
    "\n",
    "#text_group_char_subject_name_2 = detect_char(text_group_subject_name_2[:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_char\n",
    "for idx_g, text_group in enumerate(text_group_char_subject_name):\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(char[0], cmap=\"gray\")\n",
    "            plt.title(f\"text_group :{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1} \")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_one_level_of_char\n",
    "for idx_g, text_group in enumerate(text_group_char_subject_code):\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            #continue\n",
    "            #print(idx_s)\n",
    "            \n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(char, cmap=\"gray\")\n",
    "            plt.title(f\"char, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนายตัวอักษร 1 ระดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_subject_code_tn = \"../models/char_subject_code_tn_model.h5\"\n",
    "model_path_char_academic_results_tn = \"../models/char_academic_results_tn_model.h5\"\n",
    "\n",
    "model_char_subject_code_tn = load_model(model_path_char_subject_code_tn)\n",
    "model_char_academic_results_tn= load_model(model_path_char_academic_results_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "ประมวลผลเสร็จสิ้น\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_subject_code_tn = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-',\n",
    "]\n",
    "\n",
    "char_academic_results_tn = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    'ก', 'ข', 'ถ', 'ท', 'น', 'ป', 'ผ', 'ม', 'ร', 'ล', 'ส', '.'\n",
    "]\n",
    "\n",
    "char_labels = {\n",
    "    0: char_subject_code_tn,\n",
    "    1: char_academic_results_tn,\n",
    "}\n",
    "\n",
    "class_char = char_subject_code_tn\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_one_level(text_group_char, label=0):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "    text_block = []\n",
    "\n",
    "    for idx_g, text_group in enumerate(text_group_char):\n",
    "        text_result = \"\"\n",
    "\n",
    "        for idx_s, sub_text in enumerate(text_group):\n",
    "            sub_text_result = \"\"\n",
    "\n",
    "            for idx_c, char in enumerate(sub_text):\n",
    "                if char is None:\n",
    "                    print(f\"Character image {idx_c} is None.\")\n",
    "                    continue  # ข้ามภาพนี้\n",
    "                else:\n",
    "                    # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                    padded_img = resize_with_min_padding(char, input_size, min_padding=0)\n",
    "\n",
    "                    #plt.figure(figsize=(2, 2))\n",
    "                    #plt.imshow(padded_img, cmap=\"gray\")\n",
    "                    #plt.title(f\"char, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "                    #plt.show()\n",
    "\n",
    "                    # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                    normalized_img = padded_img / 255.0\n",
    "\n",
    "                    if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                        normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                        processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                        prediction = model_char_subject_code_tn.predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "\n",
    "                        char_label_model = char_labels[label]\n",
    "                        predicted_letter = char_label_model[predicted_class]\n",
    "\n",
    "                        sub_text_result += predicted_letter\n",
    "\n",
    "            text_result += sub_text_result\n",
    "            text_result += \" \"\n",
    "        text_block.append(text_result)\n",
    "\n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_block   \n",
    "            \n",
    "\n",
    "text_box_subject_code = predict_text_one_level(text_group_char_subject_code[:], 0)\n",
    "#text_box_academic_results = predict_text_one_level(text_group_char_academic_results, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: 30000-1101 \n",
      "text 2: 30000-1201 \n",
      "text 3: 30000-1501 \n",
      "text 4: 30000-2001 \n",
      "text 5: 30001-1002 \n",
      "text 6: 3020715001 \n",
      "text 7: 30201-2001 \n",
      "text 8: 30201-2101 \n",
      "text 9: 30201-2102 \n",
      "text 10: 30201-9006 \n",
      "text 11: 300071202 \n",
      "text 12: 300071219 \n",
      "text 13: 300071605 \n",
      "text 14: 30000-1608 \n",
      "text 15: 30000-2002 \n",
      "text 16: 30001-1055 \n",
      "text 17: 30001-2003 \n",
      "text 18: 30200-1002 \n",
      "text 19: 30201-2002 \n",
      "text 20: 30201-2003 \n",
      "text 21: 3020142005 \n",
      "text 22: 300071308 \n"
     ]
    }
   ],
   "source": [
    "def show_information(array):\n",
    "    for idx, data in enumerate(array):\n",
    "        print(f\"text {idx + 1}: {data}\")\n",
    "\n",
    "show_information(text_box_subject_code[:])\n",
    "#show_information(text_box_academic_results[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนายตัวอักษรหลายระดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rule_Based_Post_Processing(word):\n",
    "\n",
    "    if not word:\n",
    "        return word\n",
    "    #word = word.replace(\"ัั\", \"ะ\")\n",
    "    #word = word.replace(\"เเ\", \"แ\")\n",
    "    #word = word.replace(\"้้\", \"ะ\")\n",
    "    #word = word.replace(\"้ั\", \"ะ\")\n",
    "    #word = word.replace(\"ั้\", \"ะ\")\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_level_0 = \"../models/char_level_0_model.h5\"\n",
    "model_path_char_level_1 = \"../models/char_level_1_model.h5\"\n",
    "model_path_char_level_2 = \"../models/char_level_2_model.h5\"\n",
    "model_path_char_level_3 = \"../models/char_level_3_model.h5\"\n",
    "\n",
    "model_char_level_0 = load_model(model_path_char_level_0)\n",
    "model_char_level_1 = load_model(model_path_char_level_1)\n",
    "model_char_level_2 = load_model(model_path_char_level_2)\n",
    "model_char_level_3 = load_model(model_path_char_level_3)\n",
    "\n",
    "# สร้าง Mapping ของโมเดลตามระดับ\n",
    "models = {\n",
    "    0: model_char_level_0,\n",
    "    1: model_char_level_1,\n",
    "    2: model_char_level_2,\n",
    "    3: model_char_level_3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_level_0_label = [\n",
    "    'ุ', 'ู'\n",
    "]\n",
    "\n",
    "char_level_1_label = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "\n",
    "    'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', \n",
    "    'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', \n",
    "    'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', \n",
    "    'ห', 'ฬ', 'อ', 'ฮ',\n",
    "\n",
    "    'ะ','า', 'เ', 'โ', 'ฤ', 'ใ', 'ไ',\n",
    "\n",
    "    '+', '-', '*', '(', ')', '.', '=', '/', '|'\n",
    "]\n",
    "\n",
    "char_level_2_label = [\n",
    "     'ิ', 'ี', 'ึ', 'ื', '็', 'ั', 'ํ', '่', '้', '๊', '๋', '์'\n",
    "]\n",
    "\n",
    "char_level_3_label = [\n",
    "    '่', '้', '๊', '๋',\n",
    "]\n",
    "\n",
    "char_level_labels = {\n",
    "    0: char_level_0_label,\n",
    "    1: char_level_1_label,\n",
    "    2: char_level_2_label,\n",
    "    3: char_level_3_label,\n",
    "}\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_multi_level(text_group_char):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "    text_block = []\n",
    "\n",
    "    for idx_g, text_group in enumerate(text_group_char):\n",
    "        text_result = \"\"\n",
    "\n",
    "        for idx_s, sub_text in enumerate(text_group):\n",
    "            sub_text_result = \"\"\n",
    "\n",
    "            for idx_c, char in enumerate(sub_text):\n",
    "                char_image, char_level = char\n",
    "\n",
    "                if char is None:\n",
    "                    print(f\"Character image {idx_c} is None.\")\n",
    "                    continue  # ข้ามภาพนี้\n",
    "                else:\n",
    "\n",
    "                    # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                    padded_img = resize_with_min_padding(char_image, input_size, min_padding=2)\n",
    "\n",
    "                    '''\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(padded_img, cmap=\"gray\")\n",
    "                    plt.title(f\"Char, text group:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}, level: {char_level}\")\n",
    "                    plt.show()\n",
    "                    '''\n",
    "                    \n",
    "                    # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                    normalized_img = padded_img / 255.0\n",
    "\n",
    "                    if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                        normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                        processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                        if char_level in models:\n",
    "                            prediction = models[char_level].predict(processed_image)\n",
    "                            predicted_class = np.argmax(prediction)\n",
    "                            confidence_score = np.max(prediction)\n",
    "\n",
    "                            class_level = char_level_labels[char_level]\n",
    "                            predicted_letter = class_level[predicted_class]\n",
    "                        else:\n",
    "                            print(\"level ไม่ตรง\")\n",
    "                            prediction = models[2].predict(processed_image)\n",
    "                            predicted_class = np.argmax(prediction)\n",
    "                            confidence_score = np.max(prediction)\n",
    "\n",
    "                            class_level = char_level_labels[2]\n",
    "                            predicted_letter = class_level[predicted_class]\n",
    "\n",
    "                        sub_text_result += predicted_letter\n",
    "            sub_text_result += \" \"\n",
    "            text_result += sub_text_result\n",
    "            text_result_post = Rule_Based_Post_Processing(text_result)\n",
    "        text_block.append(text_result_post)\n",
    "        \n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_block \n",
    "        \n",
    "                    \n",
    "text_box_subject_name = predict_text_multi_level(text_group_char_subject_name[:])\n",
    "#text_box_subject_name_2 = predict_text_multi_level(text_group_char_subject_name_2[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: โปรมกว็มะาเร็จรูปเพ่องานบัญชี \n"
     ]
    }
   ],
   "source": [
    "def show_information(array):\n",
    "    for idx, data in enumerate(array):\n",
    "        print(f\"text {idx + 1}: {data}\")\n",
    "\n",
    "#show_information(text_box_subject_code[:])\n",
    "show_information(text_box_subject_name[:])\n",
    "#show_information(text_box_subject_name_2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity ratio: 0.8\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "str1 = \"กิจกรรมองค์การวิชาชีพ 4\"\n",
    "str2 = \"กิจกรรมองค์การ่๊ขาจพ 4\"\n",
    "\n",
    "matcher = difflib.SequenceMatcher(None, str1, str2)\n",
    "print(\"Similarity ratio:\", matcher.ratio())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ข้อมูลนักศึกษา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n",
      "601\n",
      "740\n",
      "745\n"
     ]
    }
   ],
   "source": [
    "def crop_border(image, left_percent=0, right_percent=0, top_percent=0, bottom_percent=0):\n",
    "    \n",
    "    # หาความกว้างและความสูงของภาพ\n",
    "    height, width = image.shape\n",
    "\n",
    "    # คำนวณพิกัดที่จะตัด (แปลงเป็นพิกเซล)\n",
    "    x_start = int(width * left_percent)\n",
    "    x_end = int(width * (1 - right_percent))\n",
    "    y_start = int(height * top_percent)\n",
    "    y_end = int(height * (1 - bottom_percent))\n",
    "\n",
    "    # ตัดภาพ (Crop)\n",
    "    cropped_img = image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    #cv2.imwrite(f\"{output_folder}/cropped_fh.jpg\", cropped_img)\n",
    "    \n",
    "    return cropped_img\n",
    "\n",
    "def find_text_student_info_fh(student_info_fh_img):\n",
    "    student_info_fh_img = crop_border(student_info_fh_img.copy(), 0.06, 0.06, 0.06, 0.01)\n",
    "\n",
    "    rgb_image = cv2.cvtColor(student_info_fh_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # กำหนด kernel (ขนาดของ kernel สามารถปรับเปลี่ยนได้ตามความเหมาะสม)\n",
    "    kernel_open = np.ones((2, 2), np.uint8)\n",
    "    kernel_close = np.ones((6, 50), np.uint8)\n",
    "    \n",
    "    opening = cv2.morphologyEx(student_info_fh_img.copy(), cv2.MORPH_OPEN, kernel=kernel_open, iterations=1)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel=kernel_close, iterations=2)\n",
    "\n",
    "    rgb_closing_image = cv2.cvtColor(closing, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/opening.jpg\", opening)\n",
    "    cv2.imwrite(f\"{output_folder}/closing.jpg\", closing)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closing, connectivity=8)\n",
    "\n",
    "    # 1. เอา stats ตัวแรก (background) ออก\n",
    "    stats_no_bg = stats[1:]\n",
    "\n",
    "    # 2. เรียง stats ใหม่โดยใช้ค่า area (คอลัมน์ที่ 4) จากมากไปน้อย\n",
    "    sorted_indices = np.argsort(-stats_no_bg[:, 4])\n",
    "    sorted_stats = stats_no_bg[sorted_indices]\n",
    "\n",
    "    # 3. เลือกแค่ 13 element ที่มีค่า area สูงสุด\n",
    "    top_13_stats = sorted_stats[:13]\n",
    "    top_13_stats_sorted_by_y = top_13_stats[np.argsort(top_13_stats[:, 1])]\n",
    "\n",
    "    img_height, img_width = student_info_fh_img.shape[:2]\n",
    "\n",
    "    # กำหนด margin เป็นเปอร์เซ็นต์ของขนาด bounding box\n",
    "    # เช่น กำหนด 10% ของความกว้าง/ความสูงของ bounding box สำหรับแต่ละด้าน\n",
    "    left_margin_percent = 0.1    # ขยายซ้าย 10%\n",
    "    right_margin_percent = 0.1   # ขยายขวา 10%\n",
    "    top_margin_percent = 0.2     # ขยายบน 20%\n",
    "    bottom_margin_percent = 0.1  # ขยายล่าง 10%\n",
    "\n",
    "    text_group_stud_fh = []\n",
    "    for idx, stats in enumerate(top_13_stats_sorted_by_y): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "\n",
    "        # คำนวณ margin ตามเปอร์เซ็นต์ของ bounding box\n",
    "        left_margin = int(w * left_margin_percent)\n",
    "        right_margin = int(w * right_margin_percent)\n",
    "        top_margin = int(h * top_margin_percent)\n",
    "        bottom_margin = int(h * bottom_margin_percent)\n",
    "\n",
    "        # คำนวณพิกัดใหม่โดยใช้ margin ที่คำนวณได้\n",
    "        x_new = max(x - left_margin, 0)\n",
    "        y_new = max(y - top_margin, 0)\n",
    "        x_end = min(x + w + right_margin, img_width)\n",
    "        y_end = min(y + h + bottom_margin, img_height)\n",
    "\n",
    "        cluster_img = student_info_fh_img[y_new:y_end, x_new:x_end]\n",
    "        text_group_stud_fh.append(cluster_img)\n",
    "\n",
    "        # วาดกรอบที่ขยายแล้วลงบนภาพ\n",
    "        cv2.rectangle(rgb_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        cv2.rectangle(rgb_closing_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        \n",
    "    cv2.imwrite(f\"{output_folder}/cca_top_13_stats.jpg\", rgb_image)\n",
    "    cv2.imwrite(f\"{output_folder}/cca_rgb_closing_image.jpg\", rgb_closing_image)\n",
    "\n",
    "    return text_group_stud_fh[1:]\n",
    "\n",
    "def find_text_student_info_sh(student_info_sh_img):\n",
    "    student_info_sh_img = crop_border(student_info_sh_img.copy(), 0.05, 0.00, 0.05, 0.01)\n",
    "\n",
    "    rgb_image = cv2.cvtColor(student_info_sh_img.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # กำหนด kernel (ขนาดของ kernel สามารถปรับเปลี่ยนได้ตามความเหมาะสม)\n",
    "    kernel_open = np.ones((2, 2), np.uint8)\n",
    "    kernel_close = np.ones((8, 50), np.uint8)\n",
    "    \n",
    "    opening = cv2.morphologyEx(student_info_sh_img.copy(), cv2.MORPH_OPEN, kernel=kernel_open, iterations=1)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel=kernel_close, iterations=2)\n",
    "\n",
    "    rgb_closing_image = cv2.cvtColor(closing, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    cv2.imwrite(f\"{output_folder}/opening_sh.jpg\", opening)\n",
    "    cv2.imwrite(f\"{output_folder}/closing_sh.jpg\", closing)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closing, connectivity=8)\n",
    "\n",
    "    # 1. เอา stats ตัวแรก (background) ออก\n",
    "    stats_no_bg = stats[1:]\n",
    "\n",
    "    # 2. เรียง stats ใหม่โดยใช้ค่า area (คอลัมน์ที่ 4) จากมากไปน้อย\n",
    "    sorted_indices = np.argsort(-stats_no_bg[:, 4])\n",
    "    sorted_stats = stats_no_bg[sorted_indices]\n",
    "\n",
    "    # 3. เลือกแค่ 14 element ที่มีค่า area สูงสุด\n",
    "    top_14_stats = sorted_stats[:14]\n",
    "    top_14_stats_sorted_by_y = top_14_stats[np.argsort(top_14_stats[:, 1])]\n",
    "\n",
    "    img_height, img_width = student_info_sh_img.shape[:2]\n",
    "\n",
    "    # กำหนด margin เป็นเปอร์เซ็นต์ของขนาด bounding box\n",
    "    # เช่น กำหนด 10% ของความกว้าง/ความสูงของ bounding box สำหรับแต่ละด้าน\n",
    "    left_margin_percent = 0.1    # ขยายซ้าย 10%\n",
    "    right_margin_percent = 0.1   # ขยายขวา 10%\n",
    "    top_margin_percent = 0.2     # ขยายบน 20%\n",
    "    bottom_margin_percent = 0.1  # ขยายล่าง 10%\n",
    "\n",
    "    text_group_stud_sh = []\n",
    "    for idx, stats in enumerate(top_14_stats_sorted_by_y): # เก็บภาพกลุม\n",
    "        x, y, w, h, area = stats\n",
    "\n",
    "        # คำนวณ margin ตามเปอร์เซ็นต์ของ bounding box\n",
    "        left_margin = int(w * left_margin_percent)\n",
    "        right_margin = int(w * right_margin_percent)\n",
    "        top_margin = int(h * top_margin_percent)\n",
    "        bottom_margin = int(h * bottom_margin_percent)\n",
    "\n",
    "        # คำนวณพิกัดใหม่โดยใช้ margin ที่คำนวณได้\n",
    "        x_new = max(x - left_margin, 0)\n",
    "        y_new = max(y - top_margin, 0)\n",
    "        x_end = min(x + w + right_margin, img_width)\n",
    "        y_end = min(y + h + bottom_margin, img_height)\n",
    "\n",
    "        cluster_img = student_info_sh_img[y_new:y_end, x_new:x_end]\n",
    "        text_group_stud_sh.append(cluster_img)\n",
    "\n",
    "        # วาดกรอบที่ขยายแล้วลงบนภาพ\n",
    "        cv2.rectangle(rgb_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        cv2.rectangle(rgb_closing_image, (x_new, y_new), (x_end, y_end), (0, 255, 0), 1)\n",
    "        \n",
    "    cv2.imwrite(f\"{output_folder}/cca_top_14_stats.jpg\", rgb_image)\n",
    "    cv2.imwrite(f\"{output_folder}/cca_rgb_closing_image.jpg\", rgb_closing_image)\n",
    "\n",
    "    return text_group_stud_sh[3:]\n",
    "\n",
    "text_stud_fh_images = find_text_student_info_fh(student_info_fh_img)\n",
    "text_stud_sh_images = find_text_student_info_sh(student_info_sh_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx_g, text_group in enumerate(text_stud_fh_images):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(text_group, cmap=\"gray\")\n",
    "    plt.title(f\"text_group {idx_g+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_fh = [3, -2, -1]\n",
    "indices_sh = [-3, -1]\n",
    "student_name, field_of_study, field_of_work = [text_stud_fh_images[i] for i in indices_fh]\n",
    "cgpa, graduation_date = [text_stud_sh_images[i] for i in indices_sh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sub_text_in_group_stud(binary_image):\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(binary_image, cmap=\"gray\")\n",
    "    plt.title(f\"binary_image\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    text_group = []\n",
    "\n",
    "    #kernel_open = np.ones((2, 2), np.uint8)\n",
    "    #remove_noise = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "\n",
    "    #plt.figure(figsize=(5,5))\n",
    "    #plt.imshow(remove_noise, cmap=\"gray\")\n",
    "    #plt.title(f\"remove_noise\")\n",
    "    #plt.show()\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dummy_image = cv2.dilate(binary_image, kernel, iterations=2)\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(dummy_image, cmap=\"gray\")\n",
    "    plt.title(f\"dummy_image\")\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    # ใช้ Connected Component Analysis\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dummy_image, connectivity=8)\n",
    "    word_stats = stats[1:] # ข้าม Background (index 0)\n",
    "    sorted_indices = np.argsort(word_stats[:, 0]) # จัดเรียงตามค่า x (คอลัมน์ที่ 0)\n",
    "    sorted_stats = word_stats[sorted_indices]\n",
    "\n",
    "    for idx, stats in enumerate(sorted_stats):\n",
    "        x, y, w, h, area = stats\n",
    "        cluster_img = binary_image[y:y+h, x:x+w]\n",
    "        text_group.append(cluster_img)\n",
    "\n",
    "    return text_group\n",
    "\n",
    "text_group_student_name = detect_sub_text_in_group_stud(student_name)\n",
    "text_group_field_of_study = detect_sub_text_in_group_stud(field_of_study)\n",
    "text_group_field_of_work = detect_sub_text_in_group_stud(field_of_work)\n",
    "\n",
    "text_group_cgpa = detect_sub_text_in_group_stud(cgpa)\n",
    "text_group_graduation_date = detect_sub_text_in_group_stud(graduation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดสอบดูรูป\n",
    "for idx, sub_text in enumerate(text_group_student_name):\n",
    "    print(f\"text {idx_g+1}\")\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(sub_text, cmap=\"gray\")\n",
    "    plt.title(f\"sub_text {idx+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_level_stud(char_images):\n",
    "\n",
    "    char_box = []\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(char_images, cmap=\"gray\")\n",
    "    plt.title(f\"char\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    #skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "    skeleton = cv2.ximgproc.thinning(char_images, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(skeleton, cmap=\"gray\")\n",
    "    plt.title(f\"skeleton\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    kernel_dummy = np.ones((3, 3), np.uint8)\n",
    "    closing_skeleton = cv2.morphologyEx(skeleton, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(closing_skeleton, cmap=\"gray\")\n",
    "    plt.title(f\"closing_skeleton\")\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "    closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_dummy, iterations=1)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(dummy_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # เรียง contours ตามค่า y ของ centroid จากน้อยไปหามาก\n",
    "    sorted_contours = sorted(contours, key=lambda cnt: get_centroid(cnt)[1], reverse=True)\n",
    "\n",
    "    # คำนวณพื้นที่ของ contour แต่ละตัว และหาพื้นที่ที่ใหญ่ที่สุด\n",
    "    max_area = max(cv2.contourArea(cnt) for cnt in sorted_contours)\n",
    "\n",
    "    # กำหนด threshold เป็น 5% ของพื้นที่ที่ใหญ่ที่สุด\n",
    "    min_area_threshold = max_area * 0.05\n",
    "\n",
    "    # กรอง contours ที่มีพื้นที่ไม่น้อยกว่า threshold\n",
    "    filtered_contours = [cnt for cnt in sorted_contours if cv2.contourArea(cnt) >= min_area_threshold]\n",
    "\n",
    "    '''\n",
    "    # คำนวณพื้นที่ของแต่ละ contour\n",
    "    areas = [cv2.contourArea(cnt) for cnt in filtered_contours]\n",
    "\n",
    "    # หาตำแหน่งของ contour ที่มีพื้นที่มากที่สุด\n",
    "    max_index = np.argmax(areas)\n",
    "\n",
    "    # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "    if max_index != 0:\n",
    "        filtered_contours[0], filtered_contours[max_index] = filtered_contours[max_index], filtered_contours[0]\n",
    "    '''\n",
    "\n",
    "    # หาก filtered_contours มีแค่ 2 ตัว\n",
    "    if len(filtered_contours) == 2:\n",
    "        area0 = cv2.contourArea(filtered_contours[0])\n",
    "        area1 = cv2.contourArea(filtered_contours[1])\n",
    "        # คำนวณความแตกต่างเป็นอัตราส่วนของ contour ที่มีพื้นที่ใหญ่กว่า\n",
    "        diff_ratio = abs(area0 - area1) / max(area0, area1)\n",
    "        if diff_ratio <= 0.05:\n",
    "            print(\"เหมือนกัน\")\n",
    "\n",
    "            kernel_same = kernel_dummy = np.ones((4, 4), np.uint8)\n",
    "            closing_same = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_same, iterations=2)\n",
    "            contours, hierarchy = cv2.findContours(char_images, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(closing_same, cmap=\"gray\")\n",
    "            plt.title(f\"closing_same\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            level = 1\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            contour_area = int(cv2.contourArea(largest_contour))\n",
    "            crop_img = char_images[y:y+h, x:x+w]\n",
    "            char_box.append([crop_img, level])\n",
    "\n",
    "            '''\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(crop_img, cmap=\"gray\")\n",
    "            plt.title(f\"Level : {level} area: {contour_area}\")\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            return char_box\n",
    "            \n",
    "    # เก็บ x, y, w, h, area ของ filtered_contours เข้าไปใน char_box\n",
    "    \n",
    "    for idx_c, cnt in enumerate(filtered_contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        contour_area = int(cv2.contourArea(cnt))\n",
    "        char_box.append([x, y, w, h, contour_area])\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # สำหรับ list ที่อยู่หลัง list ที่มี area มากที่สุด เราจะเริ่มนับจาก 2\n",
    "    after_counter = 2\n",
    "\n",
    "    # ปรับปรุงแต่ละ list ตามเงื่อนไขที่ระบุ\n",
    "    for idx, box in enumerate(char_box):\n",
    "        if idx == max_index:\n",
    "            # ถ้าเป็น list ที่มี area มากที่สุด append 1\n",
    "            box.append(1)\n",
    "        elif idx < max_index:\n",
    "            # ถ้าอยู่ก่อน list ที่มี area มากที่สุด append 0\n",
    "            box.append(0)\n",
    "        else:\n",
    "            # ถ้าอยู่หลัง list ที่มี area มากที่สุด ให้ append sequential number เริ่มจาก 2\n",
    "            box.append(after_counter)\n",
    "            #after_counter += 1\n",
    "\n",
    "    # คำนวณ index ของ list ที่มี area มากที่สุด\n",
    "    areas = [item[4] for item in char_box]\n",
    "\n",
    "    max_index = areas.index(max(areas))\n",
    "\n",
    "    # ถ้า contour ที่มีพื้นที่มากที่สุดไม่ได้อยู่ลำดับแรก ให้สลับตำแหน่งกับ contour ตัวแรก\n",
    "    if max_index != 0:\n",
    "        char_box[0], char_box[max_index] = char_box[max_index], char_box[0]\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(char_images, cmap=\"gray\")\n",
    "    plt.title(f\"char_images\")\n",
    "    plt.show()\n",
    "    '''\n",
    "        \n",
    "    char_level_images = []\n",
    "    for idx, box in enumerate(char_box):\n",
    "        x, y, w, h, area, level = box\n",
    "        crop_img = char_images[y:y+h, x:x+w]\n",
    "        char_level_images.append([crop_img, level])\n",
    "\n",
    "        '''\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(crop_img, cmap=\"gray\")\n",
    "        plt.title(f\"char : {idx+1} Leve : {level} area: {area}\")\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "    return char_level_images\n",
    "       \n",
    "def detect_char_stud(text_group):\n",
    "\n",
    "    sub_text_char = []\n",
    "    for idx_s, sub_text in enumerate(text_group):\n",
    "        rgb_image = cv2.cvtColor(sub_text, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "        skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "        #skeleton = cv2.ximgproc.thinning(sub_text, thinningType=cv2.ximgproc.THINNING_GUOHALL)\n",
    "\n",
    "        kernel_dummy = np.ones((2, 2), np.uint8)\n",
    "        dummy_image = cv2.dilate(skeleton, kernel_dummy, iterations=1)\n",
    "        kernel_closing = np.ones((7, 1), np.uint8)\n",
    "        closing = cv2.morphologyEx(dummy_image, cv2.MORPH_CLOSE, kernel=kernel_closing, iterations=1)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        sorted_contours = sorted(contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "            \n",
    "        char_images_with_levels = []\n",
    "\n",
    "        '''\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(sub_text, cmap=\"gray\")\n",
    "        plt.title(f\"sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(skeleton, cmap=\"gray\")\n",
    "        plt.title(f\"skeleton, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(dummy_image, cmap=\"gray\")\n",
    "        plt.title(f\"dummy_image, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(closing, cmap=\"gray\")\n",
    "        plt.title(f\"closing, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "        for idx_c, cnt in enumerate(sorted_contours):\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            contour_area = cv2.contourArea(cnt)\n",
    "\n",
    "            # สมมุติว่าเราได้ contour (cnt) จาก cv2.findContours แล้ว\n",
    "            #scaled_cnt = scale_contour(cnt, scale_factor=1.0)\n",
    "\n",
    "            #char_height, char_width = h, w\n",
    "            #mask = np.zeros((char_height, char_width), dtype=np.uint8)\n",
    "\n",
    "            mask = np.zeros(sub_text.shape[:2], dtype=np.uint8)\n",
    "\n",
    "            rgb_mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            # วาด contour ลงใน mask โดยเติมเต็ม (thickness = -1) ให้ภายใน contour เป็นสีขาว (255)\n",
    "            cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "            kernel_mask = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # ปรับขนาด kernel ตามต้องการ\n",
    "            dilated_mask = cv2.dilate(mask, kernel_mask, iterations=1)\n",
    "\n",
    "            \n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(dilated_mask, cmap=\"gray\")\n",
    "            plt.title(f\"dilated_mask, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            # ใช้ mask กับภาพต้นฉบับ เพื่อดึงเฉพาะส่วนภายใน contour\n",
    "            char_result = cv2.bitwise_and(sub_text, sub_text, mask=dilated_mask)\n",
    "            char_images_with_levels.extend(char_level_stud(char_result))\n",
    "            #print(\"cher_level_images :\", len(char_images_with_levels))\n",
    "\n",
    "            \n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(char_result, cmap=\"gray\")\n",
    "            plt.title(f\"sub text:{idx_s+1}, char:{idx_c+1}\")\n",
    "            plt.show()\n",
    "            \n",
    "                \n",
    "            '''\n",
    "            for idx_c_l, cher_level in enumerate(cher_level_images):\n",
    "                plt.figure(figsize=(2, 2))\n",
    "                plt.imshow(cher_level[0], cmap=\"gray\")\n",
    "                plt.title(f\"cnt, text box:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c_l+1}, level:{cher_level[1]}\")\n",
    "                plt.show()\n",
    "            '''\n",
    "            \n",
    "                \n",
    "            #print(f\"Contour #{idx_c}: bounding box = (x={x}, y={y}, w={w}, h={h}, area={contour_area})\")\n",
    "\n",
    "        sub_text_char.append(char_images_with_levels)\n",
    "            \n",
    "        '''\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(rgb_image, cmap=\"gray\")\n",
    "        plt.title(f\"Contour, text box:{idx_g+1}, sub text:{idx_s+1}\")\n",
    "        plt.show()\n",
    "        '''\n",
    "            \n",
    "\n",
    "    return sub_text_char\n",
    "\n",
    "\n",
    "text_group_char_student_name = detect_char_stud(text_group_student_name[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_char\n",
    "\n",
    "for idx_s, sub_text in enumerate(text_group_char_student_name):\n",
    "    for idx_c, char in enumerate(sub_text):\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(char[0], cmap=\"gray\")\n",
    "        plt.title(f\"sub text:{idx_s+1}, char:{idx_c+1} \")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ทำนายตัวอักษรหลายระดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rule_Based_Post_Processing(word):\n",
    "\n",
    "    if not word:\n",
    "        return word\n",
    "    #word = word.replace(\"ัั\", \"ะ\")\n",
    "    #word = word.replace(\"เเ\", \"แ\")\n",
    "    #word = word.replace(\"้้\", \"ะ\")\n",
    "    #word = word.replace(\"้ั\", \"ะ\")\n",
    "    #word = word.replace(\"ั้\", \"ะ\")\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path_char_level_0 = \"../models/char_level_0_model.h5\"\n",
    "model_path_char_level_1 = \"../models/char_level_1_model.h5\"\n",
    "model_path_char_level_2 = \"../models/char_level_2_model.h5\"\n",
    "model_path_char_level_3 = \"../models/char_level_3_model.h5\"\n",
    "\n",
    "model_char_level_0 = load_model(model_path_char_level_0)\n",
    "model_char_level_1 = load_model(model_path_char_level_1)\n",
    "model_char_level_2 = load_model(model_path_char_level_2)\n",
    "model_char_level_3 = load_model(model_path_char_level_3)\n",
    "\n",
    "# สร้าง Mapping ของโมเดลตามระดับ\n",
    "models = {\n",
    "    0: model_char_level_0,\n",
    "    1: model_char_level_1,\n",
    "    2: model_char_level_2,\n",
    "    3: model_char_level_3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "ประมวลผลเสร็จสิ้น\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "char_level_0_label = [\n",
    "    'ุ', 'ู'\n",
    "]\n",
    "\n",
    "char_level_1_label = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "\n",
    "    'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', \n",
    "    'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', \n",
    "    'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', \n",
    "    'ห', 'ฬ', 'อ', 'ฮ',\n",
    "\n",
    "    'ะ','า', 'เ', 'โ', 'ฤ', 'ใ', 'ไ',\n",
    "\n",
    "    '+', '-', '*', '(', ')', '.', '=', '/', '|'\n",
    "]\n",
    "\n",
    "char_level_2_label = [\n",
    "     'ิ', 'ี', 'ึ', 'ื', '็', 'ั', 'ํ', '่', '้', '๊', '๋', '์'\n",
    "]\n",
    "\n",
    "char_level_3_label = [\n",
    "    '่', '้', '๊', '๋',\n",
    "]\n",
    "\n",
    "char_level_labels = {\n",
    "    0: char_level_0_label,\n",
    "    1: char_level_1_label,\n",
    "    2: char_level_2_label,\n",
    "    3: char_level_3_label,\n",
    "}\n",
    "\n",
    "def resize_with_min_padding(image, desired_size, min_padding):\n",
    "    \n",
    "    \"\"\"\n",
    "    ปรับขนาดภาพให้ใกล้เคียง desired_size โดยลด Padding และเพิ่มการขยายภาพต้นฉบับ\n",
    "    \"\"\"\n",
    "    if image is None or not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a valid numpy array.\")\n",
    "\n",
    "    if not isinstance(desired_size, int) or desired_size <= 0:\n",
    "        raise ValueError(\"desired_size must be a positive integer.\")\n",
    "\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    max_size = max(old_size)\n",
    "\n",
    "    # คำนวณอัตราส่วนการปรับขนาดให้ใกล้เคียง desired_size\n",
    "    ratio = float(desired_size - 2 * min_padding) / max_size\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])  # ขนาดใหม่ (height, width)\n",
    "\n",
    "    # Resize ภาพให้คงสัดส่วนเดิม แต่ใหญ่ขึ้น\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # คำนวณ Padding ใหม่\n",
    "    delta_w = max(desired_size - new_size[1], 0)  # Padding ด้านความกว้าง\n",
    "    delta_h = max(desired_size - new_size[0], 0)  # Padding ด้านความสูง\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # ตรวจสอบสีสำหรับ Grayscale หรือ RGB\n",
    "    color = [0] if len(image.shape) == 2 else [0, 0, 0]\n",
    "\n",
    "    # เพิ่ม Padding รอบภาพ\n",
    "    padded_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def predict_text_multi_level_stud(text_group_char):\n",
    "    # กำหนดขนาด Input ของโมเดล\n",
    "    input_size = 32  # ขนาด 32x32\n",
    "\n",
    "    text_result = \"\"\n",
    "    for idx_s, sub_text in enumerate(text_group_char):\n",
    "        sub_text_result = \"\"\n",
    "\n",
    "        for idx_c, char in enumerate(sub_text):\n",
    "            char_image, char_level = char\n",
    "\n",
    "            if char is None:\n",
    "                print(f\"Character image {idx_c} is None.\")\n",
    "                continue  # ข้ามภาพนี้\n",
    "            else:\n",
    "\n",
    "                # เพิ่ม Padding และปรับขนาดภาพ\n",
    "                padded_img = resize_with_min_padding(char_image, input_size, min_padding=2)\n",
    "\n",
    "                '''\n",
    "                plt.figure(figsize=(2, 2))\n",
    "                plt.imshow(padded_img, cmap=\"gray\")\n",
    "                plt.title(f\"Char, text group:{idx_g+1}, sub text:{idx_s+1}, char:{idx_c+1}, level: {char_level}\")\n",
    "                plt.show()\n",
    "                '''\n",
    "                    \n",
    "                # Normalization (เปลี่ยนค่าพิกเซลให้อยู่ในช่วง [0, 1])\n",
    "                normalized_img = padded_img / 255.0\n",
    "\n",
    "                if len(normalized_img.shape) == 2:  # หากภาพเป็น Grayscale (2D)\n",
    "                    normalized_img = np.expand_dims(normalized_img, axis=-1)\n",
    "                    processed_image = np.expand_dims(normalized_img, axis=0)  # เพิ่ม Batch Dimension\n",
    "\n",
    "                    if char_level in models:\n",
    "                        prediction = models[char_level].predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence_score = np.max(prediction)\n",
    "\n",
    "                        class_level = char_level_labels[char_level]\n",
    "                        predicted_letter = class_level[predicted_class]\n",
    "                    else:\n",
    "                        print(\"level ไม่ตรง\")\n",
    "                        prediction = models[2].predict(processed_image)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence_score = np.max(prediction)\n",
    "\n",
    "                        class_level = char_level_labels[2]\n",
    "                        predicted_letter = class_level[predicted_class]\n",
    "\n",
    "                    sub_text_result += predicted_letter\n",
    "\n",
    "        sub_text_result += \" \"\n",
    "        text_result += sub_text_result\n",
    "        text_result_post = Rule_Based_Post_Processing(text_result)\n",
    "        #text_block.append(text_result_post)\n",
    "        \n",
    "    print(\"ประมวลผลเสร็จสิ้น\")\n",
    "    return text_result_post \n",
    "        \n",
    "                    \n",
    "text_box_student_name = predict_text_multi_level_stud(text_group_char_student_name[:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "นางสาวจรฬุท์ พืรวในสฤล \n"
     ]
    }
   ],
   "source": [
    "print(text_box_student_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
